Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Rodriguez-Mier2021,
abstract = {Author summary Understanding deregulations of metabolism based on isolated measures of gene expression or protein or metabolite concentrations is a challenging task due to the interconnection of multiple processes. One solution is to extract, from generic genome-scale metabolic networks, the specific sub-network which is modulated in the studied condition. Many algorithms have been proposed for such context-specific network extraction based on experimental measurements. However, this process is subject to some randomness and variability, since multiple metabolic networks can model the metabolic state in a similarly adequate manner for the same experimental data. This means that for a given data and reconstruction method, there are usually multiple solutions that satisfy the same constraints and with the same quality, but only one solution is returned by the commonly used reconstruction methods. Here, we formalize this problem and we propose and analyze different methods to obtain diverse samples of metabolic sub-networks. We evaluate them by performing an extensive comparison and we show how the different sets of optimal networks discovered by the different methods are biological meaningful by constructing ensembles of networks to improve the prediction of essential genes in Saccharomyces cerevisiae and to detect enriched metabolic pathways in four different human cancer cell lines.},
author = {Rodr{\'{i}}guez-Mier, Pablo and Poupin, Nathalie and de Blasio, Carlo and {Le Cam}, Laurent and Jourdan, Fabien},
journal = {PLOS Comput. Biol.},
month = {feb},
number = {2},
pages = {e1008730},
publisher = {Public Library of Science},
title = {{DEXOM: Diversity-based enumeration of optimal context-specific metabolic networks}},
url = {https://doi.org/10.1371/journal.pcbi.1008730},
volume = {17},
year = {2021}
}
@article{Wang2021,
abstract = {In recent times, machine learning has become increasingly prominent in predictive toxicology as it has shifted from in vivo studies toward in silico studies. Currently, in vitro methods together with other computational methods such as quantitative structure–activity relationship modeling and absorption, distribution, metabolism, and excretion calculations are being used. An overview of machine learning and its applications in predictive toxicology is presented here, including support vector machines (SVMs), random forest (RF) and decision trees (DTs), neural networks, regression models, na{\"{i}}ve Bayes, k-nearest neighbors, and ensemble learning. The recent successes of these machine learning methods in predictive toxicology are summarized, and a comparison of some models used in predictive toxicology is presented. In predictive toxicology, SVMs, RF, and DTs are the dominant machine learning methods due to the characteristics of the data available. Lastly, this review describes the current challenges facing the use of machine learning in predictive toxicology and offers insights into the possible areas of improvement in the field.},
annote = {doi: 10.1021/acs.chemrestox.0c00316},
author = {Wang, Marcus W H and Goodman, Jonathan M and Allen, Timothy E H},
doi = {10.1021/acs.chemrestox.0c00316},
issn = {0893-228X},
journal = {Chem. Res. Toxicol.},
month = {feb},
number = {2},
pages = {217--239},
publisher = {American Chemical Society},
title = {{Machine Learning in Predictive Toxicology: Recent Applications and Future Directions for Classification Models}},
url = {https://doi.org/10.1021/acs.chemrestox.0c00316},
volume = {34},
year = {2021}
}
@article{Zur2010b,
abstract = {SUMMARY: iMAT is an Integrative Metabolic Analysis Tool, enabling the integration of  transcriptomic and proteomic data with genome-scale metabolic network models to predict enzymes' metabolic flux, based on the method previously described by Shlomi et al. The prediction of metabolic fluxes based on high-throughput molecular data sources could help to advance our understanding of cellular metabolism, since current experimental approaches are limited to measuring fluxes through merely a few dozen enzymes. AVAILABILITY AND IMPLEMENTATION: http://imat.cs.tau.ac.il/.},
author = {Zur, Hadas and Ruppin, Eytan and Shlomi, Tomer},
doi = {10.1093/bioinformatics/btq602},
issn = {1367-4811 (Electronic)},
journal = {Bioinformatics},
keywords = {Gene Expression Profiling,Genome,Metabolic Networks and Pathways,Models, Biological,Principal Component Analysis,Proteomics,Software},
language = {eng},
month = {dec},
number = {24},
pages = {3140--3142},
pmid = {21081510},
title = {{iMAT: an integrative metabolic analysis tool.}},
volume = {26},
year = {2010}
}
@article{Jiang2019b,
abstract = {Drug-induced liver injury (DILI) complicates safety assessment for new drugs and poses major threats to both patient health and drug development in the pharmaceutical industry. A number of human liver cell-based in vitro models combined with toxicogenomics methods have been developed as an alternative to animal testing for studying human DILI mechanisms. In this review, we discuss the in vitro human liver systems and their applications in omics-based drug-induced hepatotoxicity studies. We furthermore present bioinformatic approaches that are useful for analyzing toxicogenomic data generated from these models and discuss their current and potential contributions to the understanding of mechanisms of DILI. Human pluripotent stem cells, carrying donor-specific genetic information, hold great potential for advancing the study of individual-specific toxicological responses. When co-cultured with other liver-derived non-parenchymal cells in a microfluidic device, the resulting dynamic platform enables us to study immune-mediated drug hypersensitivity and accelerates personalized drug toxicology studies. A flexible microfluidic platform would also support the assembly of a more advanced organs-on-a-chip device, further bridging gap between in vitro and in vivo conditions. The standard transcriptomic analysis of these cell systems can be complemented with causality-inferring approaches to improve the understanding of DILI mechanisms. These approaches involve statistical techniques capable of elucidating regulatory interactions in parts of these mechanisms. The use of more elaborated human liver models, in harmony with causality-inferring bioinformatic approaches will pave the way for establishing a powerful methodology to systematically assess DILI mechanisms across a wide range of conditions.},
author = {Jiang, Jian and Pieterman, Charlie D and Ertaylan, G{\"{o}}khan and Peeters, Ralf L M and de Kok, Theo M C M},
doi = {10.1007/s00204-019-02585-5},
issn = {1432-0738},
journal = {Arch. Toxicol.},
number = {11},
pages = {3067--3098},
title = {{The application of omics-based human liver platforms for investigating the mechanism of drug-induced hepatotoxicity in vitro}},
url = {https://doi.org/10.1007/s00204-019-02585-5},
volume = {93},
year = {2019}
}
@article{Castillo2017,
abstract = {BACKGROUND: Nowadays, many public repositories containing large microarray gene expression datasets are available. However, the problem lies in the fact that microarray technology are less powerful and accurate than more recent Next Generation Sequencing technologies, such as RNA-Seq. In any case, information from microarrays is truthful and robust, thus it can be exploited through the integration of microarray data with RNA-Seq data. Additionally, information extraction and acquisition of large number of samples in RNA-Seq still entails very high costs in terms of time and computational resources.This paper proposes a new model to find the gene signature of breast cancer cell lines through the integration of heterogeneous data from different breast cancer datasets, obtained from microarray and RNA-Seq technologies. Consequently, data integration is expected to provide a more robust statistical significance to the results obtained. Finally, a classification method is proposed in order to test the robustness of the Differentially Expressed Genes when unseen data is presented for diagnosis. RESULTS: The proposed data integration allows analyzing gene expression samples coming from different technologies. The most significant genes of the whole integrated data were obtained through the intersection of the three gene sets, corresponding to the identified expressed genes within the microarray data itself, within the RNA-Seq data itself, and within the integrated data from both technologies. This intersection reveals 98 possible technology-independent biomarkers. Two different heterogeneous datasets were distinguished for the classification tasks: a training dataset for gene expression identification and classifier validation, and a test dataset with unseen data for testing the classifier. Both of them achieved great classification accuracies, therefore confirming the validity of the obtained set of genes as possible biomarkers for breast cancer. Through a feature selection process, a final small subset made up by six genes was considered for breast cancer diagnosis. CONCLUSIONS: This work proposes a novel data integration stage in the traditional gene expression analysis pipeline through the combination of heterogeneous data from microarrays and RNA-Seq technologies. Available samples have been successfully classified using a subset of six genes obtained by a feature selection method. Consequently, a new classification and diagnosis tool was built and its performance was validated using previously unseen samples.},
author = {Castillo, Daniel and G{\'{a}}lvez, Juan Manuel and Herrera, Luis Javier and Rom{\'{a}}n, Bel{\'{e}}n San and Rojas, Fernando and Rojas, Ignacio},
doi = {10.1186/s12859-017-1925-0},
issn = {1471-2105},
journal = {BMC Bioinformatics},
keywords = {Algorithms,Breast Neoplasms/*genetics,Breast cancer,Cancer,Classification,Cluster Analysis,Databases, Genetic,Female,Gene Expression Profiling/*methods,Gene Expression Regulation, Neoplastic,Gene expression,Humans,Integration,Microarray,Oligonucleotide Array Sequence Analysis/*methods,RNA-Seq,Random Forest,Reproducibility of Results,SVM,Sequence Analysis, RNA/*methods,k-NN},
language = {eng},
month = {nov},
number = {1},
pages = {506},
publisher = {BioMed Central},
title = {{Integration of RNA-Seq data with heterogeneous microarray data for breast cancer profiling}},
url = {https://pubmed.ncbi.nlm.nih.gov/29157215 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5697344/},
volume = {18},
year = {2017}
}
@article{Alexander-Dann2018b,
abstract = {The toxicogenomics field aims to understand and predict toxicity by using 'omics' data in order to study systems-level responses to compound treatments. In recent years there has been a rapid increase in publicly available toxicological and 'omics' data, particularly gene expression data, and a corresponding development of methods for its analysis. In this review, we summarize recent progress relating to the analysis of RNA-Seq and microarray data, review relevant databases, and highlight recent applications of toxicogenomics data for understanding and predicting compound toxicity. These include the analysis of differentially expressed genes and their enrichment, signature matching, methods based on interaction networks, and the analysis of co-expression networks. In the future, these state-of-the-art methods will likely be combined with new technologies, such as whole human body models, to produce a comprehensive systems-level understanding of toxicity that reduces the necessity of in vivo toxicity assessment in animal models.},
author = {Alexander-Dann, Benjamin and Pruteanu, Lavinia Lorena and Oerton, Erin and Sharma, Nitin and Berindan-Neagoe, Ioana and M{\'{o}}dos, Dezső and Bender, Andreas},
doi = {10.1039/c8mo00042e},
issn = {2515-4184},
journal = {Mol. Omi.},
keywords = {*Toxicogenetics/methods,Animals,Databases, Genetic,Drug Discovery,Gene Expression Profiling/methods,Gene Expression Regulation/drug effects,Gene Regulatory Networks/drug effects,Humans,Pharmacogenomic Testing,Systems Biology/methods,Toxicity Tests},
language = {eng},
month = {aug},
number = {4},
pages = {218--236},
publisher = {Royal Society of Chemistry},
title = {{Developments in toxicogenomics: understanding and predicting compound-induced toxicity from gene expression data}},
url = {https://pubmed.ncbi.nlm.nih.gov/29917034 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6080592/},
volume = {14},
year = {2018}
}
@article{Haggart2011,
abstract = {With the advent of modern high-throughput genomics, there is a significant need for  genome-scale analysis techniques that can assist in complex systems analysis. Metabolic genome-scale network reconstructions (GENREs) paired with constraint-based modeling are an efficient method to integrate genomics, transcriptomics, and proteomics to conduct organism-specific analysis. This text explains key steps in the GENRE construction process and several methods of constraint-based modeling that can help elucidate basic life processes and development of disease treatment, bioenergy solutions, and industrial bioproduction applications.},
author = {Haggart, Charles R and Bartell, Jennifer A and Saucerman, Jeffrey J and Papin, Jason A},
doi = {10.1016/B978-0-12-385118-5.00021-9},
issn = {1557-7988 (Electronic)},
journal = {Methods Enzymol.},
keywords = {Algorithms,Animals,Bayes Theorem,Computer Simulation,Databases, Genetic,Gene Expression Profiling,Genome, Human,Humans,Metabolic Networks and Pathways,Models, Biological,Systems Biology,genetics},
language = {eng},
pages = {411--433},
pmid = {21943909},
title = {{Whole-genome metabolic network reconstruction and constraint-based modeling.}},
volume = {500},
year = {2011}
}
@article{Heusinkveld2018b,
abstract = {Mode of action information is one of the key components for chemical risk assessment  as mechanistic insight leads to better understanding of potential adverse health effects of a chemical. This insight greatly facilitates assessment of human relevance and enhances the use of non-animal methods for risk assessment, as it ultimately enables extrapolation from initiating events to adverse effects. Recently, we reported an in vitro toxicogenomics comparison approach to categorize (non-)genotoxic carcinogens according to similarities in their proposed modes of action. The present study aimed to make this comparison approach generally applicable, allowing comparison of outcomes across different studies. The resulting further developed comparison approach was evaluated through application to toxicogenomics data on 18 liver toxicants in human and rat primary hepatocytes from the Open TG-GATEs database. The results showed sensible matches between compounds with (partial) overlap in mode of action, whilst matches for compounds with different modes of action were absent. Comparison of the results across species revealed pronounced and relevant differences between primary rat and human hepatocytes, underpinning that information on mode of action enhances assessment of human relevance. Thus, we demonstrate that the comparison approach now is generally applicable, facilitating its use as tool in mechanism-based risk assessment.},
author = {Heusinkveld, Harm J and Wackers, Paul F K and Schoonen, Willem G and van der Ven, Leo and Pennings, Jeroen L A and Luijten, Mirjam},
doi = {10.1016/j.fct.2018.08.007},
issn = {1873-6351 (Electronic)},
journal = {Food Chem. Toxicol.  an Int. J. Publ. Br.  Ind. Biol. Res. Assoc.},
keywords = {Animals,Cells, Cultured,Chemical and Drug Induced Liver Injury,Databases, Factual,Drug-Related Side Effects and Adverse Reactions,Gene Expression Profiling,Hepatocytes,Humans,Rats,Risk Assessment,Toxicogenetics,Transcriptome,drug effects,genetics,methods},
language = {eng},
month = {nov},
pages = {115--123},
pmid = {30096367},
title = {{Application of the comparison approach to open TG-GATEs: A useful toxicogenomics  tool for detecting modes of action in chemical risk assessment.}},
volume = {121},
year = {2018}
}
@article{Dhawan2019,
abstract = {With the increased use of next-generation sequencing generating large amounts of  genomic data, gene expression signatures are becoming critically important tools for the interpretation of these data, and are poised to have a substantial effect on diagnosis, management, and prognosis for a number of diseases. It is becoming crucial to establish whether the expression patterns and statistical properties of sets of genes, or gene signatures, are conserved across independent datasets. Conversely, it is necessary to compare established signatures on the same dataset to better understand how they capture different clinical or biological characteristics. Here we describe how to use sigQC, a tool that enables a streamlined, systematic approach for the evaluation of previously obtained gene signatures across multiple gene expression datasets. We implemented sigQC in an R package, making it accessible to users who have knowledge of file input/output and matrix manipulation in R and a moderate grasp of core statistical principles. SigQC has been adopted in basic biology and translational studies, including, but not limited to, the evaluation of multiple gene signatures for potential clinical use as cancer biomarkers. This protocol uses a previously obtained signature for breast cancer metastasis as an example to illustrate the critical quality control steps involved in evaluating its expression, variability, and structure in breast tumor RNA-sequencing data, a different dataset from that in which the signature was originally derived. We demonstrate how the outputs created from sigQC can be used for the evaluation of gene signatures on large-scale gene expression datasets.},
author = {Dhawan, Andrew and Barberis, Alessandro and Cheng, Wei-Chen and Domingo, Enric and West, Catharine and Maughan, Tim and Scott, Jacob G and Harris, Adrian L and Buffa, Francesca M},
doi = {10.1038/s41596-019-0136-8},
issn = {1750-2799 (Electronic)},
journal = {Nat. Protoc.},
keywords = {Biomarkers, Tumor,Databases, Genetic,Gene Expression Profiling,Genomics,High-Throughput Nucleotide Sequencing,Humans,Sequence Analysis, DNA,Software,genetics,methods},
language = {eng},
month = {may},
number = {5},
pages = {1377--1400},
pmid = {30971781},
title = {{Guidelines for using sigQC for systematic evaluation of gene signatures.}},
volume = {14},
year = {2019}
}
@article{Zhang2018b,
abstract = {Toxic substances in the environment generate adverse effects at all levels of biological organization from the molecular level to community and ecosystem. Given this complexity, it is not surprising that ecotoxicologists have struggled to address the full consequences of toxic substance release at ecosystem level, due to the limits of observational and experimental tools to reveal the changes in deep structure at different levels of organization. -Omics technologies, consisting of genomics and ecogenomics, have the power to reveal, in unprecedented detail, the cellular processes of an individual or biodiversity of a community in response to environmental change with high sample/observation throughput. This represents a historic opportunity to transform the way we study toxic substances in ecosystems, through direct linkage of ecological effects with the systems biology of organisms. Three recent examples of -omics advance in the assessment of toxic substances are explored here: (1) the use of functional genomics in the discovery of novel molecular mechanisms of toxicity of chemicals in the environment; (2) the development of laboratory pipelines of dose-dependent, reduced transcriptomics to support high-throughput chemical testing at the biological pathway level; and (3) the use of eDNA metabarcoding approaches for assessing chemical effects on biological communities in mesocosm experiments and through direct observation in field monitoring. -Omics advances in ecotoxicological studies not only generate new knowledge regarding mechanisms of toxicity and environmental effect, improving the relevance and immediacy of laboratory toxicological assessment, but can provide a wholly new paradigm for ecotoxicology by linking ecological models to mechanism-based, systems biology approaches.},
author = {Zhang, Xiaowei and Xia, Pu and Wang, Pingping and Yang, Jianghu and Baird, Donald J.},
doi = {10.1021/acs.est.7b06494},
file = {:C$\backslash$:/Users/louison.fresnais/Downloads/2018{\_}Omics advances in ecotoxicology.pdf:pdf},
issn = {15205851},
journal = {Environ. Sci. Technol.},
number = {7},
pages = {3842--3851},
pmid = {29481739},
title = {{Omics Advances in Ecotoxicology}},
volume = {52},
year = {2018}
}
@article{Hyduke2013,
abstract = {Over the past decade a massive amount of research has been dedicated to generating omics data to gain insight into a variety of biological phenomena, including cancer, obesity, biofuel production, and infection. Although most of these omics data are available publicly, there is a growing concern that much of these data sit in databases without being used or fully analyzed. Statistical inference methods have been widely applied to gain insight into which genes may influence the activities of others in a given omics data set, however, they do not provide information on the underlying mechanisms or whether the interactions are direct or distal. Biochemically, genetically, and genomically consistent knowledge bases are increasingly being used to extract deeper biological knowledge and understanding from these data sets than possible by inferential methods. This improvement is largely due to knowledge bases providing a validated biological context for interpreting the data.},
author = {Hyduke, Daniel R and Lewis, Nathan E and Palsson, Bernhard {\O}},
doi = {10.1039/c2mb25453k},
edition = {2012/12/18},
issn = {1742-2051},
journal = {Mol. Biosyst.},
keywords = {*Databases, Genetic,*Genomics,*Metabolism,Animals,Humans,Models, Biological},
language = {eng},
month = {feb},
number = {2},
pages = {167--174},
title = {{Analysis of omics data with genome-scale models of metabolism}},
url = {https://pubmed.ncbi.nlm.nih.gov/23247105 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3594511/},
volume = {9},
year = {2013}
}
@article{Benedetti2020,
abstract = {{\textless}p{\textgreater}Correlation networks are frequently used to statistically extract biological interactions between omics markers. Network edge selection is typically based on the statistical significance of the correlation coefficients. This procedure, however, is not guaranteed to capture biological mechanisms. We here propose an alternative approach for network reconstruction: a cutoff selection algorithm that maximizes the overlap of the inferred network with available prior knowledge. We first evaluate the approach on IgG glycomics data, for which the biochemical pathway is known and well-characterized. Importantly, even in the case of incomplete or incorrect prior knowledge, the optimal network is close to the true optimum. We then demonstrate the generalizability of the approach with applications to untargeted metabolomics and transcriptomics data. For the transcriptomics case, we demonstrate that the optimized network is superior to statistical networks in systematically retrieving interactions that were not included in the biological reference used for optimization.{\textless}/p{\textgreater}},
author = {Benedetti, Elisa and Pu{\v{c}}i{\'{c}}-Bakovi{\'{c}}, Maja and Keser, Toma and Gerstner, Nathalie and B{\"{u}}y{\"{u}}k{\"{o}}zkan, Mustafa and {\v{S}}tambuk, Tamara and Selman, Maurice H J and Rudan, Igor and Pola{\v{s}}ek, Ozren and Hayward, Caroline and Al-Amin, Hassen and Suhre, Karsten and Kastenm{\"{u}}ller, Gabi and Lauc, Gordan and Krumsiek, Jan},
doi = {10.1038/s41467-020-18675-3},
issn = {2041-1723},
journal = {Nat. Commun.},
keywords = {Biochemical reaction networks,Computational biology and bioinformatics,Computational models},
number = {1},
pages = {5153},
publisher = {Nature Publishing Group},
title = {{A strategy to incorporate prior knowledge into correlation network cutoff selection}},
url = {http://www.nature.com/articles/s41467-020-18675-3},
volume = {11},
year = {2020}
}
@article{Mardinoglu2013,
abstract = {Abstract Altered metabolism is linked to the appearance of various human diseases and a better understanding of disease-associated metabolic changes may lead to the identification of novel prognostic biomarkers and the development of new therapies. Genome-scale metabolic models (GEMs) have been employed for studying human metabolism in a systematic manner, as well as for understanding complex human diseases. In the past decade, such metabolic models ? one of the fundamental aspects of systems biology ? have started contributing to the understanding of the mechanistic relationship between genotype and phenotype. In this review, we focus on the construction of the Human Metabolic Reaction database, the generation of healthy cell type- and cancer-specific GEMs using different procedures, and the potential applications of these developments in the study of human metabolism and in the identification of metabolic changes associated with various disorders. We further examine how in silico genome-scale reconstructions can be employed to simulate metabolic flux distributions and how high-throughput omics data can be analyzed in a context-dependent fashion. Insights yielded from this mechanistic modeling approach can be used for identifying new therapeutic agents and drug targets as well as for the discovery of novel biomarkers. Finally, recent advancements in genome-scale modeling and the future challenge of developing a model of whole-body metabolism are presented. The emergent contribution of GEMs to personalized and translational medicine is also discussed.},
annote = {https://doi.org/10.1002/biot.201200275},
author = {Mardinoglu, Adil and Gatto, Francesco and Nielsen, Jens},
doi = {https://doi.org/10.1002/biot.201200275},
issn = {1860-6768},
journal = {Biotechnol. J.},
keywords = {Genome-scale metabolic models,Human Metabolic Reaction database,Personalized medicine,Systems biology,Whole-body modeling},
month = {sep},
number = {9},
pages = {985--996},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Genome-scale modeling of human metabolism – a systems biology approach}},
url = {https://doi.org/10.1002/biot.201200275},
volume = {8},
year = {2013}
}
@article{Rawls2020,
abstract = {The kidneys are metabolically active organs with importance in several physiological tasks such as the secretion of soluble wastes into the urine and synthesizing glucose and oxidizing fatty acids for energy in fasting (non-fed) conditions. Once damaged, the metabolic capability of the kidneys becomes altered. Here, we define metabolic tasks in a computational modeling framework to capture kidney function in an update to the iRno network reconstruction of rat metabolism using literature-based evidence. To demonstrate the utility of iRno for predicting kidney function, we exposed primary rat renal proximal tubule epithelial cells to four compounds with varying levels of nephrotoxicity (acetaminophen, gentamicin, 2,3,7,8-tetrachlorodibenzodioxin, and trichloroethylene) for six and twenty-four hours, and collected transcriptomics and metabolomics data to measure the metabolic effects of compound exposure. For the transcriptomics data, we observed changes in fatty acid metabolism and amino acid metabolism, as well as changes in existing markers of kidney function such as Clu (clusterin). The iRno metabolic network reconstruction was used to predict alterations in these same pathways after integrating transcriptomics data and was able to distinguish between select compound-specific effects on the proximal tubule epithelial cells. Genome-scale metabolic network reconstructions with coupled omics data can be used to predict changes in metabolism as a step towards identifying novel metabolic biomarkers of kidney function and dysfunction.},
author = {Rawls, Kristopher D and Dougherty, Bonnie V and Vinnakota, Kalyan C and Pannala, Venkat R and Wallqvist, Anders and Kolling, Glynis L and Papin, Jason A},
doi = {https://doi.org/10.1016/j.taap.2020.115390},
issn = {0041-008X},
journal = {Toxicol. Appl. Pharmacol.},
keywords = {Kidney,Kidney Metabolism,Metabolic Modeling,Metabolomics,Nephrotoxicity,Transcriptomics},
pages = {115390},
title = {{Predicting changes in renal metabolism after compound exposure with a genome-scale metabolic model}},
url = {http://www.sciencedirect.com/science/article/pii/S0041008X20305123},
year = {2020}
}
@misc{Lee2020,
abstract = {Advances in next-generation sequencing and high-throughput techniques have enabled the generation of vast amounts of diverse omics data. These big data provide an unprecedented opportunity in biology, but impose great challenges in data integration, data mining, and knowledge discovery due to the complexity, heterogeneity, dynamics, uncertainty, and high-dimensionality inherited in the omics data. Network has been widely used to represent relations between entities in biological system, such as protein-protein interaction, gene regulation, and brain connectivity (i.e. network construction) as well as to infer novel relations given a reconstructed network (aka link prediction). Particularly, heterogeneous multi-layered network (HMLN) has proven successful in integrating diverse biological data for the representation of the hierarchy of biological system. The HMLN provides unparalleled opportunities but imposes new computational challenges on establishing causal genotype-phenotype associations and understanding environmental impact on organisms. In this review, we focus on the recent advances in developing novel computational methods for the inference of novel biological relations from the HMLN. We first discuss the properties of biological HMLN. Then we survey four categories of state-of-the-art methods (matrix factorization, random walk, knowledge graph, and deep learning). Thirdly, we demonstrate their applications to omics data integration and analysis. Finally, we outline strategies for future directions in the development of new HMLN models.},
author = {Lee, Bohyun and Zhang, Shuo and Poleksic, Aleksandar and Xie, Lei},
booktitle = {Front. Genet.  },
isbn = {1664-8021},
pages = {1381},
title = {{Heterogeneous Multi-Layered Network Model for Omics Data Integration and Analysis   }},
url = {https://www.frontiersin.org/article/10.3389/fgene.2019.01381},
volume = {10      },
year = {2020}
}
@article{Wang2012,
abstract = {BACKGROUND: Human tissues perform diverse metabolic functions. Mapping out these  tissue-specific functions in genome-scale models will advance our understanding of the metabolic basis of various physiological and pathological processes. The global knowledgebase of metabolic functions categorized for the human genome (Human Recon 1) coupled with abundant high-throughput data now makes possible the reconstruction of tissue-specific metabolic models. However, the number of available tissue-specific models remains incomplete compared with the large diversity of human tissues. RESULTS: We developed a method called metabolic Context-specificity Assessed by Deterministic Reaction Evaluation (mCADRE). mCADRE is able to infer a tissue-specific network based on gene expression data and metabolic network topology, along with evaluation of functional capabilities during model building. mCADRE produces models with similar or better functionality and achieves dramatic computational speed up over existing methods. Using our method, we reconstructed draft genome-scale metabolic models for 126 human tissue and cell types. Among these, there are models for 26 tumor tissues along with their normal counterparts, and 30 different brain tissues. We performed pathway-level analyses of this large collection of tissue-specific models and identified the eicosanoid metabolic pathway, especially reactions catalyzing the production of leukotrienes from arachidnoic acid, as potential drug targets that selectively affect tumor tissues. CONCLUSIONS: This large collection of 126 genome-scale draft metabolic models provides a useful resource for studying the metabolic basis for a variety of human diseases across many tissues. The functionality of the resulting models and the fast computational speed of the mCADRE algorithm make it a useful tool to build and update tissue-specific metabolic models.},
author = {Wang, Yuliang and Eddy, James A and Price, Nathan D},
doi = {10.1186/1752-0509-6-153},
issn = {1752-0509 (Electronic)},
journal = {BMC Syst. Biol.},
keywords = {Genomics,Humans,Metabolic Networks and Pathways,Models, Biological,Neoplasms,Organ Specificity,Time Factors,Transcriptome,genetics,metabolism,methods},
language = {eng},
month = {dec},
pages = {153},
pmid = {23234303},
title = {{Reconstruction of genome-scale metabolic models for 126 human tissues using mCADRE.}},
volume = {6},
year = {2012}
}
@article{Ekins2019,
abstract = {A variety of machine learning methods such as naive Bayesian, support vector machines and more recently deep neural networks are demonstrating their utility for drug discovery and development. These leverage the generally bigger datasets created from high-throughput screening data and allow prediction of bioactivities for targets and molecular properties with increased levels of accuracy. We have only just begun to exploit the potential of these techniques but they may already be fundamentally changing the research process for identifying new molecules and/or repurposing old drugs. The integrated application of such machine learning models for end-to-end (E2E) application is broadly relevant and has considerable implications for developing future therapies and their targeting.},
author = {Ekins, Sean and Puhl, Ana C and Zorn, Kimberley M and Lane, Thomas R and Russo, Daniel P and Klein, Jennifer J and Hickey, Anthony J and Clark, Alex M},
doi = {10.1038/s41563-019-0338-z},
issn = {1476-4660},
journal = {Nat. Mater.},
number = {5},
pages = {435--441},
title = {{Exploiting machine learning for end-to-end drug discovery and development}},
url = {https://doi.org/10.1038/s41563-019-0338-z},
volume = {18},
year = {2019}
}
@misc{Jurica2009,
author = {Jurica, Peter and {Van Leeuwen}, Cees},
booktitle = {Front. Neuroinformatics  },
isbn = {1662-5196},
pages = {5},
title = {{OMPC: an open-source MATLAB{\textregistered}-to-Python compiler   }},
url = {https://www.frontiersin.org/article/10.3389/neuro.11.005.2009},
volume = {3      },
year = {2009}
}
@article{Mulas2017,
abstract = {BACKGROUND: Methods for inference and comparison of biological networks are emerging  as powerful tools for the identification of groups of tightly connected genes whose activity may be altered during disease progression or due to chemical perturbations. Connectivity-based comparisons help identify aggregate changes that would be difficult to detect with differential analysis methods comparing individual genes. METHODS: In this study, we describe a pipeline for network comparison and its application to the analysis of gene expression datasets from chemical perturbation experiments, with the goal of elucidating the modes of actions of the profiled perturbations. We apply our pipeline to the analysis of the DrugMatrix and the TG-GATEs, two of the largest toxicogenomics resources available, containing gene expression measurements for model organisms exposed to hundreds of chemical compounds with varying carcinogenicity and genotoxicity. RESULTS: Starting from chemical-specific transcriptional networks inferred from these data, we show that the proposed comparative analysis of their associated networks identifies groups of chemicals with similar functions and similar carcinogenicity/genotoxicity profiles. We also show that the in-silico annotation by pathway enrichment analysis of the gene modules with a significant gain or loss of connectivity for specific groups of compounds can reveal molecular pathways significantly associated with the chemical perturbations and their likely modes of action. CONCLUSIONS: The proposed pipeline for transcriptional network inference and comparison is highly reproducible and allows grouping chemicals with similar functions and carcinogenicity/genotoxicity profiles. In the context of drug discovery or drug repositioning, the methods presented here could help assign new functions to novel or existing drugs, based on the similarity of their associated network with those built for other known compounds. Additionally, the method has broad applicability beyond the uses here described and could be used as an alternative or as a complement to standard approaches of differential gene expression analysis.},
author = {Mulas, Francesca and Li, Amy and Sherr, David H and Monti, Stefano},
doi = {10.1186/s12859-017-1536-9},
issn = {1471-2105 (Electronic)},
journal = {BMC Bioinformatics},
keywords = {Animals,Carcinogens,Computer Simulation,Gene Regulatory Networks,Humans,Metabolic Networks and Pathways,Mutagens,Toxicogenetics,Transcriptome,drug effects,methods,pharmacology,toxicity},
language = {eng},
month = {mar},
number = {Suppl 5},
pages = {130},
pmid = {28361664},
title = {{Network-based analysis of transcriptional profiles from chemical perturbations  experiments.}},
volume = {18},
year = {2017}
}
@article{Kim2015b,
abstract = {Undesirable toxicity is one of the main reasons for withdrawing drugs from the market or eliminating them as candidates in clinical trials. Although numerous studies have attempted to identify biomarkers capable of predicting pharmacotoxicity, few have attempted to discover robust biomarkers that are coherent across various species and experimental settings. To identify such biomarkers, we conducted meta-analyses of massive gene expression profiles for 6,567 in vivo rat samples and 453 compounds. After applying rigorous feature reduction procedures, our analyses identified 18 genes to be related with toxicity upon comparisons of untreated versus treated and innocuous versus toxic specimens of kidney, liver and heart tissue. We then independently validated these genes in human cell lines. In doing so, we found several of these genes to be coherently regulated in both in vivo rat specimens and in human cell lines. Specifically, mRNA expression of neuronal regeneration-related protein was robustly down-regulated in both liver and kidney cells, while mRNA expression of cathepsin D was commonly up-regulated in liver cells after exposure to toxic concentrations of chemical compounds. Use of these novel toxicity biomarkers may enhance the efficiency of screening for safe lead compounds in early-phase drug development prior to animal testing.},
author = {Kim, Hyosil and Kim, Ju-Hwa and Kim, So Youn and Jo, Deokyeon and Park, Ho Jun and Kim, Jihyun and Jung, Sungwon and Kim, Hyun Seok and Lee, KiYoung},
journal = {PLoS One},
month = {sep},
number = {9},
pages = {e0136698},
publisher = {Public Library of Science},
title = {{Meta-Analysis of Large-Scale Toxicogenomic Data Finds Neuronal Regeneration Related Protein and Cathepsin D to Be Novel Biomarkers of Drug-Induced Toxicity}},
url = {https://doi.org/10.1371/journal.pone.0136698},
volume = {10},
year = {2015}
}
@article{OHagan2018b,
abstract = {The expression levels of SLC or ABC membrane transporter transcripts typically  differ 100- to 10,000-fold between different tissues. The Gini coefficient characterizes such inequalities and here is used to describe the distribution of the expression of each transporter among different human tissues and cell lines. Many transporters exhibit extremely high Gini coefficients even for common substrates, indicating considerable specialization consistent with divergent evolution. The expression profiles of SLC transporters in different cell lines behave similarly, although Gini coefficients for ABC transporters tend to be larger in cell lines than in tissues, implying selection. Transporter genes are significantly more heterogeneously expressed than the members of most non-transporter gene classes. Transcripts with the stablest expression have a low Gini index and often differ significantly from the "housekeeping" genes commonly used for normalization in transcriptomics/qPCR studies. PCBP1 has a low Gini coefficient, is reasonably expressed, and is an excellent novel reference gene. The approach, referred to as GeneGini, provides rapid and simple characterization of expression-profile distributions and improved normalization of genome-wide expression-profiling data.},
author = {O'Hagan, Steve and {Wright Muelas}, Marina and Day, Philip J and Lundberg, Emma and Kell, Douglas B},
doi = {10.1016/j.cels.2018.01.003},
issn = {2405-4712 (Print)},
journal = {Cell Syst.},
keywords = {ATP-Binding Cassette Transporters,Algorithms,Computational Biology,Databases, Genetic,Gene Expression Profiling,Genes, Essential,Genes, Regulator,Humans,Membrane Transport Proteins,Sequence Analysis,Software,Transcriptome,genetics,methods},
language = {eng},
month = {feb},
number = {2},
pages = {230--244.e1},
pmid = {29428416},
title = {{GeneGini: Assessment via the Gini Coefficient of Reference "Housekeeping" Genes and  Diverse Human Transporter Expression Profiles.}},
volume = {6},
year = {2018}
}
@article{Chen2011b,
address = {Division of Systems Biology, National Center for Toxicological Research, Food and Drug Administration, 3900 NCTR Road, Jefferson, AR 72079, USA.},
author = {Chen, Minjun and Vijay, Vikrant and Shi, Qiang and Liu, Zhichao and Fang, Hong and Tong, Weida},
doi = {10.1016/j.drudis.2011.05.007},
issn = {1359-6446},
journal = {Drug Discov. Today},
keywords = {Drug Labeling,Drug-Related Side Effects and Adverse Reactions},
language = {eng},
number = {15-16},
pages = {697--703},
title = {{FDA-approved drug labeling for the study of drug-induced liver injury}},
url = {http://europepmc.org/abstract/MED/21624500 https://doi.org/10.1016/j.drudis.2011.05.007},
volume = {16},
year = {2011}
}
@article{Thiele2010b,
abstract = {Network reconstructions are a common denominator in systems biology. Bottom-up metabolic network reconstructions have been developed over the last 10 years. These reconstructions represent structured knowledge bases that abstract pertinent information on the biochemical transformations taking place within specific target organisms. The conversion of a reconstruction into a mathematical format facilitates a myriad of computational biological studies, including evaluation of network content, hypothesis testing and generation, analysis of phenotypic characteristics and metabolic engineering. To date, genome-scale metabolic reconstructions for more than 30 organisms have been published and this number is expected to increase rapidly. However, these reconstructions differ in quality and coverage that may minimize their predictive potential and use as knowledge bases. Here we present a comprehensive protocol describing each step necessary to build a high-quality genome-scale metabolic reconstruction, as well as the common trials and tribulations. Therefore, this protocol provides a helpful manual for all stages of the reconstruction process.},
author = {Thiele, Ines and Palsson, Bernhard {\O}},
doi = {10.1038/nprot.2009.203},
edition = {2010/01/07},
issn = {1750-2799},
journal = {Nat. Protoc.},
keywords = {Biomass,Computer Simulation,Gene Expression Profiling,Gene Expression Regulation,Genome,Metabolome/*genetics,Software},
language = {eng},
month = {jan},
number = {1},
pages = {93--121},
title = {{A protocol for generating a high-quality genome-scale metabolic reconstruction}},
url = {https://pubmed.ncbi.nlm.nih.gov/20057383 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3125167/},
volume = {5},
year = {2010}
}
@article{Lim2019b,
abstract = {The Connectivity Map (CMap) is a popular resource designed for data-driven drug repositioning using a large transcriptomic compendium. However, evaluations of its performance are limited. We used two iterations of CMap (CMap 1 and 2) to assess their comparability and reliability. We queried CMap 2 with CMap 1-derived signatures, expecting CMap 2 would highly prioritize the queried compounds; success rate was 17{\%}. Analysis of previously published prioritizations yielded similar results. Low recall is caused by low differential expression (DE) reproducibility both between CMaps and within each CMap. DE strength was predictive of reproducibility, and is influenced by compound concentration and cell-line responsiveness. Reproducibility of CMap 2 sample expression levels was also lower than expected. We attempted to identify the “better” CMap by comparison with a third dataset, but they were mutually discordant. Our findings have implications for CMap usage and we suggest steps for investigators to limit false positives.},
author = {Lim, Nathaniel and Pavlidis, Paul},
doi = {10.1101/845693},
journal = {bioRxiv},
month = {jan},
pages = {845693},
title = {{Evaluation of Connectivity Map shows limited reproducibility in drug repositioning}},
url = {http://biorxiv.org/content/early/2019/11/17/845693.abstract},
year = {2019}
}
@article{Becker2008,
abstract = {Author SummarySystems biology aims to characterize cells and organisms as systems through the careful curation of all components. Large models that account for all known metabolism in microorganisms have been created by our group and by others around the world. Furthermore, models are available for human cells. These models represent all possible biochemical reactions in a cell, but cells choose which subset of reactions to use to suit their immediate purposes. We have developed a method to combine widely available gene expression data with presupposed cellular functions to predict the subset of reactions that a cell uses under particular conditions. We quantify the consistency of subsets of reactions with existing biological knowledge to demonstrate that the method produces biologically realistic subsets of reactions. This method is useful for determining the activity of metabolic reactions in Escherichia coli and will be essential for understanding human cellular metabolism.},
author = {Becker, Scott A and Palsson, Bernhard O},
journal = {PLOS Comput. Biol.},
month = {may},
number = {5},
pages = {e1000082},
publisher = {Public Library of Science},
title = {{Context-Specific Metabolic Networks Are Consistent with Experiments}},
url = {https://doi.org/10.1371/journal.pcbi.1000082},
volume = {4},
year = {2008}
}
@article{Tefagh2020,
abstract = {High-throughput omics technologies have enabled the comprehensive reconstructions of genome-scale metabolic networks for many organisms. However, only a subset of reactions is active in each cell which differs from tissue to tissue or from patient to patient. Reconstructing a subnetwork of the generic metabolic network from a provided set of context-specific active reactions is a demanding computational task.},
author = {Tefagh, Mojtaba and Boyd, Stephen P},
doi = {10.1186/s12859-020-3440-y},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {1},
pages = {140},
title = {{SWIFTCORE: a tool for the context-specific reconstruction of genome-scale metabolic networks}},
url = {https://doi.org/10.1186/s12859-020-3440-y},
volume = {21},
year = {2020}
}
@article{Bordbar2012,
abstract = {Abstract.? Bordbar A, Palsson BO (University of California San Diego, La Jolla, CA, USA). Using the reconstructed genome-scale human metabolic network to study physiology and pathology (Key Symposium). J Intern Med 2012; 271: 131?141. Metabolism plays a key role in many major human diseases. Generation of high-throughput omics data has ushered in a new era of systems biology. Genome-scale metabolic network reconstructions provide a platform to interpret omics data in a biochemically meaningful manner. The release of the global human metabolic network, Recon 1, in 2007 has enabled new systems biology approaches to study human physiology, pathology and pharmacology. There are currently more than 20 publications that utilize Recon 1, including studies of cancer, diabetes, host?pathogen interactions, heritable metabolic disorders and off-target drug binding effects. In this mini-review, we focus on the reconstruction of the global human metabolic network and four classes of its application. We show that computational simulations for numerous pathologies have yielded clinically relevant results, many corroborated by existing or newly generated experimental data.},
annote = {doi: 10.1111/j.1365-2796.2011.02494.x},
author = {Bordbar, A and Palsson, B O},
doi = {10.1111/j.1365-2796.2011.02494.x},
issn = {0954-6820},
journal = {J. Intern. Med.},
keywords = {constraints-based modelling,human metabolism,systems biology},
month = {feb},
number = {2},
pages = {131--141},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Using the reconstructed genome-scale human metabolic network to study physiology and pathology}},
url = {https://doi.org/10.1111/j.1365-2796.2011.02494.x},
volume = {271},
year = {2012}
}
@article{Alonso-Betanzos2019b,
abstract = {The advent of DNA microarray datasets has stimulated a new line of research both in  bioinformatics and in machine learning. This type of data is used to collect information from tissue and cell samples regarding gene expression differences that could be useful for disease diagnosis or for distinguishing specific types of tumor. Microarray data classification is a difficult challenge for machine learning researchers due to its high number of features and the small sample sizes. This chapter is devoted to reviewing the microarray databases most frequently used in the literature. We also make the interested reader aware of the problematic of data characteristics in this domain, such as the imbalance of the data, their complexity, and the so-called dataset shift.},
author = {Alonso-Betanzos, Amparo and Bol{\'{o}}n-Canedo, Ver{\'{o}}nica and Mor{\'{a}}n-Fern{\'{a}}ndez, Laura and S{\'{a}}nchez-Maro{\~{n}}o, Noelia},
doi = {10.1007/978-1-4939-9442-7_4},
issn = {1940-6029 (Electronic)},
journal = {Methods Mol. Biol.},
keywords = {Databases, Genetic,Humans,Neoplasms,Oligonucleotide Array Sequence Analysis,Sample Size,genetics},
language = {eng},
pages = {65--85},
pmid = {31115885},
title = {{A Review of Microarray Datasets: Where to Find Them and Specific Characteristics.}},
volume = {1986},
year = {2019}
}
@article{Zilliox2007,
abstract = {The ability to measure genome-wide expression holds great promise for characterizing  cells and distinguishing diseased from normal tissues. Thus far, microarray technology has been useful only for measuring relative expression between two or more samples, which has handicapped its ability to classify tissue types. Here we present a method that can successfully predict tissue type based on data from a single hybridization. A preliminary web-tool is available online (http://rafalab.jhsph.edu/barcode/).},
author = {Zilliox, Michael J and Irizarry, Rafael A},
doi = {10.1038/nmeth1102},
issn = {1548-7091 (Print)},
journal = {Nat. Methods},
keywords = {Algorithms,Animals,Breast Neoplasms,Computational Biology,Databases, Genetic,Electronic Data Processing,Female,Gene Expression Profiling,Genome,Humans,Internet,Mice,Oligonucleotide Array Sequence Analysis,Prognosis,diagnosis,genetics,methods,statistics {\&} numerical data},
language = {eng},
month = {nov},
number = {11},
pages = {911--913},
pmid = {17906632},
title = {{A gene expression bar code for microarray data.}},
volume = {4},
year = {2007}
}
@article{Lewis2012,
abstract = {Our understanding of genotype–phenotype relationships has classically been qualitative, but recent advances are enabling us to overcome conceptual and technological barriers, leading to a quantitative understanding of these relationships. Within the framework of constraint-based modelling, the generation of quantitative relationships is facilitated by the realization that cell phenotypes are limited by physical and genetic constraints.Physical laws, such as mass conservation and thermodynamics, constrain the possible metabolic and biosynthetic transformations that can occur in nature, and genetics specify which sets of biochemical reactions have been selected through evolution. Genome sequencing and annotation have allowed the comprehensive reconstruction of microbial metabolic networks, and constraint-based reconstruction and analysis (COBRA) modelling has emerged as a set of valuable tools that allows detailed analysis of the biochemical mechanisms underlying the metabolic genotype–phenotype relationship.Network-based pathway analysis tools, such as elementary flux modes and extreme pathways analysis, delineate pathways that can perform a given metabolic function in an organism of interest. Although these methods have been difficult to use in larger metabolic networks, simplifications are now beginning to allow their use on genome-scale models.As not all pathways are used in a cell at a given time, optimization algorithms are routinely used to identify pathway use that best reflects the in vivo metabolic state. Flux balance analysis, which uses linear programing to optimize a mathematical description of the cellular objective, has been widely used to understand microbial physiology and the effects of environmental and genetic perturbations.The ability of COBRA methods to model genetic perturbations has allowed such methods to help predict antimicrobial targets and to aid in the design of strains for chemical production.Reconstructed metabolic networks are often incomplete and can have a small fraction of incorrect reactions therein. However, the integration of phenotypic screens with model simulations can provide a systematic approach to refine the models and discover new metabolic functions in an organism.COBRA methods are extending beyond metabolism, and approaches are beginning to incorporate transcription regulation, either implicitly, by constraining models with multiple 'omic data types, or explicitly, with detailed descriptions of regulatory mechanisms.The diverse range of more than 100 COBRA methods is being deployed to address many questions in microbiology. For example, several recent studies have begun to explore the roles of metabolism in community interactions, including symbiosis, competition, parasitism and evolution.},
author = {Lewis, Nathan E and Nagarajan, Harish and Palsson, Bernhard O},
doi = {10.1038/nrmicro2737},
issn = {1740-1534},
journal = {Nat. Rev. Microbiol.},
number = {4},
pages = {291--305},
title = {{Constraining the metabolic genotype–phenotype relationship using a phylogeny of in silico methods}},
url = {https://doi.org/10.1038/nrmicro2737},
volume = {10},
year = {2012}
}
@article{Yang2019d,
abstract = {Drug hepatotoxicity is the leading cause of acute liver failure (ALF) in the  developed countries. The early diagnosis and treatment are still problematic, and one important reason is the lack of reliable mechanistic biomarkers and therapeutic targets; therefore, searching for new biomarkers and therapeutic targets is urgent. Drug hepatotoxicity induces severe liver cells damage and death. Dead and damaged cells release endogenous damage-associated molecular patterns (DAMPs). Increased circulating levels of DAMPs (HMGB1, histones and DNA) can reflect the severity of drug hepatotoxicity. Elevated plasma HMGB1 concentrations can serve as early and sensitive mechanistic biomarker for clinical acetaminophen hepatotoxicity. DAMPS significantly contribute to liver injury and inhibiting the release of DAMPs ameliorates experimental hepatotoxicity. In addition, HMGB1 mediates 80{\%} of gut bacterial translocation (BT) during acetaminophen toxicity. Gut BT triggers systemic inflammation, leading to multiple organ injury and mortality. Moreover, DAMPs can trigger and extend sterile inflammation, which contributes to early phase liver injury but improves liver regeneration at the late phase of acetaminophen overdose, because anti-inflammatory treatment reduces liver injury at early phase but impairs liver regeneration at late phase of acetaminophen toxicity, whereas pro-inflammatory therapy improves late phase liver regeneration. DAMPs are promising mechanistic biomarkers and could also be the potential therapeutic targets for drug hepatotoxicity. DAMPs-triggered sterile inflammation contributes to liver injury at early phase but improves liver regeneration at later phase of acetaminophen hepatotoxicity; therefore, anti-inflammatory therapy would be beneficial at early phase but should be avoided at the late phase of acetaminophen overdose.},
author = {Yang, Runkuan and Tonnesseen, Tor Inge},
doi = {10.1007/s12072-018-9911-9},
issn = {1936-0541 (Electronic)},
journal = {Hepatol. Int.},
keywords = {Acetaminophen,Alarmins,Analgesics, Non-Narcotic,Biomarkers,Chemical and Drug Induced Liver Injury,Cytokines,DNA,HMGB1 Protein,Hepatitis,Histones,Humans,Kupffer Cells,Liver Failure, Acute,Liver Regeneration,adverse effects,chemically induced,diagnosis,metabolism,physiology,physiopathology},
language = {eng},
month = {jan},
number = {1},
pages = {42--50},
pmid = {30474802},
title = {{DAMPs and sterile inflammation in drug hepatotoxicity.}},
volume = {13},
year = {2019}
}
@article{Uhlen2016,
abstract = {Quantifying the differential expression of genes in various human organs, tissues,  and cell types is vital to understand human physiology and disease. Recently, several large-scale transcriptomics studies have analyzed the expression of protein-coding genes across tissues. These datasets provide a framework for defining the molecular constituents of the human body as well as for generating comprehensive lists of proteins expressed across tissues or in a tissue-restricted manner. Here, we review publicly available human transcriptome resources and discuss body-wide data from independent genome-wide transcriptome analyses of different tissues. Gene expression measurements from these independent datasets, generated using samples from fresh frozen surgical specimens and postmortem tissues, are consistent. Overall, the different genome-wide analyses support a distribution in which many proteins are found in all tissues and relatively few in a tissue-restricted manner. Moreover, we discuss the applications of publicly available omics data for building genome-scale metabolic models, used for analyzing cell and tissue functions both in physiological and in disease contexts.},
author = {Uhl{\'{e}}n, Mathias and Hallstr{\"{o}}m, Bj{\"{o}}rn M and Lindskog, Cecilia and Mardinoglu, Adil and Pont{\'{e}}n, Fredrik and Nielsen, Jens},
doi = {10.15252/msb.20155865},
issn = {1744-4292 (Electronic)},
journal = {Mol. Syst. Biol.},
keywords = {Databases, Genetic,Gene Expression,Gene Expression Profiling,Genome-Wide Association Study,Humans,Models, Biological,Organ Specificity,Sequence Analysis, RNA,methods},
language = {eng},
month = {apr},
number = {4},
pages = {862},
pmid = {27044256},
title = {{Transcriptomics resources of human tissues and organs.}},
volume = {12},
year = {2016}
}
@article{Kohonen2017b,
abstract = {Predicting unanticipated harmful effects of chemicals and drug molecules is a  difficult and costly task. Here we utilize a 'big data compacting and data fusion'-concept to capture diverse adverse outcomes on cellular and organismal levels. The approach generates from transcriptomics data set a 'predictive toxicogenomics space' (PTGS) tool composed of 1,331 genes distributed over 14 overlapping cytotoxicity-related gene space components. Involving ∼2.5 × 10(8) data points and 1,300 compounds to construct and validate the PTGS, the tool serves to: explain dose-dependent cytotoxicity effects, provide a virtual cytotoxicity probability estimate intrinsic to omics data, predict chemically-induced pathological states in liver resulting from repeated dosing of rats, and furthermore, predict human drug-induced liver injury (DILI) from hepatocyte experiments. Analysing 68 DILI-annotated drugs, the PTGS tool outperforms and complements existing tests, leading to a hereto-unseen level of DILI prediction accuracy.},
author = {Kohonen, Pekka and Parkkinen, Juuso A and Willighagen, Egon L and Ceder, Rebecca and Wennerberg, Krister and Kaski, Samuel and Grafstr{\"{o}}m, Roland C},
doi = {10.1038/ncomms15932},
issn = {2041-1723 (Electronic)},
journal = {Nat. Commun.},
keywords = {Animals,Chemical and Drug Induced Liver Injury,Gene Expression Profiling,Hepatocytes,Humans,Liver,Models, Biological,Pharmaceutical Preparations,Proteins,Rats,Toxicogenetics,analysis,drug effects,genetics,metabolism,pathology},
language = {eng},
month = {jul},
pages = {15932},
pmid = {28671182},
title = {{A transcriptomics data-driven gene space accurately predicts liver cytopathology and  drug-induced liver injury.}},
volume = {8},
year = {2017}
}
@article{Sarfraz2020b,
abstract = {Gene expression microarrays capture a complete image of all the transcriptional activity in a biological sample. Microarrays produce a large amount of data, which becomes a challenge when it comes to exploring and interpreting using modern computational and statistical tools. We propose the Microarray Analysis (MiCA) tool that outperforms other similar tools both in terms of ease of use and statistical features requiring minimal input to conduct an analysis. MiCA is an integrated, interactive, and streamlined desktop software for the analysis of microarray gene expression data. MiCA consists of a complete microarray analysis pipeline including but not limited to fetching data directly from GEO, normalization, interactive quality control, batch-effect correction, regression analysis, surrogate variable analysis and functional annotation methods such as GSVA using known existing R packages. We compare the features offered by MiCA and other similar tools while performing differential expression analysis using previously published datasets. MiCA offers additional statistical and visualization methods to conduct a microarray data analysis compared to other available microarray analysis tools. MiCA minimizes the need for technical knowledge by providing a very intuitive and versatile interface that integrates all necessary tasks and features required for basic microarray data analysis. We analyzed multiple published datasets and showed that the features offered by MiCA not only simplify the analysis pipeline but also provide additional interpretation to the data.},
author = {Sarfraz, Irzam and Asif, Muhammad and Hijazi, Kahkeshan},
doi = {https://doi.org/10.1016/j.compbiomed.2019.103561},
issn = {0010-4825},
journal = {Comput. Biol. Med.},
keywords = {Data analysis,Differential expression,Functional enrichment,Gene expression omnibus,Interactive environment,Microarray,Quality control},
pages = {103561},
title = {{MiCA: An extended tool for microarray gene expression analysis}},
url = {http://www.sciencedirect.com/science/article/pii/S0010482519304160},
volume = {116},
year = {2020}
}
@article{Jerby2012,
abstract = {The metabolism of cancer cells is reprogrammed in various ways to support their growth and survival. Studying these phenomena to develop noninvasive diagnostic tools and selective treatments is a promising avenue. Metabolic modeling has recently emerged as a new way to study human metabolism in a systematic, genome-scale manner by using pertinent high-throughput omics data. This method has been shown in various studies to provide fairly accurate estimates of the metabolic phenotype and its modifications following genetic and environmental perturbations. Here, we provide an overview of genome-scale metabolic modeling and its current use to model human metabolism in health and disease. We then describe the initial steps made using it to study cancer metabolism and how it may be harnessed to enhance ongoing experimental efforts to identify drug targets and biomarkers for cancer in a rationale-based manner. Clin Cancer Res; 18(20); 5572–84. {\textcopyright}2012 AACR.},
author = {Jerby, Livnat and Ruppin, Eytan},
doi = {10.1158/1078-0432.CCR-12-1856},
journal = {Clin. Cancer Res.},
month = {oct},
number = {20},
pages = {5572 LP  -- 5584},
title = {{Predicting Drug Targets and Biomarkers of Cancer via Genome-Scale Metabolic Modeling}},
url = {http://clincancerres.aacrjournals.org/content/18/20/5572.abstract},
volume = {18},
year = {2012}
}
@article{Blucher2019,
author = {Blucher, A S and McWeeney, S K and Stein, L and Wu, G},
doi = {10.12688/f1000research.19592.1},
journal = {F1000Research},
number = {908},
title = {{Visualization of drug target interactions in the contexts of pathways and networks with ReactomeFIViz [version 1; peer review: 3 approved]}},
url = {http://openr.es/gkq},
volume = {8},
year = {2019}
}
@article{Federico2020b,
abstract = {Preprocessing of transcriptomics data plays a pivotal role in the development of  toxicogenomics-driven tools for chemical toxicity assessment. The generation and exploitation of large volumes of molecular profiles, following an appropriate experimental design, allows the employment of toxicogenomics (TGx) approaches for a thorough characterisation of the mechanism of action (MOA) of different compounds. To date, a plethora of data preprocessing methodologies have been suggested. However, in most cases, building the optimal analytical workflow is not straightforward. A careful selection of the right tools must be carried out, since it will affect the downstream analyses and modelling approaches. Transcriptomics data preprocessing spans across multiple steps such as quality check, filtering, normalization, batch effect detection and correction. Currently, there is a lack of standard guidelines for data preprocessing in the TGx field. Defining the optimal tools and procedures to be employed in the transcriptomics data preprocessing will lead to the generation of homogeneous and unbiased data, allowing the development of more reliable, robust and accurate predictive models. In this review, we outline methods for the preprocessing of three main transcriptomic technologies including microarray, bulk RNA-Sequencing (RNA-Seq), and single cell RNA-Sequencing (scRNA-Seq). Moreover, we discuss the most common methods for the identification of differentially expressed genes and to perform a functional enrichment analysis. This review is the second part of a three-article series on Transcriptomics in Toxicogenomics.},
author = {Federico, Antonio and Serra, Angela and Ha, My Kieu and Kohonen, Pekka and Choi, Jang-Sik and Liampa, Irene and Nymark, Penny and Sanabria, Natasha and Cattelani, Luca and Fratello, Michele and Kinaret, Pia Anneli Sofia and Jagiello, Karolina and Puzyn, Tomasz and Melagraki, Georgia and Gulumian, Mary and Afantitis, Antreas and Sarimveis, Haralambos and Yoon, Tae-Hyun and Grafstr{\"{o}}m, Roland and Greco, Dario},
doi = {10.3390/nano10050903},
issn = {2079-4991 (Print)},
journal = {Nanomater. (Basel, Switzerland)},
language = {eng},
month = {may},
number = {5},
pmid = {32397130},
title = {{Transcriptomics in Toxicogenomics, Part II: Preprocessing and Differential  Expression Analysis for High Quality Data.}},
volume = {10},
year = {2020}
}
@article{Biour2010,
author = {Biour, M and Slim, Raoudha and Elouni, Bouraoui and ben salem Chaker and Chaillet, P},
doi = {10.1016/S1155-1976(10)46516-X},
journal = {EMC - H{\'{e}}patologie},
month = {jan},
pages = {1--3},
title = {{H{\'{e}}patox{\textregistered}. Pr{\'{e}}sentation du fichier bibliographique des atteintes h{\'{e}}patiques et des m{\'{e}}dicaments responsables}},
volume = {5},
year = {2010}
}
@article{Lagziel2020b,
abstract = {Cell culture media are typically selected on the basis of common laboratory practices but have major effects on the validity, reproducibility and physiological relevance of the scientific findings. We provide arguments and quantitative examples of why choosing an appropriate cell culture medium matters, particularly in metabolic studies.},
author = {Lagziel, Shoval and Gottlieb, Eyal and Shlomi, Tomer},
doi = {10.1038/s42255-020-00299-y},
issn = {2522-5812},
journal = {Nat. Metab.},
title = {{Mind your media}},
url = {https://doi.org/10.1038/s42255-020-00299-y},
year = {2020}
}
@article{Jetten2013,
abstract = {Efforts are put into developing toxicogenomics-based toxicity testing methods using in vitro human cell models for improving human risk assessment/replacing animal models. Human in vitro liver models include HepG2, HepaRG and primary human hepatocytes (PHH). Studies on comparability/applicability of these cell types mainly focus on assessing baseline biotransformation capacities/cytochrome P450-inducibility, but compound-induced gene expression profiles are at least as important. Therefore, we compared baseline and aflatoxin B1- and benzo($\alpha$)pyrene-induced gene expression profiles in HepG2, HepaRG and PHH (11-13 donors). At baseline, all liver models differ from each other with respect to whole genome gene expression levels. PHH show profound inter-individual differences, and are most similar to HepaRG. After compound exposure, induced gene expression profiles are more similar between cell models, especially for benzo($\alpha$)pyrene. Pathways involved in compound metabolism are induced in all 3 models, while others are more pronounced in a specific cell model. Examples are transcriptomic modifications of carbohydrate-related genes (HepaRG) and of receptor-related genes (PHH) after benzo($\alpha$)pyrene exposure, and of cell cycle-related genes (HepG2) after aflatoxin B1 exposure. PHH gene expression responses are the most heterogeneous. In conclusion, at base line level PHH are more similar to HepaRG than to HepG2, but for toxicogenomics applications both cell lines perform equally well in comparison to PHH.},
author = {Jetten, M J A and Kleinjans, J C S and Claessen, S M and Chesn{\'{e}}, C and van Delft, J H M},
doi = {https://doi.org/10.1016/j.tiv.2013.07.010},
issn = {0887-2333},
journal = {Toxicol. Vitr.},
keywords = {Gene expression,HepG2,HepaRG,Interindividual variability,Primary human hepatocytes},
number = {7},
pages = {2031--2040},
title = {{Baseline and genotoxic compound induced gene expression profiles in HepG2 and HepaRG compared to primary human hepatocytes}},
url = {http://www.sciencedirect.com/science/article/pii/S0887233313001884},
volume = {27},
year = {2013}
}
@article{Parsana2019b,
abstract = {Gene co-expression networks capture biological relationships between genes and are important tools in predicting gene function and understanding disease mechanisms. We show that technical and biological artifacts in gene expression data confound commonly used network reconstruction algorithms. We demonstrate theoretically, in simulation, and empirically, that principal component correction of gene expression measurements prior to network inference can reduce false discoveries. Using data from the GTEx project in multiple tissues, we show that this approach reduces false discoveries beyond correcting only for known confounders.},
author = {Parsana, Princy and Ruberman, Claire and Jaffe, Andrew E and Schatz, Michael C and Battle, Alexis and Leek, Jeffrey T},
doi = {10.1186/s13059-019-1700-9},
issn = {1474-760X},
journal = {Genome Biol.},
number = {1},
pages = {94},
title = {{Addressing confounding artifacts in reconstruction of gene co-expression networks}},
url = {https://doi.org/10.1186/s13059-019-1700-9},
volume = {20},
year = {2019}
}
@article{Joshi2020,
abstract = {Author summary Integration of transcriptomics data with genome-scale metabolic models is appealing but challenging due to the number of parametric decisions required to be made to by the user. This is further exacerbated by models failing to capture functionalities which are important for cellular maintenance. In this study, we propose a thresholding method for functionally qualifying a metabolic reaction to be active. We used our method to extract models of NCI-60 cancer cell lines, human tissues, and C. elegans cell types. We show that our thresholding method improves the coverage of functions required for cellular maintenance. We also validated and compared models built with our approach against those with existing approaches using CRISPR-Cas9 essentiality screens. Overall, our study provides novel insights into how cells may deal with context-specific and ubiquitous functions.},
author = {Joshi, Chintan J and Schinn, Song-Min and Richelle, Anne and Shamie, Isaac and O'Rourke, Eyleen J and Lewis, Nathan E},
journal = {PLOS Comput. Biol.},
month = {may},
number = {5},
pages = {e1007764},
publisher = {Public Library of Science},
title = {{StanDep: Capturing transcriptomic variability improves context-specific metabolic models}},
url = {https://doi.org/10.1371/journal.pcbi.1007764},
volume = {16},
year = {2020}
}
@misc{Sharma2017,
abstract = {The experimental methods for the prediction of molecular toxicity are tedious and time-consuming tasks. Thus, the computational approaches could be used to develop alternative methods for toxicity prediction. We have developed a tool for the prediction of molecular toxicity along with the aqueous solubility and permeability of any molecule/metabolite. Using a comprehensive and curated set of toxin molecules as a training set, the different chemical and structural based features such as descriptors and fingerprints were exploited for feature selection, optimization and development of machine learning based classification and regression models. The compositional differences in the distribution of atoms were apparent between toxins and non-toxins, and hence, the molecular features were used for the classification and regression. On 10-fold cross-validation, the descriptor-based, fingerprint-based and hybrid-based classification models showed similar accuracy (93{\%}) and Matthews's correlation coefficient (0.84). The performances of all the three models were comparable (Matthews's correlation coefficient = 0.84–0.87) on the blind dataset. In addition, the regression-based models using descriptors as input features were also compared and evaluated on the blind dataset. Random forest based regression model for the prediction of solubility performed better (R{\textless}sup{\textgreater}2{\textless}/sup{\textgreater} = 0.84) than the multi-linear regression (MLR) and partial least square regression (PLSR) models, whereas, the partial least squares based regression model for the prediction of permeability (caco-2) performed better (R{\textless}sup{\textgreater}2{\textless}/sup{\textgreater} = 0.68) in comparison to the random forest and MLR based regression models. The performance of final classification and regression models was evaluated using the two validation datasets including the known toxins and commonly used constituents of health products, which attests to its accuracy. The ToxiM web server would be a highly useful and reliable tool for the prediction of toxicity, solubility, and permeability of small molecules.},
author = {Sharma, Ashok K and Srivastava, Gopal N and Roy, Ankita and Sharma, Vineet K},
booktitle = {Front. Pharmacol.  },
isbn = {1663-9812},
pages = {880},
title = {{ToxiM: A Toxicity Prediction Tool for Small Molecules Developed Using Machine Learning and Chemoinformatics Approaches   }},
url = {https://www.frontiersin.org/article/10.3389/fphar.2017.00880},
volume = {8      },
year = {2017}
}
@article{Wu2004b,
annote = {doi: 10.1198/016214504000000683},
author = {Wu, Zhijin and Irizarry, Rafael A and Gentleman, Robert and Martinez-Murillo, Francisco and Spencer, Forrest},
doi = {10.1198/016214504000000683},
issn = {0162-1459},
journal = {J. Am. Stat. Assoc.},
month = {dec},
number = {468},
pages = {909--917},
publisher = {Taylor {\&} Francis},
title = {{A Model-Based Background Adjustment for Oligonucleotide Expression Arrays}},
url = {https://doi.org/10.1198/016214504000000683},
volume = {99},
year = {2004}
}
@article{Taboureau2020b,
abstract = {Biological systems are disturbed by several factors that are defined by the exposome. Environmental substances, including endocrine disruptors (EDs), represent the chemical exposome. These stressors may alter biological systems, that could lead to toxic health effects. Even if scientific evidence provide links between diverse environmental substances and disorders, innovative approaches, including alternative methods to animal testing, are still needed to address the complexity of the chemical mechanisms of action. Network science appears to be a valuable approach for helping to decipher a comprehensive assessment of the chemical exposome. A computational protein system-system association network (pS-SAN), based on various data sources such as chemical-protein interactions, chemical-system links, and protein-tissue associations was developed. The integrative systems toxicological model was applied to three EDs, to predict potential biological systems they may perturb. The results revealed that several systems may be disturbed by theses EDs, such as the kidney, liver and endocrine systems. The presented network-based approach highlights an opportunity to shift the paradigm of chemical risk assessment towards a better understanding of chemical toxicology mechanisms.},
author = {Taboureau, Olivier and {El M'Selmi}, Walid and Audouze, Karine},
doi = {https://doi.org/10.1016/j.taap.2020.115210},
issn = {0041-008X},
journal = {Toxicol. Appl. Pharmacol.},
keywords = {Chemical exposome,Computational model,Endocrine-disrupting chemical,Integrative systems biology,Network science,New approaches methodologies (NAMs),OBERON},
pages = {115210},
title = {{Integrative systems toxicology to predict human biological systems affected by exposure to environmental chemicals}},
url = {http://www.sciencedirect.com/science/article/pii/S0041008X20303367},
volume = {405},
year = {2020}
}
@article{Amy2021,
annote = {doi: 10.1289/EHP3986},
author = {Amy, Li and Xiaodong, Lu and Ted, Natoli and Joshua, Bittker and S., Sipes Nisha and Aravind, Subramanian and Scott, Auerbach and H., Sherr David and Stefano, Monti},
doi = {10.1289/EHP3986},
journal = {Environ. Health Perspect.},
month = {jan},
number = {4},
pages = {47002},
publisher = {Environmental Health Perspectives},
title = {{The Carcinogenome Project: In Vitro Gene Expression Profiling of Chemical Perturbations to Predict Long-Term Carcinogenicity}},
url = {https://doi.org/10.1289/EHP3986},
volume = {127},
year = {2021}
}
@misc{Smalley2010,
abstract = {Connectivity mapping is the process of establishing connections between different biological states using gene-expression profiles or signatures. There are a number of applications but in toxicology the most pertinent is for understanding mechanisms of toxicity. In its essence the process involves comparing a query gene signature generated as a result of exposure of a biological system to a chemical to those in a database that have been previously derived. In the ideal situation the query gene-expression signature is characteristic of the event and will be matched to similar events in the database. Key criteria are therefore the means of choosing the signature to be matched and the means by which the match is made. In this article we explore these concepts with examples applicable to toxicology. {\textcopyright} 2009 Elsevier Ireland Ltd. All rights reserved.},
author = {Smalley, Joshua L. and Gant, Timothy W. and Zhang, Shu Dong},
booktitle = {Toxicology},
doi = {10.1016/j.tox.2009.09.014},
issn = {0300483X},
keywords = {Connectivity mapping,Predictive toxicology,Query gene signature,Reference gene-expression profile},
month = {feb},
number = {3},
pages = {143--146},
title = {{Application of connectivity mapping in predictive toxicology based on gene-expression similarity}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0300483X09004879},
volume = {268},
year = {2010}
}
@article{Frezza2011,
abstract = {Inherited mutations in fumarate hydratase (FH), an enzyme in the tricarboxylic acid cycle — which links many of the metabolic reactions in aerobic cellular respiration — can lead to malignancies including kidney cancer. Frezza et al. now observe a metabolic pathway in FH-deficient cells that converts glutamine into bilirubin through the synthesis and degradation of haem. This renders FH-deficient cells sensitive to inhibition of haem oxygenase, a key enzyme in this pathway. Haem oxygenase might therefore be a therapeutic target in patients with tumours associated with FH loss.},
author = {Frezza, Christian and Zheng, Liang and Folger, Ori and Rajagopalan, Kartik N and MacKenzie, Elaine D and Jerby, Livnat and Micaroni, Massimo and Chaneton, Barbara and Adam, Julie and Hedley, Ann and Kalna, Gabriela and Tomlinson, Ian P M and Pollard, Patrick J and Watson, Dave G and Deberardinis, Ralph J and Shlomi, Tomer and Ruppin, Eytan and Gottlieb, Eyal},
doi = {10.1038/nature10363},
issn = {1476-4687},
journal = {Nature},
number = {7363},
pages = {225--228},
title = {{Haem oxygenase is synthetically lethal with the tumour suppressor fumarate hydratase}},
url = {https://doi.org/10.1038/nature10363},
volume = {477},
year = {2011}
}
@article{Garcia-Canaveras2016b,
abstract = {In preclinical stages of drug development, anticipating potential adverse drug effects such as toxicity is an important issue for both saving resources and preventing public health risks. Current in vitro cytotoxicity tests are restricted by their predictive potential and their ability to provide mechanistic information. This study aimed to develop a metabolomic mass spectrometry-based approach for the detection and classification of drug-induced hepatotoxicity. To this end, the metabolite profiles of human derived hepatic cells (i.e., HepG2) exposed to different well-known hepatotoxic compounds acting through different mechanisms (i.e., oxidative stress, steatosis, phospholipidosis and controls) were compared by multivariate data analysis, thus allowing us to decipher both common and mechanism-specific altered biochemical pathways. Briefly, oxidative stress damage markers were found in the three mechanisms, mainly showing altered levels of metabolites associated with glutathione and $\gamma$-glutamyl cycle. Phospholipidosis was characterized by a decreased lysophospholipids to phospholipids ratio, suggestive of phospholipid degradation inhibition. Whereas, steatosis led to impaired fatty acids $\beta$-oxidation and a subsequent increase in triacylglycerides synthesis. The characteristic metabolomic profiles were used to develop a predictive model aimed not only to discriminate between non-toxic and hepatotoxic drugs, but also to propose potential drug toxicity mechanism(s).},
author = {{Garc{\'{i}}a- Ca{\~{n}}averas}, Juan Carlos and Castell, Jos{\'{e}} V and Donato, M Teresa and Lahoz, Agust{\'{i}}n},
doi = {10.1038/srep27239},
issn = {2045-2322},
journal = {Sci. Rep.},
number = {1},
pages = {27239},
title = {{A metabolomics cell-based approach for anticipating and investigating drug-induced liver injury}},
url = {https://doi.org/10.1038/srep27239},
volume = {6},
year = {2016}
}
@article{Ryu2015,
abstract = {The impact of genome-scale human metabolic models on human systems biology and medical sciences is becoming greater, thanks to increasing volumes of model building platforms and publicly available omics data. The genome-scale human metabolic models started with Recon 1 in 2007, and have since been used to describe metabolic phenotypes of healthy and diseased human tissues and cells, and to predict therapeutic targets. Here we review recent trends in genome-scale human metabolic modeling, including various generic and tissue/cell type-specific human metabolic models developed to date, and methods, databases and platforms used to construct them. For generic human metabolic models, we pay attention to Recon 2 and HMR 2.0 with emphasis on data sources used to construct them. Draft and high-quality tissue/cell type-specific human metabolic models have been generated using these generic human metabolic models. Integration of tissue/cell type-specific omics data with the generic human metabolic models is the key step, and we discuss omics data and their integration methods to achieve this task. The initial version of the tissue/cell type-specific human metabolic models can further be computationally refined through gap filling, reaction directionality assignment and the subcellular localization of metabolic reactions. We review relevant tools for this model refinement procedure as well. Finally, we suggest the direction of further studies on reconstructing an improved human metabolic model.},
author = {Ryu, Jae Yong and Kim, Hyun Uk and Lee, Sang Yup},
doi = {10.1039/c5ib00002e},
issn = {1757-9708},
journal = {Integr. Biol.},
month = {aug},
number = {8},
pages = {859--868},
title = {{Reconstruction of genome-scale human metabolic models using omics data}},
url = {https://doi.org/10.1039/c5ib00002e},
volume = {7},
year = {2015}
}
@article{Auerbach2015b,
abstract = {Formalin-fixed, paraffin-embedded (FFPE) pathology specimens represent a potentially  vast resource for transcriptomic-based biomarker discovery. We present here a comparison of results from a whole transcriptome RNA-Seq analysis of RNA extracted from fresh frozen and FFPE livers. The samples were derived from rats exposed to aflatoxin B1 (AFB1 ) and a corresponding set of control animals. Principal components analysis indicated that samples were separated in the two groups representing presence or absence of chemical exposure, both in fresh frozen and FFPE sample types. Sixty-five percent of the differentially expressed transcripts (AFB1 vs. controls) in fresh frozen samples were also differentially expressed in FFPE samples (overlap significance: P {\textless} 0.0001). Genomic signature and gene set analysis of AFB1 differentially expressed transcript lists indicated highly similar results between fresh frozen and FFPE at the level of chemogenomic signatures (i.e., single chemical/dose/duration elicited transcriptomic signatures), mechanistic and pathology signatures, biological processes, canonical pathways and transcription factor networks. Overall, our results suggest that similar hypotheses about the biological mechanism of toxicity would be formulated from fresh frozen and FFPE samples. These results indicate that phenotypically anchored archival specimens represent a potentially informative resource for signature-based biomarker discovery and mechanistic characterization of toxicity.},
author = {Auerbach, Scott S and Phadke, Dhiral P and Mav, Deepak and Holmgren, Stephanie and Gao, Yuan and Xie, Bin and Shin, Joo Heon and Shah, Ruchir R and Merrick, B Alex and Tice, Raymond R},
doi = {10.1002/jat.3068},
issn = {1099-1263 (Electronic)},
journal = {J. Appl. Toxicol.},
keywords = {Aflatoxin B1,Animals,Biomarkers, Pharmacological,Formaldehyde,Freezing,Gene Expression Profiling,Gene Expression Regulation,Liver,Male,Rats,Rats, Inbred F344,Sequence Analysis, RNA,Toxicogenetics,analysis,drug effects,methods,pathology,toxicity},
language = {eng},
month = {jul},
number = {7},
pages = {766--780},
pmid = {25378103},
title = {{RNA-Seq-based toxicogenomic assessment of fresh frozen and formalin-fixed tissues  yields similar mechanistic insights.}},
volume = {35},
year = {2015}
}
@article{Swainston2016,
abstract = {INTRODUCTION: The human genome-scale metabolic reconstruction details all known  metabolic reactions occurring in humans, and thereby holds substantial promise for studying complex diseases and phenotypes. Capturing the whole human metabolic reconstruction is an on-going task and since the last community effort generated a consensus reconstruction, several updates have been developed. OBJECTIVES: We report a new consensus version, Recon 2.2, which integrates various alternative versions with significant additional updates. In addition to re-establishing a consensus reconstruction, further key objectives included providing more comprehensive annotation of metabolites and genes, ensuring full mass and charge balance in all reactions, and developing a model that correctly predicts ATP production on a range of carbon sources. METHODS: Recon 2.2 has been developed through a combination of manual curation and automated error checking. Specific and significant manual updates include a respecification of fatty acid metabolism, oxidative phosphorylation and a coupling of the electron transport chain to ATP synthase activity. All metabolites have definitive chemical formulae and charges specified, and these are used to ensure full mass and charge reaction balancing through an automated linear programming approach. Additionally, improved integration with transcriptomics and proteomics data has been facilitated with the updated curation of relationships between genes, proteins and reactions. RESULTS: Recon 2.2 now represents the most predictive model of human metabolism to date as demonstrated here. Extensive manual curation has increased the reconstruction size to 5324 metabolites, 7785 reactions and 1675 associated genes, which now are mapped to a single standard. The focus upon mass and charge balancing of all reactions, along with better representation of energy generation, has produced a flux model that correctly predicts ATP yield on different carbon sources. CONCLUSION: Through these updates we have achieved the most complete and best annotated consensus human metabolic reconstruction available, thereby increasing the ability of this resource to provide novel insights into normal and disease states in human. The model is freely available from the Biomodels database (http://identifiers.org/biomodels.db/MODEL1603150001).},
author = {Swainston, Neil and Smallbone, Kieran and Hefzi, Hooman and Dobson, Paul D and Brewer, Judy and Hanscho, Michael and Zielinski, Daniel C and Ang, Kok Siong and Gardiner, Natalie J and Gutierrez, Jahir M and Kyriakopoulos, Sarantos and Lakshmanan, Meiyappan and Li, Shangzhong and Liu, Joanne K and Mart{\'{i}}nez, Veronica S and Orellana, Camila A and Quek, Lake-Ee and Thomas, Alex and Zanghellini, Juergen and Borth, Nicole and Lee, Dong-Yup and Nielsen, Lars K and Kell, Douglas B and Lewis, Nathan E and Mendes, Pedro},
doi = {10.1007/s11306-016-1051-4},
issn = {1573-3882 (Print)},
journal = {Metabolomics},
language = {eng},
pages = {109},
pmid = {27358602},
title = {{Recon 2.2: from reconstruction to model of human metabolism.}},
volume = {12},
year = {2016}
}
@incollection{Chalancon2013,
address = {New York, NY},
author = {Chalancon, Guilhem and Kruse, Kai and Babu, M Madan},
doi = {10.1007/978-1-4419-9863-7_1238},
editor = {Dubitzky, Werner and Wolkenhauer, Olaf and Cho, Kwang-Hyun and Yokota, Hiroki},
isbn = {978-1-4419-9863-7},
pages = {1259--1263},
publisher = {Springer New York},
title = {{Metabolic Networks, Reconstruction BT  - Encyclopedia of Systems Biology}},
url = {https://doi.org/10.1007/978-1-4419-9863-7{\_}1238},
year = {2013}
}
@article{Gagnon-Bartsch2012b,
abstract = {Microarray expression studies suffer from the problem of batch effects and other unwanted variation. Many methods have been proposed to adjust microarray data to mitigate the problems of unwanted variation. Several of these methods rely on factor analysis to infer the unwanted variation from the data. A central problem with this approach is the difficulty in discerning the unwanted variation from the biological variation that is of interest to the researcher. We present a new method, intended for use in differential expression studies, that attempts to overcome this problem by restricting the factor analysis to negative control genes. Negative control genes are genes known a priori not to be differentially expressed with respect to the biological factor of interest. Variation in the expression levels of these genes can therefore be assumed to be unwanted variation. We name this method "Remove Unwanted Variation, 2-step" (RUV-2). We discuss various techniques for assessing the performance of an adjustment method and compare the performance of RUV-2 with that of other commonly used adjustment methods such as Combat and Surrogate Variable Analysis (SVA). We present several example studies, each concerning genes differentially expressed with respect to gender in the brain and find that RUV-2 performs as well or better than other methods. Finally, we discuss the possibility of adapting RUV-2 for use in studies not concerned with differential expression and conclude that there may be promise but substantial challenges remain.},
author = {Gagnon-Bartsch, Johann A and Speed, Terence P},
doi = {10.1093/biostatistics/kxr034},
edition = {2011/11/17},
issn = {1468-4357},
journal = {Biostatistics},
keywords = {*Data Interpretation, Statistical,Female,Gene Expression Profiling/*methods,Humans,Male,Oligonucleotide Array Sequence Analysis/*methods},
language = {eng},
month = {jul},
number = {3},
pages = {539--552},
publisher = {Oxford University Press},
title = {{Using control genes to correct for unwanted variation in microarray data}},
url = {https://pubmed.ncbi.nlm.nih.gov/22101192 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3577104/},
volume = {13},
year = {2012}
}
@misc{PPR:PPR121426,
author = {Liu, Anika and Walter, Moritz and Wright, Peter and Bartosik, Aleksandra Maria and Dolciami, Daniela and Elbasir, Abdurrahman and Yang, Hongbin and Bender, Andreas},
doi = {10.21203/rs.3.rs-16599/v1},
publisher = {Research Square},
title = {{Prediction and mechanistic analysis of Drug-Induced Liver Injury (DILI) based on chemical structure}},
url = {https://doi.org/10.21203/rs.3.rs-16599/v1},
year = {2020}
}
@article{Campos2020,
abstract = {Inflammation has been recognized as essential for restorative regeneration. Here, we  analyzed the sequential processes during onset of liver injury and subsequent regeneration based on time-resolved transcriptional regulatory networks (TRNs) to understand the relationship between inflammation, mature organ function, and regeneration. Genome-wide expression and TRN analysis were performed time dependently in mouse liver after acute injury by CCl(4) (2 h, 8 h, 1, 2, 4, 6, 8, 16 days), as well as lipopolysaccharide (LPS, 24 h) and compared to publicly available data after tunicamycin exposure (mouse, 6 h), hepatocellular carcinoma (HCC, mouse), and human chronic liver disease (non-alcoholic fatty liver, HBV infection and HCC). Spatiotemporal investigation differentiated lobular zones for signaling and transcription factor expression. Acute CCl(4) intoxication induced expression of gene clusters enriched for inflammation and stress signaling that peaked between 2 and 24 h, accompanied by a decrease of mature liver functions, particularly metabolic genes. Metabolism decreased not only in pericentral hepatocytes that underwent CCl(4)-induced necrosis, but extended to the surviving periportal hepatocytes. Proliferation and tissue restorative TRNs occurred only later reaching a maximum at 48 h. The same upstream regulators (e.g. inhibited RXR function) were implicated in increased inflammation and suppressed metabolism. The concomitant inflammation/metabolism TRN occurred similarly after acute LPS and tunicamycin challenges, in chronic mouse models and also in human liver diseases. Downregulation of metabolic genes occurs concomitantly to induce inflammation-associated genes as an early response and appears to be initiated by similar upstream regulators in acute and chronic liver diseases in humans and mice. In the acute setting, proliferation and restorative regeneration associated TRNs peak only later when metabolism is already suppressed.},
author = {Campos, Gisela and Schmidt-Heck, Wolfgang and {De Smedt}, Jonathan and Widera, Agata and Ghallab, Ahmed and P{\"{u}}tter, Larissa and Gonz{\'{a}}lez, Daniela and Edlund, Karolina and Cadenas, Cristina and Marchan, Rosemarie and Guthke, Reinhard and Verfaillie, Catherine and Hetz, Claudio and Sachinidis, Agapios and Braeuning, Albert and Schwarz, Michael and Wei{\ss}, Thomas S and Banhart, Benjamin K and Hoek, Jan and Vadigepalli, Rajanikanth and Willy, Jeffrey and Stevens, James L and Hay, David C and Hengstler, Jan G and Godoy, Patricio},
doi = {10.1007/s00204-019-02630-3},
issn = {1432-0738 (Electronic)},
journal = {Arch. Toxicol.},
language = {eng},
month = {jan},
number = {1},
pages = {205--217},
pmid = {31919559},
title = {{Inflammation-associated suppression of metabolic gene networks in acute and chronic  liver disease.}},
volume = {94},
year = {2020}
}
@article{Poupin2019,
annote = {doi: 10.1021/acs.jproteome.8b00524},
author = {Poupin, Nathalie and Corlu, Anne and Cabaton, Nicolas J and Dubois-Pot-Schneider, H{\'{e}}l{\`{e}}ne and Canlet, C{\'{e}}cile and Person, Elodie and Bruel, Sandrine and Frainay, Cl{\'{e}}ment and Vinson, Florence and Maurier, Florence and Morel, Fabrice and Robin, Marie-Anne and Fromenty, Bernard and Zalko, Daniel and Jourdan, Fabien},
doi = {10.1021/acs.jproteome.8b00524},
issn = {1535-3893},
journal = {J. Proteome Res.},
month = {jan},
number = {1},
pages = {204--216},
publisher = {American Chemical Society},
title = {{Large-Scale Modeling Approach Reveals Functional Metabolic Shifts during Hepatic Differentiation}},
url = {https://doi.org/10.1021/acs.jproteome.8b00524},
volume = {18},
year = {2019}
}
@article{Ellinger-Ziegelbauer2011,
abstract = {The InnoMed PredTox consortium was formed to evaluate whether conventional preclinical safety assessment can be significantly enhanced by incorporation of molecular profiling (“omics”) technologies. In short-term toxicological studies in rats, transcriptomics, proteomics and metabolomics data were collected and analyzed in relation to routine clinical chemistry and histopathology. Four of the sixteen hepato- and/or nephrotoxicants given to rats for 1, 3, or 14days at two dose levels induced similar histopathological effects. These were characterized by bile duct necrosis and hyperplasia and/or increased bilirubin and cholestasis, in addition to hepatocyte necrosis and regeneration, hepatocyte hypertrophy, and hepatic inflammation. Combined analysis of liver transcriptomics data from these studies revealed common gene expression changes which allowed the development of a potential sequence of events on a mechanistic level in accordance with classical endpoint observations. This included genes implicated in early stress responses, regenerative processes, inflammation with inflammatory cell immigration, fibrotic processes, and cholestasis encompassing deregulation of certain membrane transporters. Furthermore, a preliminary classification analysis using transcriptomics data suggested that prediction of cholestasis may be possible based on gene expression changes seen at earlier time-points. Targeted bile acid analysis, based on LC-MS metabonomics data demonstrating increased levels of conjugated or unconjugated bile acids in response to individual compounds, did not provide earlier detection of toxicity as compared to conventional parameters, but may allow distinction of different types of hepatobiliary toxicity. Overall, liver transcriptomics data delivered mechanistic and molecular details in addition to the classical endpoint observations which were further enhanced by targeted bile acid analysis using LC/MS metabonomics.},
author = {Ellinger-Ziegelbauer, Heidrun and Adler, Melanie and Amberg, Alexander and Brandenburg, Arnd and Callanan, John J and Connor, Susan and Fountoulakis, Michael and Gmuender, Hans and Gruhler, Albrecht and Hewitt, Philip and Hodson, Mark and Matheis, Katja A and McCarthy, Diane and Raschke, Marian and Riefke, Bj{\"{o}}rn and Schmitt, Christina S and Sieber, Max and Sposny, Alexandra and Suter, Laura and Sweatman, Brian and Mally, Angela},
doi = {https://doi.org/10.1016/j.taap.2010.09.022},
issn = {0041-008X},
journal = {Toxicol. Appl. Pharmacol.},
keywords = {Drug-induced hepatotoxicity,Liver,Metabonomics,Preclinical safety assessment,Toxicogenomics},
number = {2},
pages = {97--111},
title = {{The enhanced value of combining conventional and “omics” analyses in early assessment of drug-induced hepatobiliary injury}},
url = {http://www.sciencedirect.com/science/article/pii/S0041008X10003649},
volume = {252},
year = {2011}
}
@article{Vlassis2014,
abstract = {Author Summary Metabolism comprises all life-sustaining biochemical processes. It plays an essential role in various aspects of biology, including the development and progression of many diseases. As the metabolism of a living cell involves several thousands of small molecules and their conversion, a full analysis of such a metabolic network is only feasible using computational approaches. In addition, metabolism differs significantly from cell to cell and over different contexts. Therefore, the efficient generation of context-specific mathematical models is of high interest. We present fastcore, a fast algorithm for the reconstruction of compact context-specific metabolic network models. The algorithm takes as input a global metabolic model and a set of reactions that are known to be active in a given context, and it produces a context-specific model. fastcore is significantly faster than other algorithms, typically obtaining a genome-wide reconstruction in a few seconds. High-throughput model building will soon become a common procedure for the integration and analysis of omics data, and we foresee many future applications of fastcore in disease and patient specific metabolic modeling.},
author = {Vlassis, Nikos and Pacheco, Maria Pires and Sauter, Thomas},
journal = {PLOS Comput. Biol.},
month = {jan},
number = {1},
pages = {e1003424},
publisher = {Public Library of Science},
title = {{Fast Reconstruction of Compact Context-Specific Metabolic Network Models}},
url = {https://doi.org/10.1371/journal.pcbi.1003424},
volume = {10},
year = {2014}
}
@article{Sales2019,
abstract = {Metabolomics is an emerging ‘omics' science involving the characterization of metabolites and metabolism in biological systems. Few bioinformatic tools have been developed for the visualization, exploration and analysis of metabolomic data within the context of metabolic pathways: some of them became rapidly obsolete and are no longer supported, others are based on a single database. A systematic collection of existing annotations has the potential of considerably boosting the investigation and contextualization of metabolomic measurements.We have released a major update of our Bioconductor package graphite which explicitly tracks small molecules within pathway topologies and their interactions with proteins. The package gathers the information stored in eight major databases, oriented both at genes and at metabolites, across 14 different species. Depending on user preferences, all pathways can be retrieved as gene-only, gene metabolite or metabolite-only networks.The new graphite version (1.24) is available on Bioconductor.Supplementary data are available at Bioinformatics online.},
author = {Sales, Gabriele and Calura, Enrica and Romualdi, Chiara},
doi = {10.1093/bioinformatics/bty719},
issn = {1367-4803},
journal = {Bioinformatics},
month = {apr},
number = {7},
pages = {1258--1260},
title = {{metaGraphite–a new layer of pathway annotation to get metabolite networks}},
url = {https://doi.org/10.1093/bioinformatics/bty719},
volume = {35},
year = {2019}
}
@article{Ganter2005b,
abstract = {Successful drug discovery requires accurate decision making in order to advance the  best candidates from initial lead identification to final approval. Chemogenomics, the use of genomic tools in pharmacology and toxicology, offers a promising enhancement to traditional methods of target identification/validation, lead identification, efficacy evaluation, and toxicity assessment. To realize the value of chemogenomics information, a contextual database is needed to relate the physiological outcomes induced by diverse compounds to the gene expression patterns measured in the same animals. Massively parallel gene expression characterization coupled with traditional assessments of drug candidates provides additional, important mechanistic information, and therefore a means to increase the accuracy of critical decisions. A large-scale chemogenomics database developed from in vivo treated rats provides the context and supporting data to enhance and accelerate accurate interpretation of mechanisms of toxicity and pharmacology of chemicals and drugs. To date, approximately 600 different compounds, including more than 400 FDA approved drugs, 60 drugs approved in Europe and Japan, 25 withdrawn drugs, and 100 toxicants, have been profiled in up to 7 different tissues of rats (representing over 3200 different drug-dose-time-tissue combinations). Accomplishing this task required evaluating and improving a number of in vivo and microarray protocols, including over 80 rigorous quality control steps. The utility of pairing clinical pathology assessments with gene expression data is illustrated using three anti-neoplastic drugs: carmustine, methotrexate, and thioguanine, which had similar effects on the blood compartment, but diverse effects on hepatotoxicity. We will demonstrate that gene expression events monitored in the liver can be used to predict pathological events occurring in that tissue as well as in hematopoietic tissues.},
author = {Ganter, Brigitte and Tugendreich, Stuart and Pearson, Cecelia I and Ayanoglu, Eser and Baumhueter, Susanne and Bostian, Keith A and Brady, Lindsay and Browne, Leslie J and Calvin, John T and Day, Gwo-Jen and Breckenridge, Naiomi and Dunlea, Shane and Eynon, Barrett P and Furness, L Mike and Ferng, Joe and Fielden, Mark R and Fujimoto, Susan Y and Gong, Li and Hu, Christopher and Idury, Radha and Judo, Michael S B and Kolaja, Kyle L and Lee, May D and McSorley, Christopher and Minor, James M and Nair, Ramesh V and Natsoulis, Georges and Nguyen, Peter and Nicholson, Simone M and Pham, Hang and Roter, Alan H and Sun, Dongxu and Tan, Siqi and Thode, Silke and Tolley, Alexander M and Vladimirova, Antoaneta and Yang, Jian and Zhou, Zhiming and Jarnagin, Kurt},
doi = {10.1016/j.jbiotec.2005.03.022},
issn = {0168-1656 (Print)},
journal = {J. Biotechnol.},
keywords = {5-Aminolevulinate Synthetase,Animals,Antineoplastic Agents,Automation,Bile Ducts,Biotechnology,Carmustine,Computational Biology,Databases as Topic,Dose-Response Relationship, Drug,Down-Regulation,Drug Design,Drug Industry,Gene Expression,Humans,Hyperplasia,Liver,Male,Methotrexate,Nucleic Acid Hybridization,Oligonucleotide Array Sequence Analysis,Organ Size,Pharmacology,RNA,RNA, Complementary,Rats,Rats, Sprague-Dawley,Reticulocytes,Thioguanine,Time Factors,Tissue Distribution,Toxicology,biosynthesis,chemistry,cytology,drug effects,etiology,metabolism,methods,pathology,pharmacology,toxicity},
language = {eng},
month = {sep},
number = {3},
pages = {219--244},
pmid = {16005536},
title = {{Development of a large-scale chemogenomics database to improve drug candidate  selection and to understand mechanisms of chemical toxicity and action.}},
volume = {119},
year = {2005}
}
@article{Musa2017,
abstract = {Large-scale perturbation databases, such as Connectivity Map (CMap) or Library of Integrated Network-based Cellular Signatures (LINCS), provide enormous opportunities for computational pharmacogenomics and drug design. A reason for this is that in contrast to classical pharmacology focusing at one target at a time, the transcriptomics profiles provided by CMap and LINCS open the door for systems biology approaches on the pathway and network level. In this article, we provide a review of recent developments in computational pharmacogenomics with respect to CMap and LINCS and related applications.},
author = {Musa, Aliyu and Ghoraie, Laleh Soltan and Zhang, Shu-Dong and Glazko, Galina and Yli-Harja, Olli and Dehmer, Matthias and Haibe-Kains, Benjamin and Emmert-Streib, Frank},
doi = {10.1093/bib/bbw112},
issn = {1477-4054},
journal = {Brief. Bioinform.},
month = {jan},
number = {3},
pages = {506--523},
title = {{A review of connectivity map and computational approaches in pharmacogenomics}},
url = {https://doi.org/10.1093/bib/bbw112},
volume = {19},
year = {2017}
}
@book{FerreiraJ.VieiraV.GomesJ.CorreiaS.2020,
abstract = {The surge in high-throughput technology availability for molecular biology has enabled the development of powerful predictive tools for use in many applications, including (but not limited to) the diagnosis and treatment of human diseases such as cancer. Genome-scale metabolic models have shown some promise in clearing a path towards precise and personalized medicine, although some challenges still persist. The integration of omics data and subsequent creation of context-specific models for specific cells/tissues still poses a significant hurdle, and most current tools for this purpose have been implemented using proprietary software. Here, we present a new software tool developed in Python, troppo - Tissue-specific RecOnstruction and Phenotype Prediction using Omics data, implementing a large variety of context-specific reconstruction algorithms. Our framework and workflow are modular, which facilitates the development of newer algorithms or omics data sources.},
author = {{Correia S.}, Rocha M. Ferreira J. Vieira V. Gomes J.},
booktitle = {Adv. Intell. Syst. Comput.},
doi = {https://doi.org/10.1007/978-3-030-23873-5_18},
file = {:C$\backslash$:/Users/louison.fresnais/OneDrive - L'Or{\'{e}}al/Biblio{\_}these/a{\_}lire/practical{\_}applications{\_}of{\_}computational{\_}biology{\_}and{\_}bioinformatics{\_}13{\_}inter{\_}conf.pdf:pdf},
keywords = {Context-specific model reconstruction,Genome-scale metabolic models,Omics data integration,Tissue specific models},
title = {{Practical Applications of Computational Biology and Bioinformatics, 13th international conference}},
volume = {1005},
year = {2020}
}
@article{GonzaloSanz2019b,
abstract = {Microarray data analysis has been one of the most important hits in the interaction  between statistics and bioinformatics in the last two decades. The analysis of microarray data can be done in different ways using different tools. In this chapter a typical workflow for analyzing microarray data using R and Bioconductor packages is presented. The workflow starts with the raw data-binary files obtained from the hybridization process-and goes through a series of steps: Reading raw data, Quality Check, Normalization, Filtering, Selection of differentially expressed genes, Comparison of selected lists, and Analysis of Biological Significance. The implementation of each step in R is described through a use case that goes from raw data until the analysis of biological significance. Data and code for the analysis are provided in a github repository.},
author = {{Gonzalo Sanz}, Ricardo and S{\'{a}}nchez-Pla, Alex},
doi = {10.1007/978-1-4939-9442-7_5},
issn = {1940-6029 (Electronic)},
journal = {Methods Mol. Biol.},
keywords = {Gene Expression Profiling,Gene Expression Regulation,Models, Genetic,Oligonucleotide Array Sequence Analysis,Principal Component Analysis,Quality Control,Software,statistics {\&} numerical data},
language = {eng},
pages = {87--121},
pmid = {31115886},
title = {{Statistical Analysis of Microarray Data.}},
volume = {1986},
year = {2019}
}
@article{Smith2020b,
abstract = {The ability to confidently predict health outcomes from gene expression would catalyze a revolution in molecular diagnostics. Yet, the goal of developing actionable, robust, and reproducible predictive signatures of phenotypes such as clinical outcome has not been attained in almost any disease area. Here, we report a comprehensive analysis spanning prediction tasks from ulcerative colitis, atopic dermatitis, diabetes, to many cancer subtypes for a total of 24 binary and multiclass prediction problems and 26 survival analysis tasks. We systematically investigate the influence of gene subsets, normalization methods and prediction algorithms. Crucially, we also explore the novel use of deep representation learning methods on large transcriptomics compendia, such as GTEx and TCGA, to boost the performance of state-of-the-art methods. The resources and findings in this work should serve as both an up-to-date reference on attainable performance, and as a benchmarking resource for further research.},
author = {Smith, Aaron M and Walsh, Jonathan R and Long, John and Davis, Craig B and Henstock, Peter and Hodge, Martin R and Maciejewski, Mateusz and Mu, Xinmeng Jasmine and Ra, Stephen and Zhao, Shanrong and Ziemek, Daniel and Fisher, Charles K},
doi = {10.1186/s12859-020-3427-8},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {1},
pages = {119},
title = {{Standard machine learning approaches outperform deep representation learning on phenotype prediction from transcriptomics data}},
url = {https://doi.org/10.1186/s12859-020-3427-8},
volume = {21},
year = {2020}
}
@article{Ngom2010,
abstract = {In order to accurately measure the gene expression levels in microarray experiments, it is crucial to design unique, highly specific and highly sensitive oligonucleotide probes for the identification of biological agents such as genes in a sample. Unique probes are difficult to obtain for closely related genes such as the known strains of HIV genes. The non-unique probe selection problem is to select a probe set that is able to uniquely identify targets in a biological sample, while containing a minimal number of probes. This is an NP-hard problem. We introduce original deterministic greedy heuristics for finding near minimal non-unique probe sets. The heuristics, guided by selection functions defined over a probe set, decide at each moment which probes are the best to be included in, or excluded from, a candidate solution. Our methods substantially outperform the only two known greedy heuristics in the literature for the non-unique probe selection problem. We also obtained results that are very close to, and sometimes better than, those of the current state-of-the-art methods for the non-unique probe selection problem, namely integer linear programming and optimal cutting-plane approaches.},
author = {Ngom, Alioune and Rueda, Luis and Wang, Lili and Gras, Robin},
doi = {https://doi.org/10.1016/j.patrec.2010.04.015},
issn = {0167-8655},
journal = {Pattern Recognit. Lett.},
keywords = {Coverage,Heuristic,Microarray,Probe,Selection,Separation},
number = {14},
pages = {2113--2125},
title = {{Selection based heuristics for the non-unique oligonucleotide probe selection problem in microarray design}},
url = {https://www.sciencedirect.com/science/article/pii/S0167865510001388},
volume = {31},
year = {2010}
}
@article{Irizarry2003b,
abstract = {In this paper we report exploratory analyses of high-density oligonucleotide array  data from the Affymetrix GeneChip system with the objective of improving upon currently used measures of gene expression. Our analyses make use of three data sets: a small experimental study consisting of five MGU74A mouse GeneChip arrays, part of the data from an extensive spike-in study conducted by Gene Logic and Wyeth's Genetics Institute involving 95 HG-U95A human GeneChip arrays; and part of a dilution study conducted by Gene Logic involving 75 HG-U95A GeneChip arrays. We display some familiar features of the perfect match and mismatch probe (PM and MM) values of these data, and examine the variance-mean relationship with probe-level data from probes believed to be defective, and so delivering noise only. We explain why we need to normalize the arrays to one another using probe level intensities. We then examine the behavior of the PM and MM using spike-in data and assess three commonly used summary measures: Affymetrix's (i) average difference (AvDiff) and (ii) MAS 5.0 signal, and (iii) the Li and Wong multiplicative model-based expression index (MBEI). The exploratory data analyses of the probe level data motivate a new summary measure that is a robust multi-array average (RMA) of background-adjusted, normalized, and log-transformed PM values. We evaluate the four expression summary measures using the dilution study data, assessing their behavior in terms of bias, variance and (for MBEI and RMA) model fit. Finally, we evaluate the algorithms in terms of their ability to detect known levels of differential expression using the spike-in data. We conclude that there is no obvious downside to using RMA and attaching a standard error (SE) to this quantity using a linear model which removes probe-specific affinities.},
author = {Irizarry, Rafael A and Hobbs, Bridget and Collin, Francois and Beazer-Barclay, Yasmin D and Antonellis, Kristen J and Scherf, Uwe and Speed, Terence P},
doi = {10.1093/biostatistics/4.2.249},
issn = {1465-4644 (Print)},
journal = {Biostatistics},
keywords = {Algorithms,Animals,DNA Probes,Data Interpretation, Statistical,Gene Expression Profiling,Humans,Linear Models,Mice,Normal Distribution,Oligonucleotide Array Sequence Analysis,Reproducibility of Results,Statistics, Nonparametric,genetics,methods,statistics {\&} numerical data},
language = {eng},
month = {apr},
number = {2},
pages = {249--264},
pmid = {12925520},
title = {{Exploration, normalization, and summaries of high density oligonucleotide array  probe level data.}},
volume = {4},
year = {2003}
}
@article{Monks2018b,
abstract = {: The intracellular effects and overall efficacies of anticancer therapies can vary  significantly by tumor type. To identify patterns of drug-induced gene modulation that occur in different cancer cell types, we measured gene-expression changes across the NCI-60 cell line panel after exposure to 15 anticancer agents. The results were integrated into a combined database and set of interactive analysis tools, designated the NCI Transcriptional Pharmacodynamics Workbench (NCI TPW), that allows exploration of gene-expression modulation by molecular pathway, drug target, and association with drug sensitivity. We identified common transcriptional responses across agents and cell types and uncovered gene-expression changes associated with drug sensitivity. We also demonstrated the value of this tool for investigating clinically relevant molecular hypotheses and identifying candidate biomarkers of drug activity. The NCI TPW, publicly available at https://tpwb.nci.nih.gov, provides a comprehensive resource to facilitate understanding of tumor cell characteristics that define sensitivity to commonly used anticancer drugs. SIGNIFICANCE: The NCI Transcriptional Pharmacodynamics Workbench represents the most extensive compilation to date of directly measured longitudinal transcriptional responses to anticancer agents across a thoroughly characterized ensemble of cancer cell lines.},
author = {Monks, Anne and Zhao, Yingdong and Hose, Curtis and Hamed, Hossein and Krushkal, Julia and Fang, Jianwen and Sonkin, Dmitriy and Palmisano, Alida and Polley, Eric C and Fogli, Laura K and Konat{\'{e}}, Mariam M and Miller, Sarah B and Simpson, Melanie A and Voth, Andrea Regier and Li, Ming-Chung and Harris, Erik and Wu, Xiaolin and Connelly, John W and Rapisarda, Annamaria and Teicher, Beverly A and Simon, Richard and Doroshow, James H},
doi = {10.1158/0008-5472.CAN-18-0989},
issn = {1538-7445 (Electronic)},
journal = {Cancer Res.},
keywords = {Antineoplastic Agents,Biomarkers, Tumor,Cell Line, Tumor,Deoxycytidine,Dose-Response Relationship, Drug,Drug Screening Assays, Antitumor,Early Growth Response Protein 1,Erlotinib Hydrochloride,Gene Expression Profiling,Gene Expression Regulation, Neoplastic,Humans,Internet,National Cancer Institute (U.S.),Oligonucleotide Array Sequence Analysis,Signal Transduction,Translational Medical Research,United States,Vorinostat,analogs {\&} derivatives,drug effects,metabolism,methods,pharmacology},
language = {eng},
month = {dec},
number = {24},
pages = {6807--6817},
pmid = {30355619},
title = {{The NCI Transcriptional Pharmacodynamics Workbench: A Tool to Examine Dynamic  Expression Profiling of Therapeutic Response in the NCI-60 Cell Line Panel.}},
volume = {78},
year = {2018}
}
@misc{Okuno2009c,
abstract = {Abstract Toxicogenomics holds the promise of unprecedented advances in two broad, overlapping fields: mechanistic or investigative toxicology, and predictive toxicology. The progress of toxicogenomics has been supported by DNA microarray technology, a powerful tool for directly monitoring patterns of cellular perturbations through the identification and quantification of global shifts in gene expression resulting from pathological alterations within cells and tissues. Microarrays provide a large amount of transcriptional expression data for thousands of individual genes under various experimental conditions. Bioinformatics technologies can determine which genes are meaningful, facilitating the analysis of huge pools of toxicogenomics data in mechanistic and predictive toxicology. This chapter is devoted to computational approaches for the data mining of biomarker genes from toxicogenomics data, leading to toxicity prediction. Many algorithms have been developed for feature gene selection. Most studies on feature selection have found that wrapper methods are superior to filter methods, but many of these studies have over-emphasized prediction accuracy and over-looked the robustness of the selected genes. In fact, this study illustrates that intensity-based moderated t-statistics?support vector machine (SVM) produces more stable gene lists than recursive feature elimination?SVM. Therefore, we have to carefully gauge not only prediction performance but also the robustness of gene sets in feature gene selection.},
annote = {https://doi.org/10.1002/9780470744307.gat235},
author = {Okuno, Yasushi and Minowa, Yohsuke and Yamada, Hiroshi and Ohno, Yasuo and Urushidani, Tetsuro},
booktitle = {Gen. Appl. Syst. Toxicol.},
doi = {https://doi.org/10.1002/9780470744307.gat235},
isbn = {9780470744307},
keywords = {biomarker,feature selection,gene selection,machine learning,microarray,support vector machine,toxicogenomics},
month = {oct},
series = {Major Reference Works},
title = {{In Silico Toxicology Prediction Using Toxicogenomics Data}},
url = {https://doi.org/10.1002/9780470744307.gat235},
year = {2009}
}
@article{Vinken2012,
abstract = {Alternative methods, replacing animal testing, are urgently needed in view of the European regulatory changes in the field of cosmetic products and their ingredients. In this context, a joint research initiative called SEURAT was recently raised by the European Commission and COLIPA, representing the European cosmetics industry, with the overall goal of developing an animal-free repeated dose toxicity testing strategy for human safety assessment purposes. Although cosmetic ingredients are usually harmless for the consumer, one of the initial tasks of this research consortium included the identification of organs that could potentially be affected by cosmetic ingredients upon systemic exposure. The strategy that was followed hereof is described in the present paper and relies on the systematic evaluation, by using a self-generated electronic databank, of published reports issued by the scientific committee of DG SANCO responsible for the safety of cosmetic ingredients. By screening of the repeated dose toxicity studies present in these reports, it was found that the liver is potentially the most frequently targeted organ by cosmetic ingredients when orally administered to experimental animals, followed by the kidney and the spleen. Combined listing of altered morphological, histopathological, and biochemical parameters subsequently indicated the possible occurrence of hepatotoxicity, including steatosis and cholestasis, triggered by a limited number of cosmetic compounds. These findings are not only of relevance for the in vitro modeling efforts and choice of compounds to be tested in the SEURAT project cluster, but also demonstrate the importance of using previously generated toxicological data through an electronic databank for addressing specific questions regarding the safety evaluation of cosmetic ingredients.},
author = {Vinken, Mathieu and Pauwels, Marleen and Ates, Gamze and Vivier, Manon and Vanhaecke, Tamara and Rogiers, Vera},
doi = {10.1007/s00204-011-0769-z},
issn = {1432-0738},
journal = {Arch. Toxicol.},
number = {3},
pages = {405--412},
title = {{Screening of repeated dose toxicity data present in SCC(NF)P/SCCS safety evaluations of cosmetic ingredients}},
url = {https://doi.org/10.1007/s00204-011-0769-z},
volume = {86},
year = {2012}
}
@article{Chen2018b,
abstract = {Over the past decade, deep learning has achieved remarkable success in various artificial intelligence research areas. Evolved from the previous research on artificial neural networks, this technology has shown superior performance to other machine learning algorithms in areas such as image and voice recognition, natural language processing, among others. The first wave of applications of deep learning in pharmaceutical research has emerged in recent years, and its utility has gone beyond bioactivity predictions and has shown promise in addressing diverse problems in drug discovery. Examples will be discussed covering bioactivity prediction, de novo molecular design, synthesis prediction and biological image analysis.},
author = {Chen, Hongming and Engkvist, Ola and Wang, Yinhai and Olivecrona, Marcus and Blaschke, Thomas},
doi = {https://doi.org/10.1016/j.drudis.2018.01.039},
issn = {1359-6446},
journal = {Drug Discov. Today},
number = {6},
pages = {1241--1250},
title = {{The rise of deep learning in drug discovery}},
url = {http://www.sciencedirect.com/science/article/pii/S1359644617303598},
volume = {23},
year = {2018}
}
@article{Nystrom-Persson2017b,
abstract = {Toxygates was originally released as a user-friendly interface to enhance the accessibility of the large-scale toxicogenomics database, Open TG-GATEs, generated by the Japanese Toxicogenomics Project. Since the original release, significant new functionality has been added to enable users to perform sophisticated computational analysis with only modest bioinformatics skills. The new features include an orthologous mode for data comparison among different species, interactive clustering and heatmap visualisation, enrichment analysis of gene sets, and user data uploading. In a case study, we use these new functions to study the hepatotoxicity of peroxisome proliferator-activated receptor alpha (PPAR$\alpha$) agonist WY-14643. Our findings suggest that WY-14643 caused hypertrophy in the bile duct by intracellular Ca2+ dysregulation, which resulted in the induction of genes in a non-canonical WNT/Ca2+ signalling pathway. With this new release of Toxygates, we provide a suite of tools that allow anyone to carry out in-depth analysis of toxicogenomics in Open TG-GATEs, and of any other dataset that is uploaded.},
author = {Nystr{\"{o}}m-Persson, Johan and Natsume-Kitatani, Yayoi and Igarashi, Yoshinobu and Satoh, Daisuke and Mizuguchi, Kenji},
doi = {10.1038/s41598-017-01500-1},
issn = {2045-2322},
journal = {Sci. Rep.},
number = {1},
pages = {1390},
title = {{Interactive Toxicogenomics: Gene set discovery, clustering and analysis in Toxygates}},
url = {https://doi.org/10.1038/s41598-017-01500-1},
volume = {7},
year = {2017}
}
@article{Boutaba2018b,
abstract = {Machine Learning (ML) has been enjoying an unprecedented surge in applications that solve problems and enable automation in diverse domains. Primarily, this is due to the explosion in the availability of data, significant improvements in ML techniques, and advancement in computing capabilities. Undoubtedly, ML has been applied to various mundane and complex problems arising in network operation and management. There are various surveys on ML for specific areas in networking or for specific network technologies. This survey is original, since it jointly presents the application of diverse ML techniques in various key areas of networking across different network technologies. In this way, readers will benefit from a comprehensive discussion on the different learning paradigms and ML techniques applied to fundamental problems in networking, including traffic prediction, routing and classification, congestion control, resource and fault management, QoS and QoE management, and network security. Furthermore, this survey delineates the limitations, give insights, research challenges and future opportunities to advance ML in networking. Therefore, this is a timely contribution of the implications of ML for networking, that is pushing the barriers of autonomic network operation and management.},
author = {Boutaba, Raouf and Salahuddin, Mohammad A and Limam, Noura and Ayoubi, Sara and Shahriar, Nashid and Estrada-Solano, Felipe and Caicedo, Oscar M},
doi = {10.1186/s13174-018-0087-2},
issn = {1869-0238},
journal = {J. Internet Serv. Appl.},
number = {1},
pages = {16},
title = {{A comprehensive survey on machine learning for networking: evolution, applications and research opportunities}},
url = {https://doi.org/10.1186/s13174-018-0087-2},
volume = {9},
year = {2018}
}
@article{Zhang2019b,
abstract = {Abstract Primary Sj{\"{o}}gren's syndrome (pSS) is a chronic systemic autoimmune disease that affects exocrine glands. To study the molecular mechanism and identify crucial genes/pathways in pSS pathogenesis, the microarray-based whole-genome gene expression profiles from salivary glands of patients with pSS and non-sicca controls were retrieved. After normalization and subsequent batch effect adjustment, significance analysis of microarrays method was applied to five available datasets, and 379 differentially expressed genes (DEGs) were identified. The 300 upregulated DEGs were enriched in Gene Ontology terms of immune and inflammatory responses, including antigen processing and presentation, interferon-mediated signaling pathway, and chemotaxis. Previously reported pSS-associated genes, including HLA-DRA, TAP2, PRDM1, and IFI16, were found to be significantly upregulated. The downregulated DEGs were enriched in pathways of salivary secretion, carbohydrate digestion and absorption, and starch and sucrose metabolism, implying dysfunction of salivary glands during pathogenesis. Next, a protein-protein interaction network was constructed, and B2M, an upregulated DEG, was shown to be a hub, suggesting its potential involvement in pSS development. In summary, we found the activation of pSS-associated genes in pathogenesis, and provide clues for salivary glands dysfunction. Experimental investigation on the identified DEGs in this study will deepen our understanding on pSS.},
annote = {doi: 10.1002/jcb.29001},
author = {Zhang, Lei and Xu, Poshi and Wang, Xiaoyu and Zhang, Zongshan and Zhao, Wenxin and Li, Zhengmin and Yang, Guangxia and Liu, Panpan},
doi = {10.1002/jcb.29001},
issn = {0730-2312},
journal = {J. Cell. Biochem.},
keywords = {differentially expressed genes,gene expression microarray,meta-analysis,primary Sj{\"{o}}gren's syndrome,salivary glands},
month = {oct},
number = {10},
pages = {17368--17377},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Identification of differentially expressed genes in primary Sj{\"{o}}gren's syndrome}},
url = {https://doi.org/10.1002/jcb.29001},
volume = {120},
year = {2019}
}
@article{Taskova2018c,
abstract = {Toxicity affecting humans is studied by observing the effects of chemical substances  in animal organisms (in vivo) or in animal and human cultivated cell lines (in vitro). Toxicogenomics studies collect gene expression profiles and histopathology assessment data for hundreds of drugs and pollutants in standardized experimental designs using different model systems. These data are an invaluable source for analyzing genome-wide drug response in biological systems. However, a problem remains that is how to evaluate the suitability of heterogeneous in vitro and in vivo systems to model the many different aspects of human toxicity. We propose here that a given model system (cell type or animal organ) is supported to appropriately describe a particular aspect of human toxicity if the set of compounds associated in the literature with that aspect of toxicity causes a change in expression of genes with a particular function in the tested model system. This approach provides candidate genes to explain the toxicity effect (the differentially expressed genes) and the compounds whose effect could be modeled (the ones producing both the change of expression in the model system and that are associated with the human phenotype in the literature). Here we present an application of this approach using a computational pipeline that integrates compound-induced gene expression profiles (from the Open TG-GATEs database) and biomedical literature annotations (from the PubMed database) to evaluate the suitability of (human and rat) in vitro systems as well as rat in vivo systems to model human toxicity.},
author = {Ta{\v{s}}kova, Katerina and Fontaine, Jean-Fred and Mrowka, Ralf and Andrade-Navarro, Miguel A},
doi = {10.1016/j.ymeth.2017.07.010},
issn = {1095-9130 (Electronic)},
journal = {Methods},
keywords = {Animals,Cells, Cultured,Drug Evaluation, Preclinical,Hepatocytes,Humans,Rats,Toxicogenetics,Transcriptome,drug effects,methods,physiology},
language = {eng},
month = {jan},
pages = {57--65},
pmid = {28716510},
title = {{Evaluation of in vivo and in vitro models of toxicity by comparison of  toxicogenomics data with the literature.}},
volume = {132},
year = {2018}
}
@article{OBrien2015,
annote = {doi: 10.1016/j.cell.2015.05.019},
author = {O'Brien, Edward J. and Monk, Jonathan M. and Palsson, Bernhard O.},
doi = {10.1016/j.cell.2015.05.019},
issn = {0092-8674},
journal = {Cell},
month = {may},
number = {5},
pages = {971--987},
publisher = {Elsevier},
title = {{Using Genome-scale Models to Predict Biological Capabilities}},
url = {https://doi.org/10.1016/j.cell.2015.05.019},
volume = {161},
year = {2015}
}
@article{Machado2014,
abstract = {Author Summary Constraint-based modeling has become one of the most successful approaches for modeling large-scale biochemical networks. There are nowadays hundreds of genome-scale reconstructions of metabolic networks available for a wide variety of organisms ranging from bacteria to human cells. One of the limitations of the constraint-based approach is that it describes the cellular phenotype simply in terms of biochemical reaction rates, in a way that is disconnected from other biological processes such as genetic regulation. In order to overcome this limitation, different approaches for integration of gene expression data into constraint-based models have been developed during the past few years. However, all the methods developed so far have only been tested using isolated case studies. In this work, we elaborate a detailed survey of these methods, and perform a critical and quantitative evaluation of a selected subset of methods, using experimental datasets that include different organisms and conditions. This study highlights some of the current limitations in many of these methods, and reveals that no method published so far systematically outperforms the others.},
author = {Machado, Daniel and Herrg{\aa}rd, Markus},
journal = {PLOS Comput. Biol.},
month = {apr},
number = {4},
pages = {e1003580},
publisher = {Public Library of Science},
title = {{Systematic Evaluation of Methods for Integration of Transcriptomic Data into Constraint-Based Models of Metabolism}},
url = {https://doi.org/10.1371/journal.pcbi.1003580},
volume = {10},
year = {2014}
}
@article{Irizarry2006b,
abstract = {Motivation: In the Affymetrix GeneChip system, preprocessing occurs before one obtains expression level measurements. Because the number of competing preprocessing methods was large and growing we developed a benchmark to help users identify the best method for their application. A webtool was made available for developers to benchmark their procedures. At the time of writing over 50 methods had been submitted.Results: We benchmarked 31 probe set algorithms using a U95A dataset of spike in controls. Using this dataset, we found that background correction, one of the main steps in preprocessing, has the largest effect on performance. In particular, background correction appears to improve accuracy but, in general, worsen precision. The benchmark results put this balance in perspective. Furthermore, we have improved some of the original benchmark metrics to provide more detailed information regarding precision and accuracy. A handful of methods stand out as providing the best balance using spike-in data with the older U95A array, although different experiments on more current arrays may benchmark differently.Availability: The affycomp package, now version 1.5.2, continues to be available as part of the Bioconductor project (). The webtool continues to be available at Contact:rafa@jhu.eduSupplementary information:Supplementary data are available at Bioinformatics online.},
author = {Irizarry, Rafael A and Wu, Zhijin and Jaffee, Harris A},
doi = {10.1093/bioinformatics/btk046},
issn = {1367-4803},
journal = {Bioinformatics},
month = {apr},
number = {7},
pages = {789--794},
title = {{Comparison of Affymetrix GeneChip expression measures}},
url = {https://doi.org/10.1093/bioinformatics/btk046},
volume = {22},
year = {2006}
}
@article{Medlock2020b,
abstract = {Uncertainty in the structure and parameters of networks is ubiquitous across computational biology. In constraint-based reconstruction and analysis of metabolic networks, this uncertainty is present both during the reconstruction of networks and in simulations performed with them. Here, we present Medusa, a Python package for the generation and analysis of ensembles of genome-scale metabolic network reconstructions. Medusa builds on the COBRApy package for constraint-based reconstruction and analysis by compressing a set of models into a compact ensemble object, providing functions for the generation of ensembles using experimental data, and extending constraint-based analyses to ensemble scale. We demonstrate how Medusa can be used to generate ensembles and perform ensemble simulations, and how machine learning can be used in conjunction with Medusa to guide the curation of genome-scale metabolic network reconstructions. Medusa is available under the permissive MIT license from the Python Packaging Index (https://pypi.org) and from github (https://github.com/opencobra/Medusa), and comprehensive documentation is available at https://medusa.readthedocs.io/en/latest.},
author = {Medlock, Gregory L and Moutinho, Thomas J and Papin, Jason A},
journal = {PLOS Comput. Biol.},
month = {apr},
number = {4},
pages = {e1007847},
publisher = {Public Library of Science},
title = {{Medusa: Software to build and analyze ensembles of genome-scale metabolic network reconstructions}},
url = {https://doi.org/10.1371/journal.pcbi.1007847},
volume = {16},
year = {2020}
}
@article{Bordbar2014b,
author = {Bordbar, Aarash and Monk, Jonathan and King, Zachary and Palsson, Bernhard},
doi = {10.1038/nrg3643},
journal = {Nat. Rev. Genet.},
month = {feb},
pages = {107--120},
title = {{Constraint-based models predict metabolic and associated cellular functions}},
volume = {15},
year = {2014}
}
@article{Liu2017c,
abstract = {Preclinical animal toxicity studies may not accurately predict human toxicity. In  light of this, in vitro systems have been developed that have the potential to supplement or even replace animal use. We examined in vitro to in vivo extrapolation (IVIVE) of gene expression data obtained from The Open Japanese Toxicogenomics Project-Genomics Assisted Toxicity Evaluation System (Open TG-GATEs) for 131 compounds given to rats for 28 days, and to human or rat hepatocytes for 24 hours. Notably, a pair ranking (PRank) method was developed to assess IVIVE potential with a PRank score based on the preservation of the order of similarity rankings of compound pairs between the platforms using a receiver operating characteristic (ROC) curve analysis to measure area under the curve (AUC). A high IVIVE potential was noted for rat primary hepatocytes when compared to rat 28-day studies (PRank score = 0.71) whereas the IVIVE potential for human primary hepatocytes compared to rat 28-day studies was lower (PRank score = 0.58), indicating that species difference plays a critical role in IVIVE. When limiting the analysis to only those drugs causing drug-induced liver injury, the IVIVE potential was slightly improved both for rats (from 0.71 to 0.76) and for humans (from 0.58 to 0.62). Similarly, PRank scores were improved when the analysis focused on specific hepatotoxic endpoints such as hepatocellular injury, or cholestatic injury. In conclusion, toxicogenomic data generated in vitro yields a ranking of drugs regarding their potential to cause toxicity which is comparable to that generated by in vivo analyses.},
author = {Liu, Zhichao and Fang, Hong and Borlak, J{\"{u}}rgen and Roberts, Ruth and Tong, Weida},
doi = {10.14573/altex.1610201},
issn = {1868-596X (Print)},
journal = {ALTEX},
keywords = {Animals,Area Under Curve,Cells, Cultured,Chemical and Drug Induced Liver Injury,Hepatocytes,Humans,ROC Curve,Rats,Toxicity Tests,drug effects},
language = {eng},
number = {3},
pages = {399--407},
pmid = {28073113},
title = {{In vitro to in vivo extrapolation for drug-induced liver injury using a pair ranking  method.}},
volume = {34},
year = {2017}
}
@article{Raman2009,
abstract = {Systems level modelling and simulations of biological processes are proving to be invaluable in obtaining a quantitative and dynamic perspective of various aspects of cellular function. In particular, constraint-based analyses of metabolic networks have gained considerable popularity for simulating cellular metabolism, of which flux balance analysis (FBA), is most widely used. Unlike mechanistic simulations that depend on accurate kinetic data, which are scarcely available, FBA is based on the principle of conservation of mass in a network, which utilizes the stoichiometric matrix and a biologically relevant objective function to identify optimal reaction flux distributions. FBA has been used to analyse genome-scale reconstructions of several organisms; it has also been used to analyse the effect of perturbations, such as gene deletions or drug inhibitions in silico. This article reviews the usefulness of FBA as a tool for gaining biological insights, advances in methodology enabling integration of regulatory information and thermodynamic constraints, and finally addresses the challenges that lie ahead. Various use scenarios and biological insights obtained from FBA, and applications in fields such metabolic engineering and drug target identification, are also discussed. Genome-scale constraint-based models have an immense potential for building and testing hypotheses, as well as to guide experimentation.},
author = {Raman, Karthik and Chandra, Nagasuma},
doi = {10.1093/bib/bbp011},
issn = {1467-5463},
journal = {Brief. Bioinform.},
month = {jul},
number = {4},
pages = {435--449},
title = {{Flux balance analysis of biological systems: applications and challenges}},
url = {https://doi.org/10.1093/bib/bbp011},
volume = {10},
year = {2009}
}
@article{Misselbeck2019,
abstract = {Metabolic syndrome is a pathological condition characterized by obesity, hyperglycemia, hypertension, elevated levels of triglycerides and low levels of high-density lipoprotein cholesterol that increase cardiovascular disease risk and type 2 diabetes. Although numerous predisposing genetic risk factors have been identified, the biological mechanisms underlying this complex phenotype are not fully elucidated. Here we introduce a systems biology approach based on network analysis to investigate deregulated biological processes and subsequently identify drug repurposing candidates. A proximity score describing the interaction between drugs and pathways is defined by combining topological and functional similarities. The results of this computational framework highlight a prominent role of the immune system in metabolic syndrome and suggest a potential use of the BTK inhibitor ibrutinib as a novel pharmacological treatment. An experimental validation using a high fat diet-induced obesity model in zebrafish larvae shows the effectiveness of ibrutinib in lowering the inflammatory load due to macrophage accumulation.},
author = {Misselbeck, Karla and Parolo, Silvia and Lorenzini, Francesca and Savoca, Valeria and Leonardelli, Lorena and Bora, Pranami and Morine, Melissa J and Mione, Maria Caterina and Domenici, Enrico and Priami, Corrado},
doi = {10.1038/s41467-019-13208-z},
issn = {2041-1723},
journal = {Nat. Commun.},
number = {1},
pages = {5215},
title = {{A network-based approach to identify deregulated pathways and drug effects in metabolic syndrome}},
url = {https://doi.org/10.1038/s41467-019-13208-z},
volume = {10},
year = {2019}
}
@incollection{Svoboda2019b,
abstract = {DrugMatrixDrugMatrixand its automated toxicogenomicsToxicogenomicsreporting system, ToxFXToxFXare the scientific communities' largest molecular toxicology reference databaseDatabaseand informatics systems. DrugMatrixDrugMatrixconsists of the comprehensive results of thousands of highly controlled and standardized toxicological experiments where rats or primary rat hepatocytes were systematically treated with more than 600 therapeutic, industrial, or environmental chemicalsEnvironmental chemicalat both non-toxic and toxic doses. Following administration in vivoIn vivo, comprehensive studies of the effects of these compounds were carried out after multiple durations of exposure, and in multiple target organs. Study types included pharmacology, clinical chemistry, hematology, histology, body and organ weights, and clinical observations. Additionally, a curation team extracted all relevant information on the compounds from the literature, the Physicians' Desk Reference, package inserts, and other relevant sources. At the heart of the DrugMatrixDrugMatrixdatabaseDatabaseare thousands of gene expressionGene expressiondata sets generated by extracting RNARibonucleic acidfrom the toxicologically relevant organs and tissues and analyzing these RNAs using the GE Codelink rat array, and the Affymetrix whole-genome 230 2.0 rat GeneChip array systems. Additionally, the databaseDatabasecontains 148 scorable genomic signatures, covering 96 distinct phenotypes derive from mining the DrugMatrixDrugMatrixgene expressionGene expressiondata. The signatures are informative of organ-specific pathology (e.g., hepatic steatosis), and mode of toxicological action (e.g., PXR activation in the liver). The phenotypes cover several common target tissues in toxicity testing (liver, kidney, heart, bone marrow, spleen, and skeletal muscle). Taken as a whole, DrugMatrixDrugMatrixenables a toxicologist to formulate a comprehensive picture of toxicity with greater efficiency than traditional methods.},
address = {Cham},
author = {Svoboda, Daniel L and Saddler, Trey and Auerbach, Scott S},
doi = {10.1007/978-3-030-16443-0_8},
editor = {Hong, Huixiao},
isbn = {978-3-030-16443-0},
pages = {141--157},
publisher = {Springer International Publishing},
title = {{An Overview of National Toxicology Program's Toxicogenomic Applications: DrugMatrix and ToxFX BT  - Advances in Computational Toxicology: Methodologies and Applications in Regulatory Science}},
url = {https://doi.org/10.1007/978-3-030-16443-0{\_}8},
year = {2019}
}
@article{Josse2008,
abstract = {The human hepatoma HepaRG cells are able to differentiate in vitro into hepatocyte-like cells and to express various liver-specific functions, including the major cytochromes P450. This study was aimed to determine whether differentiated HepaRG cells retained their specific functional capacities for a long time period at confluence. We show that expression of transcripts encoding CYP1A2, 2B6, 3A4, and 2E1, several phase II and antioxidant enzymes, membrane transporters, including organic cation transporter 1 and bile salt export pump, the nuclear receptors constitutive androstane receptor and pregnane X receptor, and aldolase B remained relatively stable for at least the 4-week confluence period tested. Similarly, activities of CYP3A4 and CYP1A2 and their responsiveness to prototypical inducers were well preserved. Aflatoxin B1, a potent hepatotoxicant and carcinogen, induced a dose-dependent and cumulative cytotoxicity. Furthermore, at a concentration as low as 0.1 $\mu$M, this mycotoxin caused a decrease in both CYP3A4 activity and intracellular ATP associated with morphological alterations, after 14 days following every 2-day exposure. Moreover, using the comet assay, a dose-dependent DNA damage was observed after a 3-h treatment of differentiated HepaRG cells with 1 to 5 $\mu$M aflatoxin B1 in the absence of any cell damage, and this DNA damaging effect was strongly reduced in the presence of ketoconazole, a CYP3A4 inhibitor. These results bring the first demonstration of long-term stable expression of liver-specific markers in HepaRG hepatocyte cultures maintained at confluence and show that these cells represent a suitable in vitro liver cell model for analysis of acute and chronic toxicity as well as genotoxicity of chemicals in human liver. The American Society for Pharmacology and Experimental Therapeutics},
author = {Joss{\'{e}}, Rozenn and Aninat, Caroline and Glaise, Denise and Dumont, Julie and Fessard, Val{\'{e}}rie and Morel, Fabrice and Poul, Jean-Michel and Guguen-Guillouzo, Christiane and Guillouzo, Andr{\'{e}}},
doi = {10.1124/dmd.107.019901},
journal = {Drug Metab. Dispos.},
month = {jun},
number = {6},
pages = {1111 LP  -- 1118},
title = {{Long-Term Functional Stability of Human HepaRG Hepatocytes and Use for Chronic Toxicity and Genotoxicity Studies}},
url = {http://dmd.aspetjournals.org/content/36/6/1111.abstract},
volume = {36},
year = {2008}
}
@article{Fundel2008b,
abstract = {INTRODUCTION: Numerous methods exist for basic processing, e.g. normalization, of  microarray gene expression data. These methods have an important effect on the final analysis outcome. Therefore, it is crucial to select methods appropriate for a given dataset in order to assure the validity and reliability of expression data analysis. Furthermore, biological interpretation requires expression values for genes, which are often represented by several spots or probe sets on a microarray. How to best integrate spot/probe set values into gene values has so far been a somewhat neglected problem. RESULTS: We present a case study comparing different between-array normalization methods with respect to the identification of differentially expressed genes. Our results show that it is feasible and necessary to use prior knowledge on gene expression measurements to select an adequate normalization method for the given data. Furthermore, we provide evidence that combining spot/probe set p-values into gene p-values for detecting differentially expressed genes has advantages compared to combining expression values for spots/probe sets into gene expression values. The comparison of different methods suggests to use Stouffer's method for this purpose. The study has been conducted on gene expression experiments investigating human joint cartilage samples of osteoarthritis related groups: a cDNA microarray (83 samples, four groups) and an Affymetrix (26 samples, two groups) data set. CONCLUSION: The apparently straight forward steps of gene expression data analysis, e.g. between-array normalization and detection of differentially regulated genes, can be accomplished by numerous different methods. We analyzed multiple methods and the possible effects and thereby demonstrate the importance of the single decisions taken during data processing. We give guidelines for evaluating normalization outcomes. An overview of these effects via appropriate measures and plots compared to prior knowledge is essential for the biological interpretation of gene expression measurements.},
author = {Fundel, Katrin and K{\"{u}}ffner, Robert and Aigner, Thomas and Zimmer, Ralf},
doi = {10.4137/bbi.s441},
issn = {1177-9322 (Electronic)},
journal = {Bioinform. Biol. Insights},
language = {eng},
month = {may},
pages = {291--305},
pmid = {19812783},
title = {{Normalization and gene p-value estimation: issues in microarray data processing.}},
volume = {2},
year = {2008}
}
@article{Pepper2007b,
abstract = {Used alone, the MAS5.0 algorithm for generating expression summaries has been criticized for high False Positive rates resulting from exaggerated variance at low intensities.},
author = {Pepper, Stuart D and Saunders, Emma K and Edwards, Laura E and Wilson, Claire L and Miller, Crispin J},
doi = {10.1186/1471-2105-8-273},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {1},
pages = {273},
title = {{The utility of MAS5 expression summary and detection call algorithms}},
url = {https://doi.org/10.1186/1471-2105-8-273},
volume = {8},
year = {2007}
}
@article{Kuleshov2016,
abstract = {Enrichment analysis is a popular method for analyzing gene sets generated by genome-wide experiments. Here we present a significant update to one of the tools in this domain called Enrichr. Enrichr currently contains a large collection of diverse gene set libraries available for analysis and download. In total, Enrichr currently contains 180 184 annotated gene sets from 102 gene set libraries. New features have been added to Enrichr including the ability to submit fuzzy sets, upload BED files, improved application programming interface and visualization of the results as clustergrams. Overall, Enrichr is a comprehensive resource for curated gene sets and a search engine that accumulates biological knowledge for further biological discoveries. Enrichr is freely available at: http://amp.pharm.mssm.edu/Enrichr.},
author = {Kuleshov, Maxim V and Jones, Matthew R and Rouillard, Andrew D and Fernandez, Nicolas F and Duan, Qiaonan and Wang, Zichen and Koplev, Simon and Jenkins, Sherry L and Jagodnik, Kathleen M and Lachmann, Alexander and McDermott, Michael G and Monteiro, Caroline D and Gundersen, Gregory W and Ma'ayan, Avi},
doi = {10.1093/nar/gkw377},
issn = {0305-1048},
journal = {Nucleic Acids Res.},
month = {may},
number = {W1},
pages = {W90--W97},
title = {{Enrichr: a comprehensive gene set enrichment analysis web server 2016 update}},
url = {https://doi.org/10.1093/nar/gkw377},
volume = {44},
year = {2016}
}
@article{Mezencev2020b,
abstract = {Whole-genome expression data generated by microarray studies have shown promise for  quantitative human health risk assessment. While numerous approaches have been developed to determine benchmark doses (BMDs) from probeset-level dose responses, sensitivity of the results to methods used for normalization of the data has not yet been systematically investigated. Normalization of microarray data converts raw hybridization signals to expression estimates that are expected to be proportional to the amounts of transcripts in the profiled specimens. Different approaches to normalization have been shown to greatly influence the results of some downstream analyses, including biological interpretation. In this study we evaluate the influence of microarray normalization methods on the transcriptomic BMDs. We demonstrate using in vivo data that the use of alternative pipelines for normalization of Affymetrix microarray data can have a considerable impact on the number of detected differentially expressed genes and pathways (processes) determined to be treatment responsive, which may lead to alternative interpretations of the data. In addition, we found that normalization can have a considerable effect (as much as {\~{}}30-fold in this study) on estimation of the minimum biological potency (transcriptomic point of departure). We argue for consideration of alternative normalization methods and their data-informed selection to most effectively interpret microarray data for use in human health risk assessment.},
author = {Mezencev, Roman and Auerbach, Scott S},
doi = {10.1371/journal.pone.0232955},
issn = {1932-6203 (Electronic)},
journal = {PLoS One},
keywords = {Benchmarking,Computational Biology,Gene Expression Profiling,Genome,Humans,Nucleic Acid Hybridization,Oligonucleotide Array Sequence Analysis,Risk Assessment,Transcriptome,genetics,methods},
language = {eng},
number = {5},
pages = {e0232955},
pmid = {32413060},
title = {{The sensitivity of transcriptomics BMD modeling to the methods used for microarray  data normalization.}},
volume = {15},
year = {2020}
}
@article{Dumont2015,
abstract = {Abstract The exposure of the skin to consumer products, drugs, and environmental chemicals can result in their penetrating the skin barrier and entering systemic circulation, potentially resulting in adverse effects in the skin and other organs. The assessment of dermal penetration and bioavailability (including penetration, metabolism, and entry into the systemic circulation) is therefore an important consideration in the risk assessment of chemicals. The skin is a heterogeneous organ with a multilayer structure. Based on its architecture and physiology, substances can penetrate through three major ways but can also be blocked in the different skin layers and in the skin appendages, which act as reservoir. In addition to that, as the skin is a metabolically competent organ, substances can undergo metabolism. After a brief description of the skin architecture, this review will focus on the skin penetration mechanisms and skin metabolic capacities. The skin absorption has traditionally been tested in vivo on animals. However, with the new legislation (i.e., Registration, Evaluation, Authorisation, and Restriction of Chemicals Regulation or Cosmetics Regulation), alternatives to animal testing have to be implemented. In a second part, this review will provide a description of the main in vitro and in silico or computational models available to study skin absorption and skin metabolism (i.e., ex vivo skin models, artificial membrane barriers, primary cells and cell lines, Quantitative Structure?Activity Relationship [QSAR], simulators for the prediction of skin metabolism).},
annote = {doi: 10.1089/aivt.2015.0003},
author = {Dumont, Coralie and Prieto, Pilar and Asturiol, David and Worth, Andrew},
doi = {10.1089/aivt.2015.0003},
issn = {2332-1512},
journal = {Appl. Vitr. Toxicol.},
month = {jun},
number = {2},
pages = {147--164},
publisher = {Mary Ann Liebert, Inc., publishers},
title = {{Review of the Availability of In Vitro and In Silico Methods for Assessing Dermal Bioavailability}},
url = {https://doi.org/10.1089/aivt.2015.0003},
volume = {1},
year = {2015}
}
@article{Larriba2019b,
abstract = {Data derived from microarray technologies are generally subject to various sources  of noise and accordingly the raw data are pre-processed before formally analysed. Data normalization is a key pre-processing step when dealing with microarray experiments, such as circadian gene-expressions, since it removes systematic variations across arrays. A wide variety of normalization methods are available in the literature. However, from our experience in the study of rhythmic expression patterns in oscillatory systems (e.g. cell-cycle, circadian clock), the choice of the normalization method may substantially impair the identification of rhythmic genes. Hence, the identification of a gene as rhythmic could be just as an artefact of how the data were normalized. Yet, gene rhythmicity detection is crucial in modern toxicological and pharmacological studies, thus a procedure to truly identify rhythmic genes that are robust to the choice of a normalization method is required.To perform the task of detecting rhythmic features, we propose a rhythmicity measure based on bootstrap methodology to robustly identify rhythmic genes in oscillatory systems. Although our methodology can be extended to any high-throughput experiment, in this chapter, we illustrate how to apply it to a publicly available circadian clock microarray gene-expression data and give full details (both statistical and computational) so that the methodology can be used in an easy way. We will show that the choice of normalization method has very little effect on the proposed methodology since the results derived from the bootstrap-based rhythmicity measure are highly rank correlated for any pair of normalization methods considered. This suggests, on the one hand, that the rhythmicity measure proposed is robust to the choice of the normalization method, and on the other hand, that gene rhythmicity detected using this measure is potentially not a mere artefact of the normalization method used. In this way the researcher using this methodology will be protected against the possible effect of different normalizations, as the conclusions obtained will not depend so strongly on them. Additionally, the described bootstrap methodology can also be employed as a tool to simulate gene-expression participating in an oscillatory system from a reference data set.},
author = {Larriba, Yolanda and Rueda, Cristina and Fern{\'{a}}ndez, Miguel A and Peddada, Shyamal D},
doi = {10.1007/978-1-4939-9442-7_9},
issn = {1940-6029 (Electronic)},
journal = {Methods Mol. Biol.},
keywords = {Algorithms,Cell Line, Tumor,Gene Expression Regulation,Humans,Oligonucleotide Array Sequence Analysis,Statistics, Nonparametric,methods},
language = {eng},
pages = {207--225},
pmid = {31115890},
title = {{Microarray Data Normalization and Robust Detection of Rhythmic Features.}},
volume = {1986},
year = {2019}
}
@article{Saquib2020b,
abstract = {Nickel oxide nanoparticles (NiO-NPs) have been used in several consumer goods,  reported to demonstrate the hepatotoxic effects in vitro and in vivo test models. Nonetheless the molecular mechanism of hepatotoxicity is still missing. Hence, a toxicogenomic approach integrating microscopic techniques and high-throughput RNA sequencing (RNA-Seq) was applied to reveal hepatotoxicity in human hepatocellular carcinoma cells (HepG2). NiO-NPs induced a concentration dependent (5-100 $\mu$g/ml) cytotoxicity, with a No observed effect level (NOEL) of 5 $\mu$g/ml. Hypoxia-inducible transcription factor-1$\alpha$ (HIF-1$\alpha$) and miR-210 microRNA were upregulated at 25 and 100 $\mu$g/ml, while significant alteration on transcriptome at mRNA and pathway level was observed at non-toxic level of NiO-NPs treatment. The treated cells also showed activation of glycolysis, glutathione, lysosomes and autophagy pathways by a pathway-driven analysis. Flow cytometric analysis affirmed the elevation in nitric oxide (NO), Ca(++) influx, esterase, and disruption of mitochondrial membrane potential ($\Delta$$\Psi$m). Cell cycle dysregulation was affirmed by the appearance of 30.5{\%} subG1 apoptotic peak in NiO-NPs (100 $\mu$g/ml) treated cells. The molecular responses were consistent with the microscopic observation that NiO-NPs induced subcellular alterations in HepG2 cells. We conclude that hypoxia stress played a pivotal role in NiO-NPs induced hepatoxicity in HepG2 cells. Concentration dependent effects on transcriptomics specify a powerful tool to evaluate the molecular mechanisms of nanoparticle induced cytotoxicity. Overall our study unequivocally affirmed the transcriptomic alterations in human cells, consequently the prevalent usage of NiO-NPs should be given subtle consideration owing to its effects on biological processes.},
author = {Saquib, Quaiser and Xia, Pu and Siddiqui, Maqsood A and Zhang, Junjiang and Xie, Yuwei and Faisal, Mohammad and Ansari, Sabiha M and Alwathnani, Hend A and Alatar, Abdulrahman A and Al-Khedhairy, Abdulaziz A and Zhang, Xiaowei},
doi = {10.1016/j.chemosphere.2019.125488},
issn = {1879-1298 (Electronic)},
journal = {Chemosphere},
keywords = {Cell Cycle,Glutathione,Hazardous Substances,Hep G2 Cells,Humans,Lysosomes,Membrane Potential, Mitochondrial,Metal Nanoparticles,Nanoparticles,Nickel,Reactive Oxygen Species,Toxicity Tests,Transcriptome,drug effects,metabolism,toxicity},
language = {eng},
month = {apr},
pages = {125488},
pmid = {31812053},
title = {{High-throughput transcriptomics: An insight on the pathways affected in HepG2 cells  exposed to nickel oxide nanoparticles.}},
volume = {244},
year = {2020}
}
@article{Athar2019b,
abstract = {ArrayExpress (https://www.ebi.ac.uk/arrayexpress) is an archive of functional genomics data from a variety of technologies assaying functional modalities of a genome, such as gene expression or promoter occupancy. The number of experiments based on sequencing technologies, in particular RNA-seq experiments, has been increasing over the last few years and submissions of sequencing data have overtaken microarray experiments in the last 12 months. Additionally, there is a significant increase in experiments investigating single cells, rather than bulk samples, known as single-cell RNA-seq. To accommodate these trends, we have substantially changed our submission tool Annotare which, along with raw and processed data, collects all metadata necessary to interpret these experiments. Selected datasets are re-processed and loaded into our sister resource, the value-added Expression Atlas (and its component Single Cell Expression Atlas), which not only enables users to interpret the data easily but also serves as a test for data quality. With an increasing number of studies that combine different assay modalities (multi-omics experiments), a new more general archival resource the BioStudies Database has been developed, which will eventually supersede ArrayExpress. Data submissions will continue unchanged; all existing ArrayExpress data will be incorporated into BioStudies and the existing accession numbers and application programming interfaces will be maintained.},
author = {Athar, Awais and F{\"{u}}llgrabe, Anja and George, Nancy and Iqbal, Haider and Huerta, Laura and Ali, Ahmed and Snow, Catherine and Fonseca, Nuno A and Petryszak, Robert and Papatheodorou, Irene and Sarkans, Ugis and Brazma, Alvis},
doi = {10.1093/nar/gky964},
issn = {0305-1048},
journal = {Nucleic Acids Res.},
month = {jan},
number = {D1},
pages = {D711--D715},
title = {{ArrayExpress update – from bulk to single-cell expression data}},
url = {https://doi.org/10.1093/nar/gky964},
volume = {47},
year = {2019}
}
@article{McCall2011,
abstract = {Various databases have harnessed the wealth of publicly available microarray data to  address biological questions ranging from across-tissue differential expression to homologous gene expression. Despite their practical value, these databases rely on relative measures of expression and are unable to address the most fundamental question--which genes are expressed in a given cell type. The Gene Expression Barcode is the first database to provide reliable absolute measures of expression for most annotated genes for 131 human and 89 mouse tissue types, including diseased tissue. This is made possible by a novel algorithm that leverages information from the GEO and ArrayExpress public repositories to build statistical models that permit converting data from a single microarray into expressed/unexpressed calls for each gene. For selected platforms, users may upload data and obtain results in a matter of seconds. The raw data, curated annotation, and code used to create our resource are also available at http://rafalab.jhsph.edu/barcode.},
author = {McCall, Matthew N and Uppal, Karan and Jaffee, Harris A and Zilliox, Michael J and Irizarry, Rafael A},
doi = {10.1093/nar/gkq1259},
issn = {1362-4962 (Electronic)},
journal = {Nucleic Acids Res.},
keywords = {Animals,Databases, Genetic,Gene Expression Profiling,Humans,Mice,Oligonucleotide Array Sequence Analysis,Software},
language = {eng},
month = {jan},
number = {Database issue},
pages = {D1011--5},
pmid = {21177656},
title = {{The Gene Expression Barcode: leveraging public data repositories to begin cataloging  the human and murine transcriptomes.}},
volume = {39},
year = {2011}
}
@article{Lim2007b,
abstract = {Motivation: An increasingly common application of gene expression profile data is the reverse engineering of cellular networks. However, common procedures to normalize expression profiles generated using the Affymetrix GeneChips technology were originally developed for a rather different purpose, namely the accurate measure of differential gene expression between two or more phenotypes. As a result, current evaluation strategies lack comprehensive metrics to assess the suitability of available normalization procedures for reverse engineering and, in general, for measuring correlation between the expression profiles of a gene pair.Results: We benchmark four commonly used normalization procedures (MAS5, RMA, GCRMA and Li-Wong) in the context of established algorithms for the reverse engineering of protein–protein and protein–DNA interactions. Replicate sample, randomized and human B-cell data sets are used as an input. Surprisingly, our study suggests that MAS5 provides the most faithful cellular network reconstruction. Furthermore, we identify a crucial step in GCRMA responsible for introducing severe artifacts in the data leading to a systematic overestimate of pairwise correlation. This has key implications not only for reverse engineering but also for other methods, such as hierarchical clustering, relying on accurate measurements of pairwise expression profile correlation. We propose an alternative implementation to eliminate such side effect.Contect:califano@c2b2.columbia.edu},
author = {Lim, Wei Keat and Wang, Kai and Lefebvre, Celine and Califano, Andrea},
doi = {10.1093/bioinformatics/btm201},
issn = {1367-4803},
journal = {Bioinformatics},
month = {jul},
number = {13},
pages = {i282--i288},
title = {{Comparative analysis of microarray normalization procedures: effects on reverse engineering gene networks}},
url = {https://doi.org/10.1093/bioinformatics/btm201},
volume = {23},
year = {2007}
}
@article{Su2019f,
abstract = {Drug-induced hepatotoxicity may cause acute and chronic liver disease, leading to great concern for patient safety. It is also one of the main reasons for drug withdrawal from the market. Toxicogenomics data has been widely used in hepatotoxicity prediction. In our study, we proposed a multi-dose computational model to predict the drug-induced hepatotoxicity based on gene expression and toxicity data. The dose/concentration information after drug treatment is fully utilized in our study based on the dose-response curve, thus a more informative representative of the dose-response relationship is considered. We also proposed a new feature selection method, named MEMO, which is also one important aspect of our multi-dose model in our study, to deal with the high-dimensional toxicogenomics data. We validated the proposed model using the TG-GATEs, which is a large database recording toxicogenomics data from multiple views. The experimental results show that the drug-induced hepatotoxicity can be predicted with high accuracy and efficiency using the proposed predictive model.},
author = {Su, R and Wu, H and Xu, B and Liu, X and Wei, L},
doi = {10.1109/TCBB.2018.2858756},
issn = {1557-9964 VO  - 16},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinforma.},
keywords = {Biological system modeling,Computational modeling,Data models,Drug-induced,Drugs,Feature extraction,MEMO,Predictive models,Support vector machines,TG-GATE,acute liver disease,chronic liver disease,computational model,database recording,diseases,dose-concentration information,dose-response curve,dose-response relationship,drug delivery systems,drug treatment,drug withdrawal,drug-induced hepatotoxicity prediction,drugs,feature selection,feature selection method,gene expression,genetics,genomics,hepatotoxicity,high-dimensional toxicogenomics data,liver,medical computing,multi-dose,multidose computational model,prediction,toxicity data,toxicogenomics,toxicology},
number = {4},
pages = {1231--1239},
title = {{Developing a Multi-Dose Computational Model for Drug-Induced Hepatotoxicity Prediction Based on Toxicogenomics Data}},
volume = {16},
year = {2019}
}
@article{Wu2018,
abstract = {Toxicity prediction is very important to public health. Among its many applications, toxicity prediction is essential to reduce the cost and labor of a drug's preclinical and clinical trials, because a lot of drug evaluations (cellular, animal, and clinical) can be spared due to the predicted toxicity. In the era of Big Data and artificial intelligence, toxicity prediction can benefit from machine learning, which has been widely used in many fields such as natural language processing, speech recognition, image recognition, computational chemistry, and bioinformatics, with excellent performance. In this article, we review machine learning methods that have been applied to toxicity prediction, including deep learning, random forests, k-nearest neighbors, and support vector machines. We also discuss the input parameter to the machine learning algorithm, especially its shift from chemical structural description only to that combined with human transcriptome data analysis, which can greatly enhance prediction accuracy.},
author = {Wu, Yunyi and Wang, Guanyu},
doi = {10.3390/ijms19082358},
issn = {1422-0067},
journal = {Int. J. Mol. Sci.},
keywords = {*Machine Learning,*Natural Language Processing,*Transcriptome,Animals,Gene Expression Profiling/*methods,Humans,chemical structure,deep learning,machine learning,molecular fingerprint,molecular fragment,toxicity prediction,transcriptome},
language = {eng},
month = {aug},
number = {8},
pages = {2358},
publisher = {MDPI},
title = {{Machine Learning Based Toxicity Prediction: From Chemical Structural Description to Transcriptome Analysis}},
url = {https://pubmed.ncbi.nlm.nih.gov/30103448 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6121588/},
volume = {19},
year = {2018}
}
@misc{Urushidani2007c,
abstract = {Summary This chapter contains sections titled: Introduction The Features of the Toxicogenomics Project (TGP) Construction of a Toxicity Prediction System Based on the TGP Database The Image of Toxicity Testing after the TGP Database is Established Acknowledgments References},
annote = {https://doi.org/10.1002/9780470516751.ch20},
author = {Urushidani, Tetsuro},
booktitle = {Hepatotoxicity},
doi = {https://doi.org/10.1002/9780470516751.ch20},
isbn = {9780470516751},
keywords = {animal species,clinical dose range,disease-related genes,dose–response relationship,drug development cost,human-type genes,human-type molecule,molecular functions,pathophysiological changes,pharmacological target},
month = {dec},
pages = {507--529},
series = {Wiley Online Books},
title = {{Prediction of Hepatotoxicity Based on the Toxicogenomics Database}},
url = {https://doi.org/10.1002/9780470516751.ch20},
year = {2007}
}
@article{Xu2015,
annote = {doi: 10.1021/acs.jcim.5b00238},
author = {Xu, Youjun and Dai, Ziwei and Chen, Fangjin and Gao, Shuaishi and Pei, Jianfeng and Lai, Luhua},
doi = {10.1021/acs.jcim.5b00238},
issn = {1549-9596},
journal = {J. Chem. Inf. Model.},
month = {oct},
number = {10},
pages = {2085--2093},
publisher = {American Chemical Society},
title = {{Deep Learning for Drug-Induced Liver Injury}},
url = {https://doi.org/10.1021/acs.jcim.5b00238},
volume = {55},
year = {2015}
}
@article{Stempler2014b,
abstract = {Accumulating evidence links numerous abnormalities in cerebral metabolism with the progression of Alzheimer's disease (AD), beginning in its early stages. Here, we integrate transcriptomic data from AD patients with a genome-scale computational human metabolic model to characterize the altered metabolism in AD, and employ state-of-the-art metabolic modelling methods to predict metabolic biomarkers and drug targets in AD. The metabolic descriptions derived are first tested and validated on a large scale versus existing AD proteomics and metabolomics data. Our analysis shows a significant decrease in the activity of several key metabolic pathways, including the carnitine shuttle, folate metabolism and mitochondrial transport. We predict several metabolic biomarkers of AD progression in the blood and the CSF, including succinate and prostaglandin D2. Vitamin D and steroid metabolism pathways are enriched with predicted drug targets that could mitigate the metabolic alterations observed. Taken together, this study provides the first network wide view of the metabolic alterations associated with AD progression. Most importantly, it offers a cohort of new metabolic leads for the diagnosis of AD and its treatment.},
author = {Stempler, Shiri and Yizhak, Keren and Ruppin, Eytan},
journal = {PLoS One},
month = {aug},
number = {8},
pages = {e105383},
publisher = {Public Library of Science},
title = {{Integrating Transcriptomics with Metabolic Modeling Predicts Biomarkers and Drug Targets for Alzheimer's Disease}},
url = {https://doi.org/10.1371/journal.pone.0105383},
volume = {9},
year = {2014}
}
@article{Thiele2013b,
abstract = {Multiple models of human metabolism have been reconstructed, but each represents only a subset of our knowledge. Here we describe Recon 2, a community-driven, consensus 'metabolic reconstruction', which is the most comprehensive representation of human metabolism that is applicable to computational modeling. Compared with its predecessors, the reconstruction has improved topological and functional features, including ∼2× more reactions and ∼1.7× more unique metabolites. Using Recon 2 we predicted changes in metabolite biomarkers for 49 inborn errors of metabolism with 77{\%} accuracy when compared to experimental data. Mapping metabolomic data and drug information onto Recon 2 demonstrates its potential for integrating and analyzing diverse data types. Using protein expression data, we automatically generated a compendium of 65 cell type-specific models, providing a basis for manual curation or investigation of cell-specific metabolic properties. Recon 2 will facilitate many future biomedical studies and is freely available at http://humanmetabolism.org/.},
author = {Thiele, Ines and Swainston, Neil and Fleming, Ronan M T and Hoppe, Andreas and Sahoo, Swagatika and Aurich, Maike K and Haraldsdottir, Hulda and Mo, Monica L and Rolfsson, Ottar and Stobbe, Miranda D and Thorleifsson, Stefan G and Agren, Rasmus and B{\"{o}}lling, Christian and Bordel, Sergio and Chavali, Arvind K and Dobson, Paul and Dunn, Warwick B and Endler, Lukas and Hala, David and Hucka, Michael and Hull, Duncan and Jameson, Daniel and Jamshidi, Neema and Jonsson, Jon J and Juty, Nick and Keating, Sarah and Nookaew, Intawat and {Le Nov{\`{e}}re}, Nicolas and Malys, Naglis and Mazein, Alexander and Papin, Jason A and Price, Nathan D and {Selkov  Sr}, Evgeni and Sigurdsson, Martin I and Simeonidis, Evangelos and Sonnenschein, Nikolaus and Smallbone, Kieran and Sorokin, Anatoly and van Beek, Johannes H G M and Weichart, Dieter and Goryanin, Igor and Nielsen, Jens and Westerhoff, Hans V and Kell, Douglas B and Mendes, Pedro and Palsson, Bernhard {\O}},
doi = {10.1038/nbt.2488},
edition = {2013/03/03},
issn = {1546-1696},
journal = {Nat. Biotechnol.},
keywords = {*Databases, Protein,*Models, Biological,Computer Simulation,Humans,Metabolome/*physiology,Proteome/*metabolism},
language = {eng},
month = {may},
number = {5},
pages = {419--425},
title = {{A community-driven global reconstruction of human metabolism}},
url = {https://pubmed.ncbi.nlm.nih.gov/23455439 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3856361/},
volume = {31},
year = {2013}
}
@article{McCall2014,
abstract = {The Gene Expression Barcode project, http://barcode.luhs.org, seeks to determine the  genes expressed for every tissue and cell type in humans and mice. Understanding the absolute expression of genes across tissues and cell types has applications in basic cell biology, hypothesis generation for gene function and clinical predictions using gene expression signatures. In its current version, this project uses the abundant publicly available microarray data sets combined with a suite of single-array preprocessing, quality control and analysis methods. In this article, we present the improvements that have been made since the previous version of the Gene Expression Barcode in 2011. These include a variety of new data mining tools and summaries, estimated transcriptomes and curated annotations.},
author = {McCall, Matthew N and Jaffee, Harris A and Zelisko, Susan J and Sinha, Neeraj and Hooiveld, Guido and Irizarry, Rafael A and Zilliox, Michael J},
doi = {10.1093/nar/gkt1204},
issn = {1362-4962 (Electronic)},
journal = {Nucleic Acids Res.},
keywords = {Animals,Data Mining,Databases, Genetic,Gene Expression Profiling,Humans,Internet,Mice,Oligonucleotide Array Sequence Analysis,Software,Transcriptome},
language = {eng},
month = {jan},
number = {Database issue},
pages = {D938--43},
pmid = {24271388},
title = {{The Gene Expression Barcode 3.0: improved data processing and mining tools.}},
volume = {42},
year = {2014}
}
@article{Zhang2015,
abstract = {Predicting drug side effects is an important topic in the drug discovery. Although several machine learning methods have been proposed to predict side effects, there is still space for improvements. Firstly, the side effect prediction is a multi-label learning task, and we can adopt the multi-label learning techniques for it. Secondly, drug-related features are associated with side effects, and feature dimensions have specific biological meanings. Recognizing critical dimensions and reducing irrelevant dimensions may help to reveal the causes of side effects.},
author = {Zhang, Wen and Liu, Feng and Luo, Longqiang and Zhang, Jingxia},
doi = {10.1186/s12859-015-0774-y},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {1},
pages = {365},
title = {{Predicting drug side effects by multi-label learning and ensemble learning}},
url = {https://doi.org/10.1186/s12859-015-0774-y},
volume = {16},
year = {2015}
}
@inproceedings{Cardoso2012b,
abstract = {The considerable growth in the number of sequenced genomes and recent advances in Bioinformatics and Systems Biology fields have provided several genome-scale metabolic models (GSMs) that have been used to provide phenotype simulation methods. Given their importance in biomedical research and biotechnology applications (e.g. in Metabolic Engineering efforts), several workflows and computational platforms have been proposed for GSM reconstruction. One of the challenges of these methods is related to the assignment of gene-protein-reaction (GPR) associations that allow to add transcriptional/ translational information to GSMs, a task typically addressed through manual literature curation. This work proposes a novel algorithm to create a set of GPR rules, based on the integration of the information provided by the genome annotation with information on protein composition and function (protein complexes, sub-units, iso-enzymes, etc.) provided by the UniProt database. The methods are validated by using two state-of-the-art models for E. coli and S. cerevisiae, with competitive results.},
address = {Berlin, Heidelberg},
author = {Cardoso, Jo{\~{a}}o and Vila{\c{c}}a, Paulo and Soares, Sim{\~{a}}o and Rocha, Miguel},
editor = {Shibuya, Tetsuo and Kashima, Hisashi and Sese, Jun and Ahmad, Shandar},
isbn = {978-3-642-34123-6},
pages = {118--128},
publisher = {Springer Berlin Heidelberg},
title = {{An Algorithm to Assemble Gene-Protein-Reaction Associations for Genome-Scale Metabolic Model Reconstruction BT  - Pattern Recognition in Bioinformatics}},
year = {2012}
}
@article{McMullen2019c,
abstract = {Because of their broad biological coverage and increasing affordability  transcriptomic technologies have increased our ability to evaluate cellular response to chemical stressors, providing a potential means of evaluating chemical response while decreasing dependence on apical endpoints derived from traditional long-term animal studies. It has recently been suggested that dose-response modeling of transcriptomic data may be incorporated into risk assessment frameworks as a means of approximating chemical hazard. However, identification of mode of action from transcriptomics lacks a similar systematic framework. To this end, we developed a web-based interactive browser-MoAviz-that allows visualization of perturbed pathways. We populated this browser with expression data from a large public toxicogenomic database (TG-GATEs). We evaluated the extent to which gene expression changes from in-life exposures could be associated with mode of action by developing a novel similarity index-the Modified Jaccard Index (MJI)-that provides a quantitative description of genomic pathway similarity (rather than gene level comparison). While typical compound-compound similarity is low (median MJI = 0.026), clustering of the TG-GATES compounds identifies groups of similar chemistries. Some clusters aggregated compounds with known similar modes of action, including PPARa agonists (median MJI = 0.315) and NSAIDs (median MJI = 0.322). Analysis of paired in vitro (hepatocyte)-in vivo (liver) experiments revealed systematic patterns in the responses of model systems to chemical stress. Accounting for these model-specific, but chemical-independent, differences improved pathway concordance by 36{\%} between in vivo and in vitro models.},
author = {McMullen, Patrick D and Pendse, Salil N and Black, Michael B and Mansouri, Kamel and Haider, Saad and Andersen, Melvin E and Clewell, Rebecca A},
doi = {10.1016/j.tiv.2019.02.014},
issn = {1879-3177 (Electronic)},
journal = {Toxicol. In Vitro},
keywords = {Animals,Biological pathway visualization,Chemical mode of action,Databases,Factual,Gene Expression Profiling,Gene Ontology,Hepatocytes,Humans,MoAviz,Risk Assessment,TG-GATES,Toxicogenomics response,Transcriptome,Transcriptomics,metabolism},
language = {eng},
month = {aug},
pages = {1--12},
pmid = {30807807},
title = {{Addressing systematic inconsistencies between in vitro and in vivo transcriptomic  mode of action signatures.}},
url = {http://www.sciencedirect.com/science/article/pii/S088723331830328X},
volume = {58},
year = {2019}
}
@article{Vatakuti2016,
annote = {doi: 10.1021/acs.chemrestox.5b00491},
author = {Vatakuti, Suresh and Pennings, Jeroen L A and Gore, Emilia and Olinga, Peter and Groothuis, Geny M M},
doi = {10.1021/acs.chemrestox.5b00491},
issn = {0893-228X},
journal = {Chem. Res. Toxicol.},
month = {mar},
number = {3},
pages = {342--351},
publisher = {American Chemical Society},
title = {{Classification of Cholestatic and Necrotic Hepatotoxicants Using Transcriptomics on Human Precision-Cut Liver Slices}},
url = {https://doi.org/10.1021/acs.chemrestox.5b00491},
volume = {29},
year = {2016}
}
@article{Manduchi2020c,
abstract = {BACKGROUND: A typical task in bioinformatics consists of identifying which features are associated with a target outcome of interest and building a predictive model. Automated machine learning (AutoML) systems such as the Tree-based Pipeline Optimization Tool (TPOT) constitute an appealing approach to this end. However, in biomedical data, there are often baseline characteristics of the subjects in a study or batch effects that need to be adjusted for in order to better isolate the effects of the features of interest on the target. Thus, the ability to perform covariate adjustments becomes particularly important for applications of AutoML to biomedical big data analysis. RESULTS: We developed an approach to adjust for covariates affecting features and/or target in TPOT. Our approach is based on regressing out the covariates in a manner that avoids 'leakage' during the cross-validation training procedure. We describe applications of this approach to toxicogenomics and schizophrenia gene expression data sets. The TPOT extensions discussed in this work are available at https://github.com/EpistasisLab/tpot/tree/v0.11.1-resAdj . CONCLUSIONS: In this work, we address an important need in the context of AutoML, which is particularly crucial for applications to bioinformatics and medical informatics, namely covariate adjustments. To this end we present a substantial extension of TPOT, a genetic programming based AutoML approach. We show the utility of this extension by applications to large toxicogenomics and differential gene expression data. The method is generally applicable in many other scenarios from the biomedical field.},
author = {Manduchi, Elisabetta and Fu, Weixuan and Romano, Joseph D and Ruberto, Stefano and Moore, Jason H},
doi = {10.1186/s12859-020-03755-4},
issn = {1471-2105},
journal = {BMC Bioinformatics},
keywords = {AutoML,Covariate adjustment,Feature importance,Genetic programming,Pathways},
language = {eng},
month = {oct},
number = {1},
pages = {430},
publisher = {BioMed Central},
title = {{Embedding covariate adjustments in tree-based automated machine learning for biomedical big data analyses}},
url = {https://pubmed.ncbi.nlm.nih.gov/32998684 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7528347/},
volume = {21},
year = {2020}
}
@article{Fromenty2010,
abstract = {R{\'{e}}sum{\'{e}} De nombreux travaux ont montr{\'{e}} qu'un m{\'{e}}canisme majeur d'h{\'{e}}patotoxicit{\'{e}} m{\'{e}}dicamenteuse est l'alt{\'{e}}ration des fonctions mitochondriales, soit par le m{\'{e}}dicament en lui-m{\^{e}}me, soit par l'interm{\'{e}}diaire d'un m{\'{e}}tabolite r{\'{e}}actif g{\'{e}}n{\'{e}}r{\'{e}} par le cytochrome P450. En fonction de leur nature et de leur s{\'{e}}v{\'{e}}rit{\'{e}}, ces dysfonctionnements mitochondriaux peuvent {\^{e}}tre responsables de l'apparition d'une cytolyse h{\'{e}}patique plus ou moins massive et d'une st{\'{e}}atose qui peut {\^{e}}tre de type microv{\'{e}}siculaire ou macrovacuolaire. La st{\'{e}}atose microv{\'{e}}siculaire, l{\'{e}}sion potentiellement grave pouvant {\^{e}}tre associ{\'{e}}e {\`{a}} une insuffisance h{\'{e}}patique et {\`{a}} une hypoglyc{\'{e}}mie profonde, est induite par une inhibition s{\'{e}}v{\`{e}}re de la $\beta$-oxydation mitochondriale des acides gras. La st{\'{e}}atose macrovacuolaire, l{\'{e}}sion plut{\^{o}}t b{\'{e}}nigne {\`{a}} court terme, semble {\^{e}}tre induite par diff{\'{e}}rents types d'alt{\'{e}}rations du m{\'{e}}tabolisme des lipides telles qu'une inhibition mod{\'{e}}r{\'{e}}e de l'oxydation des acides gras, une augmentation de la synth{\`{e}}se des lipides ou une diminution de la sortie h{\'{e}}patique des triglyc{\'{e}}rides sous forme de VLDL. De plus, des travaux r{\'{e}}cents sugg{\`{e}}rent que des m{\'{e}}dicaments, ou certains toxiques comme l'alcool, pourraient favoriser l'accumulation intrah{\'{e}}patique des lipides en alt{\'{e}}rant la s{\'{e}}cr{\'{e}}tion par le tissu adipeux de leptine et d'adiponectine, deux adipokines qui pr{\'{e}}sentent une action anti-st{\'{e}}atosique. Si le traitement m{\'{e}}dicamenteux n'est pas interrompu, la st{\'{e}}atose peut {\'{e}}voluer chez certains patients en st{\'{e}}atoh{\'{e}}patite caract{\'{e}}ris{\'{e}}e non seulement par l'accumulation des lipides mais {\'{e}}galement par une n{\'{e}}cro-inflammation et une fibrose. Bien que les m{\'{e}}canismes de l'{\'{e}}volution de la st{\'{e}}atose en st{\'{e}}atoh{\'{e}}patite ne soient pas encore bien caract{\'{e}}ris{\'{e}}s, il semble que la production d'esp{\`{e}}ces r{\'{e}}actives de l'oxyg{\`{e}}ne par les mitochondries endommag{\'{e}}es puisse jouer un r{\^{o}}le important. De nombreux facteurs pourraient favoriser une toxicit{\'{e}} mitochondriale et m{\'{e}}tabolique induite par les m{\'{e}}dicaments tels que la structure de la mol{\'{e}}cule en elle-m{\^{e}}me, des pr{\'{e}}dispositions g{\'{e}}n{\'{e}}tiques (en particulier celles concernant des enzymes mitochondriales), la consommation excessive d'alcool, l'infection par le virus de l'h{\'{e}}patite C et l'ob{\'{e}}sit{\'{e}}. Chez les sujets ob{\`{e}}ses, certains m{\'{e}}dicaments pourraient non seulement induire plus fr{\'{e}}quemment une h{\'{e}}patite aigu{\"{e}} mais {\'{e}}galement aggraver la st{\'{e}}atose (ou la st{\'{e}}atoh{\'{e}}patite) pr{\'{e}}existante. Summary Numerous investigations have shown that a major mechanism of drug-induced liver injury is mitochondrial dysfunction, involving the parent drug by itself or a reactive metabolite generated through the cytochrome P450. Depending of their nature and their severity, mitochondrial alterations are able to induce hepatic cytolysis and steatosis that can be microvesicular or macrovacuolar. Microvesicular steatosis, a potentially severe liver injury that can be associated with liver failure and profound hypoglycemia, is due to a major inhibition of mitochondrial fatty acid oxidation. Macrovacuolar steatosis, a relatively benign liver injury in the short term, can be induced by different types of alterations of lipid homeostasis including a moderate reduction of fatty acid oxidation, an enhancement of lipid synthesis and a decreased hepatic export of VLDL-associated triglycerides. Moreover, recent investigations suggest that some drugs, as well as ethanol intoxication, could favor lipid accretion in the liver through an altered secretion by the white adipose tissue of leptin and adiponectin, two adipokines that have an anti-steatotic action. If the treatment is not interrupted, steatosis can evolve toward steatohepatitis, which is characterized not only by lipid accumulation but also by necroinflammation and fibrosis. Although the mechanisms involved in this worsening is not fully characterized, it appears that overproduction of reactive oxygen species by the damaged mitochondria could play a salient role. Numerous factors could favor drug-induced mitochondrial and metabolic toxicity such as the structure of the parent molecule, genetic predispositions (in particular those involving mitochondrial enzymes), ethanol intoxication, hepatitis virus C infection and obesity. In the obese patients, some drugs could not only induce drug-induced acute liver injury more frequently but also worsen the preexistent steatosis (or steatohepatitis).},
author = {Fromenty, B},
doi = {https://doi.org/10.1016/j.reaurg.2010.05.003},
issn = {1624-0693},
journal = {R{\'{e}}animation},
keywords = {Cell death,Drugs,Hepatotoxicity,H{\'{e}}patotoxicit{\'{e}},Lipides,Lipids,Mitochondria,Mitochondries,Mort cellulaire,M{\'{e}}dicaments,Obesity,Ob{\'{e}}sit{\'{e}},Steatosis,St{\'{e}}atose},
number = {6},
pages = {552--567},
title = {{Toxicit{\'{e}} mitochondriale et m{\'{e}}tabolique des m{\'{e}}dicaments : m{\'{e}}canismes et cons{\'{e}}quences au niveau du foie}},
url = {http://www.sciencedirect.com/science/article/pii/S1624069310001131},
volume = {19},
year = {2010}
}
@article{Grinberg2014c,
abstract = {A long-term goal of numerous research projects is to identify biomarkers for in  vitro systems predicting toxicity in vivo. Often, transcriptomics data are used to identify candidates for further evaluation. However, a systematic directory summarizing key features of chemically influenced genes in human hepatocytes is not yet available. To bridge this gap, we used the Open TG-GATES database with Affymetrix files of cultivated human hepatocytes incubated with chemicals, further sets of gene array data with hepatocytes from human donors generated in this study, and publicly available genome-wide datasets of human liver tissue from patients with non-alcoholic steatohepatitis (NASH), cirrhosis, and hepatocellular cancer (HCC). After a curation procedure, expression data of 143 chemicals were included into a comprehensive biostatistical analysis. The results are summarized in the publicly available toxicotranscriptomics directory ( http://wiki.toxbank.net/toxicogenomics-map/ ) which provides information for all genes whether they are up- or downregulated by chemicals and, if yes, by which compounds. The directory also informs about the following key features of chemically influenced genes: (1) Stereotypical stress response. When chemicals induce strong expression alterations, this usually includes a complex but highly reproducible pattern named 'stereotypical response.' On the other hand, more specific expression responses exist that are induced only by individual compounds or small numbers of compounds. The directory differentiates if the gene is part of the stereotypical stress response or if it represents a more specific reaction. (2) Liver disease-associated genes. Approximately 20 {\%} of the genes influenced by chemicals are up- or downregulated, also in liver disease. Liver disease genes deregulated in cirrhosis, HCC, and NASH that overlap with genes of the aforementioned stereotypical chemical stress response include CYP3A7, normally expressed in fetal liver; the phase II metabolizing enzyme SULT1C2; ALDH8A1, known to generate the ligand of RXR, one of the master regulators of gene expression in the liver; and several genes involved in normal liver functions: CPS1, PCK1, SLC2A2, CYP8B1, CYP4A11, ABCA8, and ADH4. (3) Unstable baseline genes. The process of isolating and the cultivation of hepatocytes was sufficient to induce some stress leading to alterations in the expression of genes, the so-called unstable baseline genes. (4) Biological function. Although more than 2,000 genes are transcriptionally influenced by chemicals, they can be assigned to a relatively small group of biological functions, including energy and lipid metabolism, inflammation and immune response, protein modification, endogenous and xenobiotic metabolism, cytoskeletal organization, stress response, and DNA repair. In conclusion, the introduced toxicotranscriptomics directory offers a basis for a rationale choice of candidate genes for biomarker evaluation studies and represents an easy to use source of background information on chemically influenced genes.},
author = {Grinberg, Marianna and St{\"{o}}ber, Regina M and Edlund, Karolina and Rempel, Eugen and Godoy, Patricio and Reif, Raymond and Widera, Agata and Madjar, Katrin and Schmidt-Heck, Wolfgang and Marchan, Rosemarie and Sachinidis, Agapios and Spitkovsky, Dimitry and Hescheler, J{\"{u}}rgen and Carmo, Helena and Arbo, Marcelo D and van de Water, Bob and Wink, Steven and Vinken, Mathieu and Rogiers, Vera and Escher, Sylvia and Hardy, Barry and Mitic, Dragana and Myatt, Glenn and Waldmann, Tanja and Mardinoglu, Adil and Damm, Georg and Seehofer, Daniel and N{\"{u}}ssler, Andreas and Weiss, Thomas S and Oberemm, Axel and Lampen, Alfons and Schaap, Mirjam M and Luijten, Mirjam and van Steeg, Harry and Thasler, Wolfgang E and Kleinjans, Jos C S and Stierum, Rob H and Leist, Marcel and Rahnenf{\"{u}}hrer, J{\"{o}}rg and Hengstler, Jan G},
doi = {10.1007/s00204-014-1400-x},
issn = {1432-0738 (Electronic)},
journal = {Arch. Toxicol.},
keywords = {Cells, Cultured,Databases, Genetic,Dose-Response Relationship, Drug,Gene Expression,Hepatocytes,Humans,Liver Diseases,Principal Component Analysis,Small Molecule Libraries,Toxicogenetics,chemistry,drug effects,genetics,methods,statistics {\&} numerical data,toxicity},
language = {eng},
month = {dec},
number = {12},
pages = {2261--2287},
pmid = {25399406},
title = {{Toxicogenomics directory of chemically exposed human hepatocytes.}},
volume = {88},
year = {2014}
}
@article{Luo2017c,
abstract = {Drug-induced liver injuries have been a major focus of current research in drug  development, and are also one of the major reasons for the failure and withdrawal of drugs in development. Drug-induced liver injuries have been systematically recorded in many public databases, which have become valuable resources in this field. In this study, we provide an overview of these databases, including the liver injury-specific databases LiverTox, LTKB, Open TG-GATEs, LTMap and Hepatox, and the general databases, T3DB, DrugBank, DITOP, DART, CTD and HSDB. The features and limitations of these databases are summarized and discussed in detail. Apart from their powerful functions, we believe that these databases can be improved in several ways: by providing the data about the molecular targets involved in liver toxicity, by incorporating information regarding liver injuries caused by drug interactions, and by regularly updating the data.},
author = {Luo, Guangwen and Shen, Yiting and Yang, Lizhu and Lu, Aiping and Xiang, Zheng},
doi = {10.1007/s00204-017-2024-8},
issn = {1432-0738 (Electronic)},
journal = {Arch. Toxicol.},
keywords = {Animals,Chemical and Drug Induced Liver Injury,Databases, Factual,Humans,Rats,etiology},
language = {eng},
month = {sep},
number = {9},
pages = {3039--3049},
pmid = {28717830},
title = {{A review of drug-induced liver injury databases.}},
volume = {91},
year = {2017}
}
@article{Brunk2018,
abstract = {Genome-scale network reconstructions have helped uncover the molecular basis of  metabolism. Here we present Recon3D, a computational resource that includes three-dimensional (3D) metabolite and protein structure data and enables integrated analyses of metabolic functions in humans. We use Recon3D to functionally characterize mutations associated with disease, and identify metabolic response signatures that are caused by exposure to certain drugs. Recon3D represents the most comprehensive human metabolic network model to date, accounting for 3,288 open reading frames (representing 17{\%} of functionally annotated human genes), 13,543 metabolic reactions involving 4,140 unique metabolites, and 12,890 protein structures. These data provide a unique resource for investigating molecular mechanisms of human metabolism. Recon3D is available at http://vmh.life.},
author = {Brunk, Elizabeth and Sahoo, Swagatika and Zielinski, Daniel C and Altunkaya, Ali and Dr{\"{a}}ger, Andreas and Mih, Nathan and Gatto, Francesco and Nilsson, Avlant and {Preciat Gonzalez}, German Andres and Aurich, Maike Kathrin and Prli{\'{c}}, Andreas and Sastry, Anand and Danielsdottir, Anna D and Heinken, Almut and Noronha, Alberto and Rose, Peter W and Burley, Stephen K and Fleming, Ronan M T and Nielsen, Jens and Thiele, Ines and Palsson, Bernhard O},
doi = {10.1038/nbt.4072},
issn = {1546-1696 (Electronic)},
journal = {Nat. Biotechnol.},
keywords = {Computational Biology,Databases, Genetic,Databases, Protein,Humans,Internet,Metabolic Networks and Pathways,Molecular Sequence Annotation,Open Reading Frames,genetics,methods},
language = {eng},
month = {mar},
number = {3},
pages = {272--281},
pmid = {29457794},
title = {{Recon3D enables a three-dimensional view of gene variation in human metabolism.}},
volume = {36},
year = {2018}
}
@article{Schultz2015,
abstract = {Category formation, grouping and read across methods are broadly applicable in toxicological assessments and may be used to fill data gaps for chemical safety assessment and regulatory decisions. In order to facilitate a transparent and systematic approach to aid regulatory acceptance, a strategy to evaluate chemical category membership, to support the use of read-across predictions that may be used to fill data gaps for regulatory decisions is proposed. There are two major aspects of any read-across exercise, namely assessing similarity and uncertainty. While there can be an over-arching rationale for grouping organic substances based on molecular structure and chemical properties, these similarities alone are generally not sufficient to justify a read-across prediction. Further scientific justification is normally required to justify the chemical grouping, typically including considerations of bioavailability, metabolism and biological/mechanistic plausibility. Sources of uncertainty include a variety of elements which are typically divided into two main issues: the uncertainty associated firstly with the similarity justification and secondly the completeness of the read-across argument. This article focuses on chronic toxicity, whilst acknowledging the approaches are applicable to all endpoints. Templates, developed from work to prepare for the application of new toxicological data to read-across assessment, are presented. These templates act as proposals to assist in assessing similarity in the context of chemistry, toxicokinetics and toxicodynamics as well as to guide the systematic characterisation of uncertainty both in the context of the similarity rationale, the read across data and overall approach and conclusion. Lastly, a workflow for reporting a read-across prediction is suggested.},
author = {Schultz, T W and Amcoff, P and Berggren, E and Gautier, F and Klaric, M and Knight, D J and Mahony, C and Schwarz, M and White, A and Cronin, M T D},
doi = {https://doi.org/10.1016/j.yrtph.2015.05.016},
issn = {0273-2300},
journal = {Regul. Toxicol. Pharmacol.},
keywords = {Chemical analogue identification,OECD,Prediction,REACH,Read-across,Regulatory acceptance,Similarity,Toxicity,Uncertainty},
number = {3},
pages = {586--601},
title = {{A strategy for structuring and reporting a read-across prediction of toxicity}},
url = {http://www.sciencedirect.com/science/article/pii/S0273230015001154},
volume = {72},
year = {2015}
}
@misc{Li2016b,
abstract = {Microarray technology, with its high-throughput advantage, has been applied to  analyze various biomaterials, such as nucleic acids, proteins, glycans, peptides, and cells.},
author = {Li, Paul C H},
booktitle = {Methods Mol. Biol.},
doi = {10.1007/978-1-4939-3136-1_1},
issn = {1940-6029 (Electronic)},
keywords = {Humans,Microarray Analysis},
language = {eng},
pages = {3--4},
pmid = {26614064},
title = {{Overview of Microarray Technology.}},
volume = {1368},
year = {2016}
}
@article{Risso2014,
abstract = {Remove unwanted variation (RUV) is a new statistical method for RNA-seq data normalization that uses control genes or samples to improve differential expression analysis.},
author = {Risso, Davide and Ngai, John and Speed, Terence P and Dudoit, Sandrine},
doi = {10.1038/nbt.2931},
issn = {1546-1696},
journal = {Nat. Biotechnol.},
number = {9},
pages = {896--902},
title = {{Normalization of RNA-seq data using factor analysis of control genes or samples}},
url = {https://doi.org/10.1038/nbt.2931},
volume = {32},
year = {2014}
}
@article{Hebenstreit2011,
abstract = {The expression level of a gene is often used as a proxy for determining whether the protein or RNA product is functional in a cell or tissue. Therefore, it is of fundamental importance to understand the global distribution of gene expression levels, and to be able to interpret it mechanistically and functionally. Here we use RNA sequencing (RNA-seq) of mouse Th2 cells, coupled with a range of other techniques, to show that all genes can be separated, based on their expression abundance, into two distinct groups: one group comprised of lowly expressed and putatively non-functional mRNAs, and the other of highly expressed mRNAs with active chromatin marks at their promoters. These observations are confirmed in many other microarray and RNA-seq data sets of metazoan cell types.},
author = {Hebenstreit, Daniel and Fang, Miaoqing and Gu, Muxin and Charoensawan, Varodom and van Oudenaarden, Alexander and Teichmann, Sarah A},
doi = {10.1038/msb.2011.28},
issn = {1744-4292},
journal = {Mol. Syst. Biol.},
keywords = {*Gene Expression Regulation,Animals,Cells, Cultured,Computational Biology,Gene Expression Profiling/*methods,In Situ Hybridization, Fluorescence,Mice,Mice, Inbred C57BL,Microarray Analysis,RNA, Messenger/genetics,Sequence Analysis, RNA/*methods,Th2 Cells},
language = {eng},
month = {jun},
pages = {497},
publisher = {Nature Publishing Group},
title = {{RNA sequencing reveals two major classes of gene expression levels in metazoan cells}},
url = {https://pubmed.ncbi.nlm.nih.gov/21654674 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3159973/},
volume = {7},
year = {2011}
}
@article{Su2019d,
abstract = {Identifying hepatotoxicity as early as possible is significant in drug development.  In this study, we developed a drug-induced hepatotoxicity prediction model taking account of both the biological context and the computational efficacy based on toxicogenomics data. Specifically, we proposed a novel gene selection algorithm considering gene's participation, named BioCB, to choose the discriminative genes and make more efficient prediction. Then instead of using the raw gene expression levels to characterize each drug, we developed a two-dimensional biological process feature pattern map to represent each drug. Then we employed two strategies to handle the maps and identify the hepatotoxicity, the direct use of maps, named Two-dim branch, and vectorization of maps, named One-dim branch. The two strategies subsequently used the deep convolutional neural networks and LightGBM as predictors, respectively. Additionally, we here for the first time proposed a stacked vectorized gene matrix, which was more predictive than the raw gene matrix. Results validated on both in vivo and in vitro data from two public data sets, the TG-GATES and DrugMatrix, show that the proposed One-dim branch outperforms the deep framework, the Two-dim branch, and has achieved high accuracy and efficiency. The implementation of the proposed method is available at https://github.com/RanSuLab/Hepatotoxicity.},
author = {Su, Ran and Wu, Huichen and Liu, Xinyi and Wei, Leyi},
doi = {10.1093/bib/bbz165},
issn = {1477-4054 (Electronic)},
journal = {Brief. Bioinform.},
language = {eng},
month = {dec},
pmid = {31838506},
title = {{Predicting drug-induced hepatotoxicity based on biological feature maps and diverse  classification strategies.}},
year = {2019}
}
@article{Goyak2008b,
abstract = {To examine the magnitude of human variability across the entire transcriptome after chemical challenge, we profiled gene expression responses to three different prototypic chemical inducers in primary human hepatocyte cultures from ten independent donors. Correlation between basal expression in any two hepatocyte donors ranged from r(2) values of 0.967 to 0.857, and chemical treatment tended to negatively impact correlation between donors. Including anticipated target genes, 10,812, 8373, and 7847 genes were changed in at least one donor by Aroclor 1254 (A1254), di(2-ethylhexyl) phthalate (DEHP), and phenobarbital (PB), respectively. A subset of these gene targets (n=41) were altered with a high level of reproducibility in at least 9 donors, gene responses that correlated well with literature-reported mechanism of action. Filtering responses to the level of gene subsets clarified the biological impact associated with the respective chemical effectors, in lieu of substantial interindividual variation among donor responses. In these respects, the use of hierarchical clustering methods successfully grouped seven of the ten donors into chemical-specific rather than donor-specific clusters. However, at the whole-genome level, the magnitude of conserved gene expression changes among donors was surprisingly small, with fewer than 50{\%} of the gene responses altered by a single chemical conserved in more than one donor. The use of higher level descriptors, such as those defined by the PANTHER classification system, may enable more consistent categorization of gene expression changes across individuals, as increased reproducibility was identified using this method.},
author = {Goyak, Katy M O and Johnson, Mary C and Strom, Stephen C and Omiecinski, Curtis J},
doi = {10.1016/j.taap.2008.04.024},
edition = {2008/05/10},
issn = {1096-0333},
journal = {Toxicol. Appl. Pharmacol.},
keywords = {Cells, Cultured,Chlorodiphenyl (54{\%} Chlorine)/pharmacology,Diethylhexyl Phthalate/pharmacology,Gene Expression Profiling/*methods,Gene Expression Regulation/*drug effects,Genome, Human,Hepatocytes/*drug effects/metabolism,Humans,Phenobarbital/pharmacology,Reproducibility of Results,Xenobiotics/*pharmacology},
language = {eng},
month = {sep},
number = {2},
pages = {216--224},
title = {{Expression profiling of interindividual variability following xenobiotic exposures in primary human hepatocyte cultures}},
url = {https://pubmed.ncbi.nlm.nih.gov/18559280 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2610447/},
volume = {231},
year = {2008}
}
@article{Maarleveld2013,
abstract = {Metabolic networks supply the energy and building blocks for cell growth and maintenance. Cells continuously rewire their metabolic networks in response to changes in environmental conditions to sustain fitness. Studies of the systemic properties of metabolic networks give insight into metabolic plasticity and robustness, and the ability of organisms to cope with different environments. Constraint-based stoichiometric modeling of metabolic networks has become an indispensable tool for such studies. Herein, we review the basic theoretical underpinnings of constraint-based stoichiometric modeling of metabolic networks. Basic concepts, such as stoichiometry, chemical moiety conservation, flux modes, flux balance analysis, and flux solution spaces, are explained with simple, illustrative examples. We emphasize the mathematical definitions and their network topological interpretations.},
author = {Maarleveld, Timo R and Khandelwal, Ruchir A and Olivier, Brett G and Teusink, Bas and Bruggeman, Frank J},
doi = {10.1002/biot.201200291},
edition = {2013/07/29},
issn = {1860-7314},
journal = {Biotechnol. J.},
keywords = {*Metabolic Networks and Pathways,*Models, Biological,Algorithms,Cells/metabolism,Computer Simulation,Constraint-based modeling,Flux balance analysis,Flux modes,Metabolic Flux Analysis,Metabolism,Optimal solution space},
language = {eng},
month = {sep},
number = {9},
pages = {997--1008},
publisher = {WILEY-VCH Verlag},
title = {{Basic concepts and principles of stoichiometric modeling of metabolic networks}},
url = {https://pubmed.ncbi.nlm.nih.gov/23893965 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4671265/},
volume = {8},
year = {2013}
}
@article{Igarashi2015,
abstract = {Toxicogenomics focuses on assessing the safety of compounds using gene expression profiles. Gene expression signatures from large toxicogenomics databases are expected to perform better than small databases in identifying biomarkers for the prediction and evaluation of drug safety based on a compound's toxicological mechanisms in animal target organs. Over the past 10 years, the Japanese Toxicogenomics Project consortium (TGP) has been developing a large-scale toxicogenomics database consisting of data from 170 compounds (mostly drugs) with the aim of improving and enhancing drug safety assessment. Most of the data generated by the project (e.g. gene expression, pathology, lot number) are freely available to the public via Open TG-GATEs (Toxicogenomics Project-Genomics Assisted Toxicity Evaluation System). Here, we provide a comprehensive overview of the database, including both gene expression data and metadata, with a description of experimental conditions and procedures used to generate the database. Open TG-GATEs is available from http://toxico.nibio.go.jp/english/index.html.},
author = {Igarashi, Yoshinobu and Nakatsu, Noriyuki and Yamashita, Tomoya and Ono, Atsushi and Ohno, Yasuo and Urushidani, Tetsuro and Yamada, Hiroshi},
doi = {10.1093/nar/gku955},
edition = {2014/10/13},
issn = {1362-4962},
journal = {Nucleic Acids Res.},
keywords = {*Databases,*Toxicogenetics,Animals,Biomarkers/metabolism,Genetic,Genomics,Humans,Internet,Kidney/drug effects/metabolism/pathology,Liver/drug effects/metabolism/pathology,Male,Rats,Sprague-Dawley,Transcriptome/*drug effects},
language = {eng},
month = {jan},
number = {Database issue},
pages = {D921--D927},
publisher = {Oxford University Press},
title = {{Open TG-GATEs: a large-scale toxicogenomics database}},
url = {https://pubmed.ncbi.nlm.nih.gov/25313160 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4384023/},
volume = {43},
year = {2015}
}
@article{LeCao2014b,
abstract = {Gene expression databases contain invaluable information about a range of cell states, but the question “Where is my gene of interest expressed?” remains one of the most difficult to systematically assess when relevant data is derived on different platforms. Barriers to integrating this data include disparities in data formats and scale, a lack of common identifiers, and the disproportionate contribution of a platform to the ‘batch effect'. There are few purpose-built cross-platform normalization strategies, and most of these fit data to an idealized data structure, which in turn may compromise gene expression comparisons between different platforms. YuGene addresses this gap by providing a simple transform that assigns a modified cumulative proportion value to each measurement, without losing essential underlying information on data distributions or experimental correlates. The Yugene transform is applied to individual samples and is suitable to apply to data with different distributions. Yugene is robust to combining datasets of different sizes, does not require global renormalization as new data is added, and does not require a common identifier. YuGene was benchmarked against commonly used normalization approaches, performing favorably in comparison to quantile (RMA), Z-score or rank methods. Implementation in the www.stemformatics.org resource provides users with expression queries across stem cell related datasets. Probe performance statistics including poorly performing (never expressed) probes, and examples of probes/genes expressed in a sample-restricted manner are provided. The YuGene software is implemented as an R package available from CRAN.},
author = {{L{\^{e}} Cao}, Kim-Anh and Rohart, Florian and McHugh, Leo and Korn, Othmar and Wells, Christine A},
doi = {https://doi.org/10.1016/j.ygeno.2014.03.001},
issn = {0888-7543},
journal = {Genomics},
keywords = {Cross platform normalization,Gene expression,Microarray},
number = {4},
pages = {239--251},
title = {{YuGene: A simple approach to scale gene expression data derived from different platforms for integrated analyses}},
url = {http://www.sciencedirect.com/science/article/pii/S0888754314000299},
volume = {103},
year = {2014}
}
@article{Carithers2015b,
abstract = {The Genotype-Tissue Expression (GTEx) project, sponsored by the NIH Common Fund, was established to study the correlation between human genetic variation and tissue-specific gene expression in non-diseased individuals. A significant challenge was the collection of high-quality biospecimens for extensive genomic analyses. Here we describe how a successful infrastructure for biospecimen procurement was developed and implemented by multiple research partners to support the prospective collection, annotation, and distribution of blood, tissues, and cell lines for the GTEx project. Other research projects can follow this model and form beneficial partnerships with rapid autopsy and organ procurement organizations to collect high quality biospecimens and associated clinical data for genomic studies. Biospecimens, clinical and genomic data, and Standard Operating Procedures guiding biospecimen collection for the GTEx project are available to the research community.},
annote = {doi: 10.1089/bio.2015.0032},
author = {Carithers, Latarsha J and Ardlie, Kristin and Barcus, Mary and Branton, Philip A and Britton, Angela and Buia, Stephen A and Compton, Carolyn C and DeLuca, David S and Peter-Demchok, Joanne and Gelfand, Ellen T and Guan, Ping and Korzeniewski, Greg E and Lockhart, Nicole C and Rabiner, Chana A and Rao, Abhi K and Robinson, Karna L and Roche, Nancy V and Sawyer, Sherilyn J and Segr{\`{e}}, Ayellet V and Shive, Charles E and Smith, Anna M and Sobin, Leslie H and Undale, Anita H and Valentino, Kimberly M and Vaught, Jim and Young, Taylor R and Moore, Helen M},
doi = {10.1089/bio.2015.0032},
issn = {1947-5535},
journal = {Biopreserv. Biobank.},
month = {oct},
number = {5},
pages = {311--319},
publisher = {Mary Ann Liebert, Inc., publishers},
title = {{A Novel Approach to High-Quality Postmortem Tissue Procurement: The GTEx Project}},
url = {https://doi.org/10.1089/bio.2015.0032},
volume = {13},
year = {2015}
}
@article{Blais2017,
abstract = {The laboratory rat has been used as a surrogate to study human biology for more than a century. Here we present the first genome-scale network reconstruction of Rattus norvegicus metabolism, iRno, and a significantly improved reconstruction of human metabolism, iHsa. These curated models comprehensively capture metabolic features known to distinguish rats from humans including vitamin C and bile acid synthesis pathways. After reconciling network differences between iRno and iHsa, we integrate toxicogenomics data from rat and human hepatocytes, to generate biomarker predictions in response to 76 drugs. We validate comparative predictions for xanthine derivatives with new experimental data and literature-based evidence delineating metabolite biomarkers unique to humans. Our results provide mechanistic insights into species-specific metabolism and facilitate the selection of biomarkers consistent with rat and human biology. These models can serve as powerful computational platforms for contextualizing experimental data and making functional predictions for clinical and basic science applications.},
author = {Blais, Edik M and Rawls, Kristopher D and Dougherty, Bonnie V and Li, Zhuo I and Kolling, Glynis L and Ye, Ping and Wallqvist, Anders and Papin, Jason A},
doi = {10.1038/ncomms14250},
issn = {2041-1723},
journal = {Nat. Commun.},
number = {1},
pages = {14250},
title = {{Reconciled rat and human metabolic networks for comparative toxicogenomics and biomarker predictions}},
url = {https://doi.org/10.1038/ncomms14250},
volume = {8},
year = {2017}
}
@article{Liu2020c,
abstract = {In vitro toxicogenomics (TGx) has the potential to replace or supplement animal  studies. However, TGx studies often suffer from a limited sample size and cell types. Meanwhile, transcriptomic data have been generated for tens of thousands of compounds using cancer cell lines mainly for drug efficacy screening. Here, we asked the question of whether these types of transcriptomic data can be used to support toxicity assessment. We compared transcriptomic profiles from three cancer lines (HL60, MCF7, and PC3) from the CMap data set with those using primary hepatocytes or in vivo repeated dose studies from the Open TG-GATEs database by using our previously reported pair ranking (PRank) method. We observed an encouraging similarity between HL60 and human primary hepatocytes (PRank score = 0.70), suggesting the two cellular assays could be potentially interchangeable. When the analysis was limited to drug-induced liver injury (DILI)-related compounds or genes, the cancer cell lines exhibited promise in DILI assessment in comparison with conventional TGx systems (i.e., human primary hepatocytes or rat in vivo repeated dose). Also, some toxicity-related pathways, such as PPAR signaling pathways and fatty acid-related pathways, were preserved across various assay systems, indicating the assay transferability is biological process-specific. Furthermore, we established a potential application of transcriptomic profiles of cancer cell lines for studying immune-related biological processes involving some specific cell types. Moreover, if PRank analysis was focused on only landmark genes from L1000 or S1500+, the advantage of cancer cell lines over the TGx studies was limited. In conclusion, repurposing of existing cancer-related transcript profiling data has great potential for toxicity assessment, particularly in predicting DILI.},
annote = {From Duplicate 1 (Can Transcriptomic Profiles from Cancer Cell Lines Be Used for Toxicity Assessment? - Liu, Zhichao; Zhu, Liyuan; Thakkar, Shraddha; Roberts, Ruth; Tong, Weida)

doi: 10.1021/acs.chemrestox.9b00288},
author = {Liu, Zhichao and Zhu, Liyuan and Thakkar, Shraddha and Roberts, Ruth and Tong, Weida},
doi = {10.1021/acs.chemrestox.9b00288},
issn = {0893-228X},
journal = {Chem. Res. Toxicol.},
language = {eng},
month = {jan},
number = {1},
pages = {271--280},
pmid = {31808688},
publisher = {American Chemical Society},
title = {{Can Transcriptomic Profiles from Cancer Cell Lines Be Used for Toxicity Assessment?}},
url = {https://doi.org/10.1021/acs.chemrestox.9b00288},
volume = {33},
year = {2020}
}
@article{Rao2018b,
abstract = {Gene expression profiling is a useful tool to predict and interrogate mechanisms of  toxicity. RNA-Seq technology has emerged as an attractive alternative to traditional microarray platforms for conducting transcriptional profiling. The objective of this work was to compare both transcriptomic platforms to determine whether RNA-Seq offered significant advantages over microarrays for toxicogenomic studies. RNA samples from the livers of rats treated for 5 days with five tool hepatotoxicants ($\alpha$-naphthylisothiocyanate/ANIT, carbon tetrachloride/CCl(4), methylenedianiline/MDA, acetaminophen/APAP, and diclofenac/DCLF) were analyzed with both gene expression platforms (RNA-Seq and microarray). Data were compared to determine any potential added scientific (i.e., better biological or toxicological insight) value offered by RNA-Seq compared to microarrays. RNA-Seq identified more differentially expressed protein-coding genes and provided a wider quantitative range of expression level changes when compared to microarrays. Both platforms identified a larger number of differentially expressed genes (DEGs) in livers of rats treated with ANIT, MDA, and CCl(4) compared to APAP and DCLF, in agreement with the severity of histopathological findings. Approximately 78{\%} of DEGs identified with microarrays overlapped with RNA-Seq data, with a Spearman's correlation of 0.7 to 0.83. Consistent with the mechanisms of toxicity of ANIT, APAP, MDA and CCl(4), both platforms identified dysregulation of liver relevant pathways such as Nrf2, cholesterol biosynthesis, eiF2, hepatic cholestasis, glutathione and LPS/IL-1 mediated RXR inhibition. RNA-Seq data showed additional DEGs that not only significantly enriched these pathways, but also suggested modulation of additional liver relevant pathways. In addition, RNA-Seq enabled the identification of non-coding DEGs that offer a potential for improved mechanistic clarity. Overall, these results indicate that RNA-Seq is an acceptable alternative platform to microarrays for rat toxicogenomic studies with several advantages. Because of its wider dynamic range as well as its ability to identify a larger number of DEGs, RNA-Seq may generate more insight into mechanisms of toxicity. However, more extensive reference data will be necessary to fully leverage these additional RNA-Seq data, especially for non-coding sequences.},
author = {Rao, Mohan S and {Van Vleet}, Terry R and Ciurlionis, Rita and Buck, Wayne R and Mittelstadt, Scott W and Blomme, Eric A G and Liguori, Michael J},
doi = {10.3389/fgene.2018.00636},
issn = {1664-8021 (Print)},
journal = {Front. Genet.},
language = {eng},
pages = {636},
pmid = {30723492},
title = {{Comparison of RNA-Seq and Microarray Gene Expression Platforms for the Toxicogenomic  Evaluation of Liver From Short-Term Rat Toxicity Studies.}},
volume = {9},
year = {2018}
}
@article{McCall2010b,
abstract = {Robust multiarray analysis (RMA) is the most widely used preprocessing algorithm for  Affymetrix and Nimblegen gene expression microarrays. RMA performs background correction, normalization, and summarization in a modular way. The last 2 steps require multiple arrays to be analyzed simultaneously. The ability to borrow information across samples provides RMA various advantages. For example, the summarization step fits a parametric model that accounts for probe effects, assumed to be fixed across arrays, and improves outlier detection. Residuals, obtained from the fitted model, permit the creation of useful quality metrics. However, the dependence on multiple arrays has 2 drawbacks: (1) RMA cannot be used in clinical settings where samples must be processed individually or in small batches and (2) data sets preprocessed separately are not comparable. We propose a preprocessing algorithm, frozen RMA (fRMA), which allows one to analyze microarrays individually or in small batches and then combine the data for analysis. This is accomplished by utilizing information from the large publicly available microarray databases. In particular, estimates of probe-specific effects and variances are precomputed and frozen. Then, with new data sets, these are used in concert with information from the new arrays to normalize and summarize the data. We find that fRMA is comparable to RMA when the data are analyzed as a single batch and outperforms RMA when analyzing multiple batches. The methods described here are implemented in the R package fRMA and are currently available for download from the software section of http://rafalab.jhsph.edu.},
author = {McCall, Matthew N and Bolstad, Benjamin M and Irizarry, Rafael A},
doi = {10.1093/biostatistics/kxp059},
issn = {1468-4357 (Electronic)},
journal = {Biostatistics},
keywords = {Algorithms,Biometry,Databases, Genetic,Humans,Internet,Oligonucleotide Array Sequence Analysis,Software,methods},
language = {eng},
month = {apr},
number = {2},
pages = {242--253},
pmid = {20097884},
title = {{Frozen robust multiarray analysis (fRMA).}},
volume = {11},
year = {2010}
}
@misc{Pawar2019,
abstract = {A plethora of databases exist online that can assist in in silico chemical or drug safety assessment. However, a systematic review and grouping of databases, based on purpose and information content, consolidated in a single source, has been lacking. To resolve this issue, this review provides a comprehensive listing of the key in silico data resources relevant to: chemical identity and properties, drug action, toxicology (including nano-material toxicity), exposure, omics, pathways, Absorption, Distribution, Metabolism and Elimination (ADME) properties, clinical trials, pharmacovigilance, patents-related databases, biological (genes, enzymes, proteins, other macromolecules etc.) databases, protein-protein interactions (PPIs), environmental exposure related, and finally databases relating to animal alternatives in support of 3Rs policies. More than nine hundred databases were identified and reviewed against criteria relating to accessibility, data coverage, interoperability or application programming interface (API), appropriate identifiers, types of in vitro, in vivo,-clinical or other data recorded and suitability for modelling, read-across, or similarity searching. This review also specifically addresses the need for solutions for mapping and integration of databases into a common platform for better translatability of preclinical data to clinical data.},
author = {Pawar, Gopal and Madden, Judith C and Ebbrell, David and Firman, James W and Cronin, Mark T D},
booktitle = {Front. Pharmacol.  },
isbn = {1663-9812},
pages = {561},
title = {{In Silico Toxicology Data Resources to Support Read-Across and (Q)SAR   }},
url = {https://www.frontiersin.org/article/10.3389/fphar.2019.00561},
volume = {10      },
year = {2019}
}
@article{Zeilinger2016b,
abstract = {In vitro liver cell culture models are gaining increasing importance in  pharmacological and toxicological research. The source of cells used is critical for the relevance and the predictive value of such models. Primary human hepatocytes (PHH) are currently considered to be the gold standard for hepatic in vitro culture models, since they directly reflect the specific metabolism and functionality of the human liver; however, the scarcity and difficult logistics of PHH have driven researchers to explore alternative cell sources, including liver cell lines and pluripotent stem cells. Liver cell lines generated from hepatomas or by genetic manipulation are widely used due to their good availability, but they are generally altered in certain metabolic functions. For the past few years, adult and pluripotent stem cells have been attracting increasing attention, due their ability to proliferate and to differentiate into hepatocyte-like cells in vitro However, controlling the differentiation of these cells is still a challenge. This review gives an overview of the major human cell sources under investigation for in vitro liver cell culture models, including primary human liver cells, liver cell lines, and stem cells. The promises and challenges of different cell types are discussed with a focus on the complex 2D and 3D culture approaches under investigation for improving liver cell functionality in vitro Finally, the specific application options of individual cell sources in pharmacological research or disease modeling are described.},
author = {Zeilinger, Katrin and Freyer, Nora and Damm, Georg and Seehofer, Daniel and Kn{\"{o}}spel, Fanny},
doi = {10.1177/1535370216657448},
issn = {1535-3699 (Electronic)},
journal = {Exp. Biol. Med. (Maywood).},
keywords = {Cell Culture Techniques,Cell Line,Cells, Cultured,Hepatocytes,Humans,In Vitro Techniques,Liver,Stem Cells,cytology,metabolism},
language = {eng},
month = {sep},
number = {15},
pages = {1684--1698},
pmid = {27385595},
title = {{Cell sources for in vitro human liver cell culture models.}},
volume = {241},
year = {2016}
}
@article{DeAbrew2015b,
abstract = {High-content data have the potential to inform mechanism of action for toxicants.  However, most data to support this notion have been generated in vivo. Because many cell lines and primary cells maintain a differentiated cell phenotype, it is possible that cells grown in culture may also be useful in predictive toxicology via high-content approaches such as whole-genome microarray. We evaluated global changes in gene expression in primary rat hepatocytes exposed to two concentrations of ten hepatotoxicants: acetaminophen (APAP), $\beta$-naphthoflavone (BNF), chlorpromazine (CPZ), clofibrate (CLO), bis(2-ethylhexyl)phthalate (DEHP), diisononyl phthalate (DINP), methapyrilene (MP), valproic acid (VPA), phenobarbital (PB) and WY14643 at two separate time points. These compounds were selected to cover a range of mechanisms of toxicity, with some overlap in expected mechanism to address the question of how predictive gene expression analysis is, for a given mode of action. Gene expression microarray analysis was performed on cells after 24h and 48h of exposure to each chemical using Affymetrix microarrays. Cluster analysis suggests that the primary hepatocyte model was capable of responding to these hepatotoxicants, with changes in gene expression that appear to be mode of action-specific. Among the different methods used for analysis of the data, a combination method that used pathways (MOAs) to filter total probesets provided the most robust analysis. The analysis resulted in the phthalates clustering closely together, with the two other peroxisome proliferators, CLO and WY14643, eliciting similar responses at the whole-genome and pathway levels. The Cyp inducers PB, MP, CPZ and BNF also clustered together. VPA and APAP had profiles that were unique. A similar analysis was performed on externally available (TG-GATES) in vivo data for 6 of the chemicals (APAP, CLO, CPZ, MP, MP and WY14643) and compared to the in vitro result. These results indicate that transcription profiling using an in vitro assay may offer pertinent biological data to support predictions of in vivo hepatotoxicity potential.},
author = {{De Abrew}, K Nadira and Overmann, Gary J and Adams, Rachel L and Tiesman, Jay P and Dunavent, John and Shan, Yuqing K and Carr, Gregory J and Daston, George P and Naciff, Jorge M},
doi = {10.1016/j.tox.2014.11.008},
issn = {1879-3185 (Electronic)},
journal = {Toxicology},
keywords = {Animals,Cells, Cultured,Chemical and Drug Induced Liver Injury,Cluster Analysis,Dose-Response Relationship, Drug,Gene Expression Profiling,Gene Expression Regulation,Genetic Markers,Hepatocytes,Liver,Male,Oligonucleotide Array Sequence Analysis,Proteins,Rats, Sprague-Dawley,Time Factors,Toxicogenetics,drug effects,genetics,metabolism,methods},
language = {eng},
month = {feb},
pages = {29--39},
pmid = {25475144},
title = {{A novel transcriptomics based in vitro method to compare and predict hepatotoxicity  based on mode of action.}},
volume = {328},
year = {2015}
}
@misc{Liu2019b,
abstract = {Dozens of normalization methods for correcting experimental variation and bias in high-throughput expression data have been developed during the last two decades. Up to 23 methods among them consider the skewness of expression data between sample states, which are even more than the conventional methods, such as loess and quantile. From the perspective of reference selection, we classified the normalization methods for skewed expression data into three categories, data-driven reference, foreign reference, and entire gene set. We separately introduced and summarized these normalization methods designed for gene expression data with global shift between compared conditions, including both microarray and RNA-seq, based on the reference selection strategies. To our best knowledge, this is the most comprehensive review of available preprocessing algorithms for the unbalanced transcriptome data. The anatomy and summarization of these methods shed light on the understanding and appropriate application of preprocessing methods.},
author = {Liu, Xueyan and Li, Nan and Liu, Sheng and Wang, Jun and Zhang, Ning and Zheng, Xubin and Leung, Kwong-Sak and Cheng, Lixin},
booktitle = {Front. Bioeng. Biotechnol.  },
isbn = {2296-4185},
pages = {358},
title = {{Normalization Methods for the Analysis of Unbalanced Transcriptome Data: A Review   }},
url = {https://www.frontiersin.org/article/10.3389/fbioe.2019.00358},
volume = {7      },
year = {2019}
}
@article{VandenHof2014,
annote = {doi: 10.1021/tx4004165},
author = {{Van den Hof}, Wim F P M and Coonen, Maarten L J and van Herwijnen, Marcel and Brauers, Karen and Wodzig, Will K W H and van Delft, Joost H M and Kleinjans, Jos C S},
doi = {10.1021/tx4004165},
issn = {0893-228X},
journal = {Chem. Res. Toxicol.},
month = {mar},
number = {3},
pages = {433--442},
publisher = {American Chemical Society},
title = {{Classification of Hepatotoxicants Using HepG2 Cells: A Proof of Principle Study}},
url = {https://doi.org/10.1021/tx4004165},
volume = {27},
year = {2014}
}
@article{Wang2016b,
abstract = {Motivation: Adverse drug reactions (ADRs) are a central consideration during drug development. Here we present a machine learning classifier to prioritize ADRs for approved drugs and pre-clinical small-molecule compounds by combining chemical structure (CS) and gene expression (GE) features. The GE data is from the Library of Integrated Network-based Cellular Signatures (LINCS) L1000 dataset that measured changes in GE before and after treatment of human cells with over 20 000 small-molecule compounds including most of the FDA-approved drugs. Using various benchmarking methods, we show that the integration of GE data with the CS of the drugs can significantly improve the predictability of ADRs. Moreover, transforming GE features to enrichment vectors of biological terms further improves the predictive capability of the classifiers. The most predictive biological-term features can assist in understanding the drug mechanisms of action. Finally, we applied the classifier to all  {\textgreater}20 000 small-molecules profiled, and developed a web portal for browsing and searching predictive small-molecule/ADR connections.Availability and Implementation: The interface for the adverse event predictions for the  {\textgreater}20 000 LINCS compounds is available at http://maayanlab.net/SEP-L1000/.Contact:avi.maayan@mssm.eduSupplementary information: Supplementary data are available at Bioinformatics online.},
author = {Wang, Zichen and Clark, Neil R and Ma'ayan, Avi},
doi = {10.1093/bioinformatics/btw168},
issn = {1367-4803},
journal = {Bioinformatics},
month = {aug},
number = {15},
pages = {2338--2345},
title = {{Drug-induced adverse events prediction with the LINCS L1000 data}},
url = {https://doi.org/10.1093/bioinformatics/btw168},
volume = {32},
year = {2016}
}
@article{Opdam2017,
abstract = {Genome-scale models of metabolism can illuminate the molecular basis of cell  phenotypes. Since some enzymes are only active in specific cell types, several algorithms use omics data to construct cell-line- and tissue-specific metabolic models from genome-scale models. However, these methods are often not rigorously benchmarked, and it is unclear how algorithm and parameter selection (e.g., gene expression thresholds, metabolic constraints) affects model content and predictive accuracy. To investigate this, we built hundreds of models of four different cancer cell lines using six algorithms, four gene expression thresholds, and three sets of metabolic constraints. Model content varied substantially across different parameter sets, but the algorithms generally increased accuracy in gene essentiality predictions. However, model extraction method choice had the largest impact on model accuracy. We further highlight how assumptions during model development influence model prediction accuracy. These insights will guide further development of context-specific models, thus more accurately resolving genotype-phenotype relationships.},
author = {Opdam, Sjoerd and Richelle, Anne and Kellman, Benjamin and Li, Shanzhong and Zielinski, Daniel C and Lewis, Nathan E},
doi = {10.1016/j.cels.2017.01.010},
issn = {2405-4712 (Print)},
journal = {Cell Syst.},
keywords = {Algorithms,Animals,Forecasting,Genome,Genomics,Humans,Metabolomics,Models, Biological,Models, Theoretical,Systems Biology,methods},
language = {eng},
month = {mar},
number = {3},
pages = {318--329.e6},
pmid = {28215528},
title = {{A Systematic Evaluation of Methods for Tailoring Genome-Scale Metabolic Models.}},
volume = {4},
year = {2017}
}
@article{Mav2018b,
abstract = {Changes in gene expression can help reveal the mechanisms of disease processes and the mode of action for toxicities and adverse effects on cellular responses induced by exposures to chemicals, drugs and environment agents. The U.S. Tox21 Federal collaboration, which currently quantifies the biological effects of nearly 10,000 chemicals via quantitative high-throughput screening(qHTS) in in vitro model systems, is now making an effort to incorporate gene expression profiling into the existing battery of assays. Whole transcriptome analyses performed on large numbers of samples using microarrays or RNA-Seq is currently cost-prohibitive. Accordingly, the Tox21 Program is pursuing a high-throughput transcriptomics (HTT) method that focuses on the targeted detection of gene expression for a carefully selected subset of the transcriptome that potentially can reduce the cost by a factor of 10-fold, allowing for the analysis of larger numbers of samples. To identify the optimal transcriptome subset, genes were sought that are (1) representative of the highly diverse biological space, (2) capable of serving as a proxy for expression changes in unmeasured genes, and (3) sufficient to provide coverage of well described biological pathways. A hybrid method for gene selection is presented herein that combines data-driven and knowledge-driven concepts into one cohesive method. Our approach is modular, applicable to any species, and facilitates a robust, quantitative evaluation of performance. In particular, we were able to perform gene selection such that the resulting set of “sentinel genes” adequately represents all known canonical pathways from Molecular Signature Database (MSigDB v4.0) and can be used to infer expression changes for the remainder of the transcriptome. The resulting computational model allowed us to choose a purely data-driven subset of 1500 sentinel genes, referred to as the S1500 set, which was then augmented using a knowledge-driven selection of additional genes to create the final S1500+ gene set. Our results indicate that the sentinel genes selected can be used to accurately predict pathway perturbations and biological relationships for samples under study.},
author = {Mav, Deepak and Shah, Ruchir R and Howard, Brian E and Auerbach, Scott S and Bushel, Pierre R and Collins, Jennifer B and Gerhold, David L and Judson, Richard S and Karmaus, Agnes L and Maull, Elizabeth A and Mendrick, Donna L and Merrick, B Alex and Sipes, Nisha S and Svoboda, Daniel and Paules, Richard S},
journal = {PLoS One},
month = {feb},
number = {2},
pages = {e0191105},
publisher = {Public Library of Science},
title = {{A hybrid gene selection approach to create the S1500+ targeted gene sets for use in high-throughput transcriptomics}},
url = {https://doi.org/10.1371/journal.pone.0191105},
volume = {13},
year = {2018}
}
@article{Lamb2006,
abstract = {To pursue a systematic approach to the discovery of functional connections among diseases, genetic perturbation, and drug action, we have created the first installment of a reference collection of gene-expression profiles from cultured human cells treated with bioactive small molecules, together with pattern-matching software to mine these data. We demonstrate that this "Connectivity Map" resource can be used to find connections among small molecules sharing a mechanism of action, chemicals and physiological processes, and diseases and drugs. These results indicate the feasibility of the approach and suggest the value of a large-scale community Connectivity Map project.},
author = {Lamb, Justin and Crawford, Emily D. and Peck, David and Modell, Joshua W. and Blat, Irene C. and Wrobel, Matthew J. and Lerner, Jim and Brunet, Jean Philippe and Subramanian, Aravind and Ross, Kenneth N. and Reich, Michael and Hieronymus, Haley and Wei, Guo and Armstrong, Scott A. and Haggarty, Stephen J. and Clemons, Paul A. and Wei, Ru and Carr, Steven A. and Lander, Eric S. and Golub, Todd R.},
doi = {10.1126/science.1132939},
issn = {00368075},
journal = {Science (80-. ).},
month = {sep},
number = {5795},
pages = {1929--1935},
pmid = {17008526},
title = {{The connectivity map: Using gene-expression signatures to connect small molecules, genes, and disease}},
url = {https://www.sciencemag.org/lookup/doi/10.1126/science.1132939},
volume = {313},
year = {2006}
}
@article{Kiyosawa2009b,
abstract = {As information regarding microarray data sets and toxicogenomic biomarkers grows  rapidly, the process of analyzing data and interpreting the results is increasingly complicated. To facilitate data analysis, a simple expression ratio-based scoring method called the TGP1 score was previously proposed [Kiyosawa, N., Shiwaku, K., Hirode, M., Omura, K., Uehara, T., Shimizu, T., Mizukawa, Y., Miyagishima, T., Ono, A., Nagao, T., Urushidani, T., 2006. Utilization of a one-dimensional score for surveying chemical-induced changes in expression levels of multiple biomarker gene sets using a large-scale toxicogenomics database. J. Toxicol. Sci. 31, 433-448]. Although the TGP1 score has demonstrated its efficacy for rapid comprehension of large-scale toxicogenomic data sets, inclusion of low quality gene expression data in the biomarker gene set produced flaws in the calculated score. To overcome this shortcoming, we tested a new scoring method called the differentially expressed gene score (D-score), where Detection Call as well as signal log ratios generated by MAS5 algorithm on Affymetrix GeneChip data were considered for the calculation. Four prototypical toxicants, namely acetaminophen, phenobarbital, clofibrate and acetamidofluorene, were used for detailed analysis. A toxicogenomics database (TG-GATEs) was utilized as a reference data set. The D-score successfully alleviated the effects of low quality data on the score calculation, and captured the overall direction of expression changes as well as the magnitude of expression change level of a set of genes, highlighting the affected toxicological endpoints elicited by chemical treatment. The D-score will be useful for high-throughput toxicity screening using a toxicogenomic database and biomarkers.},
author = {Kiyosawa, Naoki and Ando, Yosuke and Watanabe, Kyoko and Niino, Noriyo and Manabe, Sunao and Yamoto, Takashi},
doi = {10.1016/j.toxlet.2009.03.011},
issn = {1879-3169 (Electronic)},
journal = {Toxicol. Lett.},
keywords = {2-Acetylaminofluorene,Acetaminophen,Algorithms,Animals,Biomarkers,Clofibrate,Data Interpretation, Statistical,Databases, Genetic,Endpoint Determination,Gene Expression,Liver,Male,Oligonucleotide Array Sequence Analysis,Phenobarbital,Rats,Rats, Sprague-Dawley,Toxicity Tests,Toxicogenetics,analysis,drug effects,metabolism,methods,statistics {\&} numerical data,toxicity},
language = {eng},
month = {jul},
number = {2},
pages = {91--97},
pmid = {19446240},
title = {{Scoring multiple toxicological endpoints using a toxicogenomic database.}},
volume = {188},
year = {2009}
}
@article{Chen2016b,
author = {Chen, Minjun and Suzuki, Ayako and Thakkar, Shraddha and Yu, Ke and Hu, Chuchu and Tong, Weida},
doi = {10.1016/j.drudis.2016.02.015},
issn = {1878-5832 (Electronic)},
journal = {Drug Discov. Today},
keywords = {Chemical and Drug Induced Liver Injury,Databases, Factual,Drug Labeling,Humans,Pharmaceutical Preparations,Risk,classification},
language = {eng},
month = {apr},
number = {4},
pages = {648--653},
pmid = {26948801},
title = {{DILIrank: the largest reference drug list ranked by the risk for developing  drug-induced liver injury in humans.}},
volume = {21},
year = {2016}
}
@article{Ramaiahgari2017,
abstract = {Effective prediction of human responses to chemical and drug exposure is of critical importance in environmental toxicology research and drug development. While significant progress has been made to address this challenge using invitro liver models, these approaches often fail due to inadequate tissue model functionality. Herein, we describe the development, optimization, and characterization of a novel three-dimensional (3D) spheroid model using differentiated HepaRG cells that achieve and maintain physiologically relevant levels of xenobiotic metabolism (CYP1A2, CYP2B6, and CYP3A4/5). This invitro model maintains a stable phenotype over multiple weeks in both 96- and 384-well formats, supports highly reproducible tissue-like architectures and models pharmacologically- and environmentally important hepatic receptor pathways (ie AhR, CAR, and PXR) analogous to primary human hepatocyte cultures. HepaRG spheroid cultures use 50–100× fewer cells than conventional two dimensional cultures, and enable the identification of metabolically activated toxicants. Spheroid size, time in culture and culture media composition were important factors affecting basal levels of xenobiotic metabolism and liver enzyme inducibility with activators of hepatic receptors AhR, CAR and PXR. Repeated exposure studies showed higher sensitivity than traditional 2D cultures in identifying compounds that cause liver injury and metabolism-dependent toxicity. This platform combines the well-documented impact of 3D culture configuration for improved tissue functionality and longevity with the requisite throughput and repeatability needed for year-over-year toxicology screening.},
author = {Ramaiahgari, Sreenivasa C and Waidyanatha, Suramya and Dixon, Darlene and DeVito, Michael J and Paules, Richard S and Ferguson, Stephen S},
doi = {10.1093/toxsci/kfx122},
issn = {1096-6080},
journal = {Toxicol. Sci.},
month = {jun},
number = {1},
pages = {124--136},
title = {{From the Cover: Three-Dimensional (3D) HepaRG Spheroid Model With Physiologically Relevant Xenobiotic Metabolism Competence and Hepatocyte Functionality for Liver Toxicity Screening}},
url = {https://doi.org/10.1093/toxsci/kfx122},
volume = {159},
year = {2017}
}
@misc{Hoofnagle2013,
author = {Hoofnagle, Jay H and Serrano, Jose and Knoben, James E and Navarro, Victor J},
booktitle = {Hepatology},
doi = {10.1002/hep.26175},
issn = {1527-3350 (Electronic)},
keywords = {Chemical and Drug Induced Liver Injury,Humans,Information Dissemination,Internet,National Institute of Diabetes and Digestive and K,United States,diagnosis,therapy,trends},
language = {eng},
month = {mar},
number = {3},
pages = {873--874},
pmid = {23456678},
title = {{LiverTox: a website on drug-induced liver injury.}},
volume = {57},
year = {2013}
}
@article{Yang2019e,
abstract = {The widespread applications in microarray technology have produced the vast quantity  of publicly available gene expression datasets. However, analysis of gene expression data using biostatistics and machine learning approaches is a challenging task due to (1) high noise; (2) small sample size with high dimensionality; (3) batch effects and (4) low reproducibility of significant biomarkers. These issues reveal the complexity of gene expression data, thus significantly obstructing microarray technology in clinical applications. The integrative analysis offers an opportunity to address these issues and provides a more comprehensive understanding of the biological systems, but current methods have several limitations. This work leverages state of the art machine learning development for multiple gene expression datasets integration, classification and identification of significant biomarkers. We design a novel integrative framework, MVIAm - Multi-View based Integrative Analysis of microarray data for identifying biomarkers. It applies multiple cross-platform normalization methods to aggregate multiple datasets into a multi-view dataset and utilizes a robust learning mechanism Multi-View Self-Paced Learning (MVSPL) for gene selection in cancer classification problems. We demonstrate the capabilities of MVIAm using simulated data and studies of breast cancer and lung cancer, it can be applied flexibly and is an effective tool for facing the four challenges of gene expression data analysis. Our proposed model makes microarray integrative analysis more systematic and expands its range of applications.},
author = {Yang, Zi-Yi and Liu, Xiao-Ying and Shu, Jun and Zhang, Hui and Ren, Yan-Qiong and Xu, Zong-Ben and Liang, Yong},
doi = {10.1038/s41598-019-49967-4},
issn = {2045-2322 (Electronic)},
journal = {Sci. Rep.},
language = {eng},
month = {sep},
number = {1},
pages = {13504},
pmid = {31534156},
title = {{Multi-view based integrative analysis of gene expression data for identifying  biomarkers.}},
volume = {9},
year = {2019}
}
@article{Edgar2002b,
abstract = {The Gene Expression Omnibus (GEO) project was initiated in response to the growing  demand for a public repository for high-throughput gene expression data. GEO provides a flexible and open design that facilitates submission, storage and retrieval of heterogeneous data sets from high-throughput gene expression and genomic hybridization experiments. GEO is not intended to replace in house gene expression databases that benefit from coherent data sets, and which are constructed to facilitate a particular analytic method, but rather complement these by acting as a tertiary, central data distribution hub. The three central data entities of GEO are platforms, samples and series, and were designed with gene expression and genomic hybridization experiments in mind. A platform is, essentially, a list of probes that define what set of molecules may be detected. A sample describes the set of molecules that are being probed and references a single platform used to generate its molecular abundance data. A series organizes samples into the meaningful data sets which make up an experiment. The GEO repository is publicly accessible through the World Wide Web at http://www.ncbi.nlm.nih.gov/geo.},
author = {Edgar, Ron and Domrachev, Michael and Lash, Alex E},
doi = {10.1093/nar/30.1.207},
issn = {1362-4962 (Electronic)},
journal = {Nucleic Acids Res.},
keywords = {Animals,Communication,Database Management Systems,Databases, Genetic,Forecasting,Gene Expression Profiling,Genome,Humans,Information Storage and Retrieval,Internet,National Library of Medicine (U.S.),Oligonucleotide Array Sequence Analysis,United States},
language = {eng},
month = {jan},
number = {1},
pages = {207--210},
pmid = {11752295},
title = {{Gene Expression Omnibus: NCBI gene expression and hybridization array data  repository.}},
volume = {30},
year = {2002}
}
@article{Lee2014,
abstract = {Isolated human primary hepatocytes are an essential in vitro model for basic and  clinical research. For successful application as a model, isolated hepatocytes need to have a good viability and be available in sufficient yield. Therefore, this study aims to identify donor characteristics, intra-operative factors, tissue processing and cell isolation parameters that affect the viability and yield of human hepatocytes. Remnant liver pieces from tissue designated as surgical waste were collected from 1034 donors with informed consent. Human hepatocytes were isolated by a two-step collagenase perfusion technique with modifications and hepatocyte yield and viability were subsequently determined. The accompanying patient data was collected and entered into a database. Univariate analyses found that the viability and the yield of hepatocytes were affected by many of the variables examined. Multivariate analyses were then carried out to confirm the factors that have a significant relationship with the viability and the yield. It was found that the viability of hepatocytes was significantly decreased by the presence of fibrosis, liver fat and with increasing gamma-glutamyltranspeptidase activity and bilirubin content. Yield was significantly decreased by the presence of liver fat, septal fibrosis, with increasing aspartate aminotransferase activity, cold ischemia times and weight of perfused liver. However, yield was significantly increased by chemotherapy treatment. In conclusion, this study determined the variables that have a significant effect on the viability and the yield of isolated human hepatocytes. These variables have been used to generate an algorithm that can calculate projected viability and yield of isolated human hepatocytes. In this way, projected viability can be determined even before isolation of hepatocytes, so that donors that result in high viability and yield can be identified. Further, if the viability and yield of the isolated hepatocytes is lower than expected, this will highlight a methodological problem that can be addressed.},
author = {Lee, Serene M L and Schelcher, Celine and Laubender, R{\"{u}}diger P and Fr{\"{o}}se, Natalja and Thasler, Reinhard M K and Schiergens, Tobias S and Mansmann, Ulrich and Thasler, Wolfgang E},
doi = {10.1371/journal.pone.0107567},
issn = {1932-6203 (Electronic)},
journal = {PLoS One},
keywords = {Age Factors,Algorithms,Aspartate Aminotransferases,Bilirubin,Body Mass Index,Cell Separation,Cell Survival,Cells, Cultured,Collagenases,Female,Fibrosis,Humans,Liver,Male,Sex Factors,Tissue Donors,cytology,gamma-Glutamyltransferase,metabolism,methods,pathology},
language = {eng},
number = {10},
pages = {e107567},
pmid = {25313881},
title = {{An algorithm that predicts the viability and the yield of human hepatocytes isolated  from remnant liver pieces obtained from liver resections.}},
volume = {9},
year = {2014}
}
@article{Schubert2018,
abstract = {Aberrant cell signaling can cause cancer and other diseases and is a focal point of drug research. A common approach is to infer signaling activity of pathways from gene expression. However, mapping gene expression to pathway components disregards the effect of post-translational modifications, and downstream signatures represent very specific experimental conditions. Here we present PROGENy, a method that overcomes both limitations by leveraging a large compendium of publicly available perturbation experiments to yield a common core of Pathway RespOnsive GENes. Unlike pathway mapping methods, PROGENy can (i) recover the effect of known driver mutations, (ii) provide or improve strong markers for drug indications, and (iii) distinguish between oncogenic and tumor suppressor pathways for patient survival. Collectively, these results show that PROGENy accurately infers pathway activity from gene expression in a wide range of conditions.},
author = {Schubert, Michael and Klinger, Bertram and Kl{\"{u}}nemann, Martina and Sieber, Anja and Uhlitz, Florian and Sauer, Sascha and Garnett, Mathew J and Bl{\"{u}}thgen, Nils and Saez-Rodriguez, Julio},
doi = {10.1038/s41467-017-02391-6},
issn = {2041-1723},
journal = {Nat. Commun.},
number = {1},
pages = {20},
title = {{Perturbation-response genes reveal signaling footprints in cancer gene expression}},
url = {https://doi.org/10.1038/s41467-017-02391-6},
volume = {9},
year = {2018}
}
@article{Roh2018b,
abstract = {The detoxifying effect of pyridoxine against acetaminophen (APAP)-induced  hepatotoxicity was investigated. HepG2 cells were co-treated with APAP and pyridoxine to compare with betaine or methionine for 24 h. LDH, ALT and AST activities were measured to determine direct cells damage in vitro and in vivo. Lipid peroxidation, antioxidant enzymes activity, and glutathione level were measured. Cytochrome c releaseand procaspase-3, cleaved caspase-3, Bcl-2, or Bax protein levels were measured to determine APAP-induced apoptotic cell death. Pyridoxine treatment significantly increased cell viability and decreased leakage of LDH activity against APAP-induced hepatotoxicity in HepG2 cells. ALT and AST activities were dose-dependently reduced by pyridoxine treatment compared to APAP-treated group. Significant increases in activities of GST and GPx were observed after co-treatment with APAP and pyridoxine. Although APAP-induced Nrf2 and HO-1 expression levels were gradually reduced in HepG2 cells by pyridoxine treatment, induction of antioxidant enzymes activities were dose-dependently increased. These protected effects of pyridoxine against APAP-induced hepatoxicity were closely associated with suppression of APAP-induced oxidative stress and apoptotic cell death in HepG2 cells. These data indicated that the protective action of pyridoxine against hepatic cell injuries was involved in the direct antioxidant activity which provides a pivotal mechanism for its potential hepatoprotective action.},
author = {Roh, Taehyun and De, Umasankar and Lim, Seong Kwang and Kim, Min Kook and Choi, Seul Min and Lim, Duck Soo and Yoon, Sungpil and Kacew, Sam and Kim, Hyung Sik and Lee, Byung-Mu},
doi = {10.1016/j.fct.2018.02.017},
issn = {1873-6351 (Electronic)},
journal = {Food Chem. Toxicol.  an Int. J. Publ. Br.  Ind. Biol. Res. Assoc.},
keywords = {Acetaminophen,Alanine Transaminase,Animals,Aspartate Aminotransferases,Chemical and Drug Induced Liver Injury,Cytochromes c,Glutathione,Glutathione Peroxidase,Hep G2 Cells,Humans,Lipid Peroxidation,Liver,Male,Malondialdehyde,Mice, Inbred ICR,Oxidative Stress,Pyridoxine,administration {\&} dosage,adverse effects,drug effects,drug therapy,enzymology,etiology,metabolism},
language = {eng},
month = {apr},
pages = {11--22},
pmid = {29438775},
title = {{Detoxifying effect of pyridoxine on acetaminophen-induced hepatotoxicity via  suppressing oxidative stress injury.}},
volume = {114},
year = {2018}
}
@article{Rohart2017b,
abstract = {The advent of high throughput technologies has led to a wealth of publicly available ‘omics data coming from different sources, such as transcriptomics, proteomics, metabolomics. Combining such large-scale biological data sets can lead to the discovery of important biological insights, provided that relevant information can be extracted in a holistic manner. Current statistical approaches have been focusing on identifying small subsets of molecules (a ‘molecular signature') to explain or predict biological conditions, but mainly for a single type of ‘omics. In addition, commonly used methods are univariate and consider each biological feature independently. We introduce mixOmics, an R package dedicated to the multivariate analysis of biological data sets with a specific focus on data exploration, dimension reduction and visualisation. By adopting a systems biology approach, the toolkit provides a wide range of methods that statistically integrate several data sets at once to probe relationships between heterogeneous ‘omics data sets. Our recent methods extend Projection to Latent Structure (PLS) models for discriminant analysis, for data integration across multiple ‘omics data or across independent studies, and for the identification of molecular signatures. We illustrate our latest mixOmics integrative frameworks for the multivariate analyses of ‘omics data available from the package.},
author = {Rohart, Florian and Gautier, Beno{\^{i}}t and Singh, Amrit and {L{\^{e}} Cao}, Kim-Anh},
journal = {PLOS Comput. Biol.},
month = {nov},
number = {11},
pages = {e1005752},
publisher = {Public Library of Science},
title = {{mixOmics: An R package for ‘omics feature selection and multiple data integration}},
url = {https://doi.org/10.1371/journal.pcbi.1005752},
volume = {13},
year = {2017}
}
@article{Jaskowiak2014b,
abstract = {Clustering is crucial for gene expression data analysis. As an unsupervised exploratory procedure its results can help researchers to gain insights and formulate new hypothesis about biological data from microarrays. Given different settings of microarray experiments, clustering proves itself as a versatile exploratory tool. It can help to unveil new cancer subtypes or to identify groups of genes that respond similarly to a specific experimental condition. In order to obtain useful clustering results, however, different parameters of the clustering procedure must be properly tuned. Besides the selection of the clustering method itself, determining which distance is going to be employed between data objects is probably one of the most difficult decisions.},
author = {Jaskowiak, Pablo A and Campello, Ricardo J G B and Costa, Ivan G},
doi = {10.1186/1471-2105-15-S2-S2},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {2},
pages = {S2},
title = {{On the selection of appropriate distances for gene expression data clustering}},
url = {https://doi.org/10.1186/1471-2105-15-S2-S2},
volume = {15},
year = {2014}
}
@article{SahebSharif-Askari2020b,
abstract = {Besides lung drastic involvement, SARS-CoV-2 severely affected other systems  including liver. Emerging epidemiological studies brought the attentions towards liver injury and impairment as a potential outcome of COVID19. Angiotensin-converting enzyme 2 (ACE2) and Transmembrane serine protease (TMPRSS2) are the main cell entry receptors of SARS-CoV-2. We have tested the ability of medications to regulate expression of SARS-CoV-2 receptors. Understanding that may reflect how such medications may affect the level of infectivity and permissibility of the liver following COVID-19. Using transcriptomic datasets, Toxicogenomic Project-Genomics Assisted Toxicity Evaluation System (Open TG-GATEs) and GSE30351, we have tested the ability of ninety common medications to regulate COVID-19 receptors expression in human primary hepatocytes. Most medications displayed a dose-dependent change in expression of receptors which could hint at a potentially more pronounced change with chronic use. The expression level of TMPRSS2 was increased noticeably with a number of medications such as metformin. Within the analgesics, acetaminophen revealed a dose-dependent reduction in expression of ACE2, while non-steroidal anti-inflammatory drugs had mixed effect on receptors expression. To confirm the observed effects on primary human hepatocytes, rat hepatocyte treatments data was obtained from DrugMatrix toxicogenomic database (GSE57805), which showed a similar ACE2 and TMPRSS2 expression pattern. Treatment of common co-morbidities often require chronic use of multiple medications, which may result in an additive increase in the expression of ACE2 and TMPRSS2. More research is needed to determine the effect of different medications on COVID-19 receptors.},
author = {{Saheb Sharif-Askari}, Narjes and {Saheb Sharif-Askari}, Fatemeh and Mdkhana, Bushra and {Al Heialy}, Saba and Ratemi, Elaref and Alghamdi, Malak and Abusnana, Salah and Kashour, Tarek and Hamid, Qutayba and Halwani, Rabih},
doi = {10.1007/s00204-020-02869-1},
issn = {1432-0738 (Electronic)},
journal = {Arch. Toxicol.},
language = {eng},
month = {aug},
pages = {1--5},
pmid = {32808185},
title = {{Effect of common medications on the expression of SARS-CoV-2 entry receptors in  liver tissue.}},
year = {2020}
}
@article{Subramanian2017,
abstract = {We previously piloted the concept of a Connectivity Map (CMap), whereby genes,  drugs, and disease states are connected by virtue of common gene-expression signatures. Here, we report more than a 1,000-fold scale-up of the CMap as part of the NIH LINCS Consortium, made possible by a new, low-cost, high-throughput reduced representation expression profiling method that we term L1000. We show that L1000 is highly reproducible, comparable to RNA sequencing, and suitable for computational inference of the expression levels of 81{\%} of non-measured transcripts. We further show that the expanded CMap can be used to discover mechanism of action of small molecules, functionally annotate genetic variants of disease genes, and inform clinical trials. The 1.3 million L1000 profiles described here, as well as tools for their analysis, are available at https://clue.io.},
author = {Subramanian, Aravind and Narayan, Rajiv and Corsello, Steven M and Peck, David D and Natoli, Ted E and Lu, Xiaodong and Gould, Joshua and Davis, John F and Tubelli, Andrew A and Asiedu, Jacob K and Lahr, David L and Hirschman, Jodi E and Liu, Zihan and Donahue, Melanie and Julian, Bina and Khan, Mariya and Wadden, David and Smith, Ian C and Lam, Daniel and Liberzon, Arthur and Toder, Courtney and Bagul, Mukta and Orzechowski, Marek and Enache, Oana M and Piccioni, Federica and Johnson, Sarah A and Lyons, Nicholas J and Berger, Alice H and Shamji, Alykhan F and Brooks, Angela N and Vrcic, Anita and Flynn, Corey and Rosains, Jacqueline and Takeda, David Y and Hu, Roger and Davison, Desiree and Lamb, Justin and Ardlie, Kristin and Hogstrom, Larson and Greenside, Peyton and Gray, Nathanael S and Clemons, Paul A and Silver, Serena and Wu, Xiaoyun and Zhao, Wen-Ning and Read-Button, Willis and Wu, Xiaohua and Haggarty, Stephen J and Ronco, Lucienne V and Boehm, Jesse S and Schreiber, Stuart L and Doench, John G and Bittker, Joshua A and Root, David E and Wong, Bang and Golub, Todd R},
doi = {10.1016/j.cell.2017.10.049},
issn = {1097-4172 (Electronic)},
journal = {Cell},
keywords = {Cell Line, Tumor,Drug Resistance, Neoplasm,Gene Expression Profiling,Humans,Neoplasms,Organ Specificity,Pharmaceutical Preparations,Sequence Analysis, RNA,Small Molecule Libraries,drug therapy,economics,metabolism,methods},
language = {eng},
month = {nov},
number = {6},
pages = {1437--1452.e17},
pmid = {29195078},
title = {{A Next Generation Connectivity Map: L1000 Platform and the First 1,000,000 Profiles.}},
volume = {171},
year = {2017}
}
@article{Lim2010,
abstract = {In an effort to capture meaningful biological, chemical and mechanistic information about clinically relevant, commonly encountered or important toxins, we have developed the Toxin and Toxin-Target Database (T3DB). The T3DB is a unique bioinformatics resource that compiles comprehensive information about common or ubiquitous toxins and their toxin-targets into a single electronic repository. The database currently contains over 2900 small molecule and peptide toxins, 1300 toxin-targets and more than 33,000 toxin-target associations. Each T3DB record (ToxCard) contains over 80 data fields providing detailed information on chemical properties and descriptors, toxicity values, protein and gene sequences (for both targets and toxins), molecular and cellular interaction data, toxicological data, mechanistic information and references. This information has been manually extracted and manually verified from numerous sources, including other electronic databases, government documents, textbooks and scientific journals. A key focus of the T3DB is on providing 'depth' over 'breadth' with detailed descriptions, mechanisms of action, and information on toxins and toxin-targets. T3DB is fully searchable and supports extensive text, sequence, chemical structure and relational query searches, similar to those found in the Human Metabolome Database (HMDB) and DrugBank. Potential applications of the T3DB include clinical metabolomics, toxin target prediction, toxicity prediction and toxicology education. The T3DB is available online at http://www.t3db.org.},
author = {Lim, Emilia and Pon, Allison and Djoumbou, Yannick and Knox, Craig and Shrivastava, Savita and Guo, An Chi and Neveu, Vanessa and Wishart, David S},
doi = {10.1093/nar/gkp934},
edition = {2009/11/06},
issn = {1362-4962},
journal = {Nucleic Acids Res.},
keywords = {*Databases, Factual,*Databases, Protein,Computational Biology/*methods/trends,Drug Design,Drug-Related Side Effects and Adverse Reactions,Humans,Information Storage and Retrieval/methods,Internet,Pharmaceutical Preparations/*chemistry,Pharmacology/methods,Quality Control,Reproducibility of Results,Software,Toxins, Biological/*chemistry},
language = {eng},
month = {jan},
number = {Database issue},
pages = {D781--D786},
publisher = {Oxford University Press},
title = {{T3DB: a comprehensively annotated database of common toxins and their targets}},
url = {https://pubmed.ncbi.nlm.nih.gov/19897546 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2808899/},
volume = {38},
year = {2010}
}
@article{Fallahi2020,
abstract = {Reaction rates (fluxes) in a metabolic network can be analyzed using constraint-based modeling which imposes a steady state assumption on the system. In a deterministic formulation of the problem the steady state assumption has to be fulfilled exactly, and the observed fluxes are included in the model without accounting for experimental noise. One can relax the steady state constraint, and also include experimental noise in the model, through a stochastic formulation of the problem. Uniform sampling of fluxes, feasible in both the deterministic and stochastic formulation, can provide us with statistical properties of the metabolic network, such as marginal flux probability distributions. In this study we give an overview of both the deterministic and stochastic formulation of the problem, and of available Monte Carlo sampling methods for sampling the corresponding solution space. We apply the ACHR, OPTGP, CHRR and Gibbs sampling algorithms to ten metabolic networks and evaluate their convergence, consistency and efficiency. The coordinate hit-and-run with rounding (CHRR) is found to perform best among the algorithms suitable for the deterministic formulation. A desirable property of CHRR is its guaranteed distributional convergence. Among the three other algorithms, ACHR has the largest consistency with CHRR for genome scale models. For the stochastic formulation, the Gibbs sampler is the only method appropriate for sampling at genome scale. However, our analysis ranks it as less efficient than the samplers used for the deterministic formulation.},
author = {Fallahi, Shirin and Skaug, Hans J and Alendal, Guttorm},
journal = {PLoS One},
month = {jul},
number = {7},
pages = {e0235393},
publisher = {Public Library of Science},
title = {{A comparison of Monte Carlo sampling methods for metabolic network models}},
url = {https://doi.org/10.1371/journal.pone.0235393},
volume = {15},
year = {2020}
}
@article{Cho2016b,
abstract = {The topological landscape of molecular or functional interaction networks provides a  rich source of information for inferring functional patterns of genes or proteins. However, a pressing yet-unsolved challenge is how to combine multiple heterogeneous networks, each having different connectivity patterns, to achieve more accurate inference. Here, we describe the Mashup framework for scalable and robust network integration. In Mashup, the diffusion in each network is first analyzed to characterize the topological context of each node. Next, the high-dimensional topological patterns in individual networks are canonically represented using low-dimensional vectors, one per gene or protein. These vectors can then be plugged into off-the-shelf machine learning methods to derive functional insights about genes or proteins. We present tools based on Mashup that achieve state-of-the-art performance in three diverse functional inference tasks: protein function prediction, gene ontology reconstruction, and genetic interaction prediction. Mashup enables deeper insights into the structure of rapidly accumulating and diverse biological network data and can be broadly applied to other network science domains.},
author = {Cho, Hyunghoon and Berger, Bonnie and Peng, Jian},
doi = {10.1016/j.cels.2016.10.017},
issn = {2405-4712 (Print)},
journal = {Cell Syst.},
language = {eng},
month = {dec},
number = {6},
pages = {540--548.e5},
pmid = {27889536},
title = {{Compact Integration of Multi-Network Topology for Functional Analysis of Genes.}},
volume = {3},
year = {2016}
}
@article{Nair2020,
abstract = {In the past few decades, major initiatives have been launched around the world to address chemical safety testing. These efforts aim to innovate and improve the efficacy of existing methods with the long-term goal of developing new risk assessment paradigms. The transcriptomic and toxicological profiling of mammalian cells has resulted in the creation of multiple toxicogenomic datasets and corresponding tools for analysis. To enable easy access and analysis of these valuable toxicogenomic data, we have developed ToxicoDB (toxicodb.ca), a free and open cloud-based platform integrating data from large in vitro toxicogenomic studies, including gene expression profiles of primary human and rat hepatocytes treated with 231 potential toxicants. To efficiently mine these complex toxicogenomic data, ToxicoDB provides users with harmonized chemical annotations, time- and dose-dependent plots of compounds across datasets, as well as the toxicity-related pathway analysis. The data in ToxicoDB have been generated using our open-source R package, ToxicoGx (github.com/bhklab/ToxicoGx). Altogether, ToxicoDB provides a streamlined process for mining highly organized, curated, and accessible toxicogenomic data that can be ultimately applied to preclinical toxicity studies and further our understanding of adverse outcomes.},
author = {Nair, Sisira Kadambat and Eeles, Christopher and Ho, Chantal and Beri, Gangesh and Yoo, Esther and Tkachuk, Denis and Tang, Amy and Nijrabi, Parwaiz and Smirnov, Petr and Seo, Heewon and Jennen, Danyel and Haibe-Kains, Benjamin},
doi = {10.1093/nar/gkaa390},
issn = {0305-1048},
journal = {Nucleic Acids Res.},
month = {may},
number = {W1},
pages = {W455--W462},
title = {{ToxicoDB: an integrated database to mine and visualize large-scale toxicogenomic datasets}},
url = {https://doi.org/10.1093/nar/gkaa390},
volume = {48},
year = {2020}
}
@article{Rueda-Zarate2017b,
abstract = {The liver and the kidney are the most common targets of chemical toxicity, due to  their major metabolic and excretory functions. However, since the liver is directly involved in biotransformation, compounds in many currently and normally used drugs could affect it adversely. Most chemical compounds are already labeled according to FDA-approved labels using DILI-concern scale. Drug Induced Liver Injury (DILI) scale refers to an adverse drug reaction. Many compounds do not exhibit hepatotoxicity at early stages of development, so it is important to detect anomalies at gene expression level that could predict adverse reactions in later stages. In this study, a large collection of microarray data is used to investigate gene expression changes associated with hepatotoxicity. Using TG-GATEs a large-scale toxicogenomics database, we present a computational strategy to classify compounds by toxicity levels in human and animal models through patterns of gene expression. We combined machine learning algorithms with time series analysis to identify genes capable of classifying compounds by FDA-approved labeling as DILI-concern toxic. The goal is to define gene expression profiles capable of distinguishing the different subtypes of hepatotoxicity. The study illustrates that expression profiling can be used to classify compounds according to different hepatotoxic levels; to label those that are currently labeled as undertemined; and to determine if at the molecular level, animal models are a good proxy to predict hepatotoxicity in humans.},
author = {Rueda-Z{\'{a}}rate, H{\'{e}}ctor A and Imaz-Rosshandler, Iv{\'{a}}n and C{\'{a}}rdenas-Ovando, Roberto A and Castillo-Fern{\'{a}}ndez, Juan E and Noguez-Monroy, Julieta and Rangel-Escare{\~{n}}o, Claudia},
doi = {10.1371/journal.pone.0176284},
issn = {1932-6203 (Electronic)},
journal = {PLoS One},
keywords = {Animals,Chemical and Drug Induced Liver Injury,Cytotoxins,Databases, Genetic,Dose-Response Relationship, Drug,Drug Evaluation, Preclinical,Genomics,Humans,Liver,Mice,Oligonucleotide Array Sequence Analysis,Time Factors,Toxicogenetics,Unsupervised Machine Learning,drug effects,genetics,metabolism,methods,toxicity},
language = {eng},
number = {4},
pages = {e0176284},
pmid = {28448553},
title = {{A computational toxicogenomics approach identifies a list of highly hepatotoxic  compounds from a large microarray database.}},
volume = {12},
year = {2017}
}
@article{Lazar2013b,
abstract = {Genomic data integration is a key goal to be achieved towards large-scale genomic data analysis. This process is very challenging due to the diverse sources of information resulting from genomics experiments. In this work, we review methods designed to combine genomic data recorded from microarray gene expression (MAGE) experiments. It has been acknowledged that the main source of variation between different MAGE datasets is due to the so-called ‘batch effects'. The methods reviewed here perform data integration by removing (or more precisely attempting to remove) the unwanted variation associated with batch effects. They are presented in a unified framework together with a wide range of evaluation tools, which are mandatory in assessing the efficiency and the quality of the data integration process. We provide a systematic description of the MAGE data integration methodology together with some basic recommendation to help the users in choosing the appropriate tools to integrate MAGE data for large-scale analysis; and also how to evaluate them from different perspectives in order to quantify their efficiency. All genomic data used in this study for illustration purposes were retrieved from InSilicoDB http://insilico.ulb.ac.be.},
author = {Lazar, Cosmin and Meganck, Stijn and Taminau, Jonatan and Steenhoff, David and Coletta, Alain and Molter, Colin and Weiss-Sol{\'{i}}s, David Y and Duque, Robin and Bersini, Hugues and Now{\'{e}}, Ann},
doi = {10.1093/bib/bbs037},
issn = {1467-5463},
journal = {Brief. Bioinform.},
month = {jul},
number = {4},
pages = {469--490},
title = {{Batch effect removal methods for microarray gene expression data integration: a survey}},
url = {https://doi.org/10.1093/bib/bbs037},
volume = {14},
year = {2013}
}
@article{Robinson2020,
abstract = {Genome-scale metabolic models (GEMs) are valuable tools to study metabolism and  provide a scaffold for the integrative analysis of omics data. Researchers have developed increasingly comprehensive human GEMs, but the disconnect among different model sources and versions impedes further progress. We therefore integrated and extensively curated the most recent human metabolic models to construct a consensus GEM, Human1. We demonstrated the versatility of Human1 through the generation and analysis of cell- and tissue-specific models using transcriptomic, proteomic, and kinetic data. We also present an accompanying web portal, Metabolic Atlas (https://www.metabolicatlas.org/), which facilitates further exploration and visualization of Human1 content. Human1 was created using a version-controlled, open-source model development framework to enable community-driven curation and refinement. This framework allows Human1 to be an evolving shared resource for future studies of human health and disease.},
author = {Robinson, Jonathan L and Kocabaş, Pınar and Wang, Hao and Cholley, Pierre-Etienne and Cook, Daniel and Nilsson, Avlant and Anton, Mihail and Ferreira, Raphael and Domenzain, Iv{\'{a}}n and Billa, Virinchi and Limeta, Angelo and Hedin, Alex and Gustafsson, Johan and Kerkhoven, Eduard J and Svensson, L Thomas and Palsson, Bernhard O and Mardinoglu, Adil and Hansson, Lena and Uhl{\'{e}}n, Mathias and Nielsen, Jens},
doi = {10.1126/scisignal.aaz1482},
issn = {1937-9145 (Electronic)},
journal = {Sci. Signal.},
language = {eng},
month = {mar},
number = {624},
pmid = {32209698},
title = {{An atlas of human metabolism.}},
volume = {13},
year = {2020}
}
@article{Ji2018,
abstract = {SUMMARY: In this work, we present eMolTox, a web server for the prediction of  potential toxicity associated with a given molecule. A total of 174 toxicology-related in vitro/vivo experimental datasets were used for model construction and Mondrian conformal prediction was used to estimate the confidence of the resulting predictions. Toxic substructure analysis is also implemented in eMolTox. eMolTox predicts and displays a wealth of information of potential molecular toxicities for safety analysis in drug development. AVAILABILITY AND IMPLEMENTATION: The eMolTox Server is freely available for use on the web at http://xundrug.cn/moltox. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
author = {Ji, Changge and Svensson, Fredrik and Zoufir, Azedine and Bender, Andreas},
doi = {10.1093/bioinformatics/bty135},
issn = {1367-4811 (Electronic)},
journal = {Bioinformatics},
keywords = {Animals,Carcinogens,Humans,Mutagens,Software,Toxicology,methods,toxicity},
language = {eng},
month = {jul},
number = {14},
pages = {2508--2509},
pmid = {29522123},
title = {{eMolTox: prediction of molecular toxicity with confidence.}},
volume = {34},
year = {2018}
}
@article{Shlomi2008,
abstract = {Direct in vivo investigation of mammalian metabolism is complicated by the distinct  metabolic functions of different tissues. We present a computational method that successfully describes the tissue specificity of human metabolism on a large scale. By integrating tissue-specific gene- and protein-expression data with an existing comprehensive reconstruction of the global human metabolic network, we predict tissue-specific metabolic activity in ten human tissues. This reveals a central role for post-transcriptional regulation in shaping tissue-specific metabolic activity profiles. The predicted tissue specificity of genes responsible for metabolic diseases and tissue-specific differences in metabolite exchange with biofluids extend markedly beyond tissue-specific differences manifest in enzyme-expression data, and are validated by large-scale mining of tissue-specificity data. Our results establish a computational basis for the genome-wide study of normal and abnormal human metabolism in a tissue-specific manner.},
author = {Shlomi, Tomer and Cabili, Moran N and Herrg{\aa}rd, Markus J and Palsson, Bernhard {\O} and Ruppin, Eytan},
doi = {10.1038/nbt.1487},
issn = {1546-1696 (Electronic)},
journal = {Nat. Biotechnol.},
keywords = {Cell Physiological Phenomena,Computational Biology,Databases, Protein,Gene Expression Profiling,Gene Expression Regulation,Genome, Human,Humans,Metabolic Networks and Pathways,Models, Genetic,Models, Statistical,Reproducibility of Results,Software,genetics,methods,physiology},
language = {eng},
month = {sep},
number = {9},
pages = {1003--1010},
pmid = {18711341},
title = {{Network-based prediction of human tissue-specific metabolism.}},
volume = {26},
year = {2008}
}
@article{Biour2004,
author = {Biour, Michel and {Ben Salem}, Chaker and Chazouill{\`{e}}res, Olivier and Grang{\'{e}}, Jean-Didier and Serfati, Lawrence and Poupon, Raoul},
doi = {https://doi.org/10.1016/S0399-8320(04)95062-2},
issn = {0399-8320},
journal = {Gastroent{\'{e}}rologie Clin. Biol.},
number = {8},
pages = {720--759},
title = {{H{\'{e}}patotoxicit{\'{e}} des m{\'{e}}dicaments 14e mise {\`{a}} jour du fichier bibliographique des atteintes h{\'{e}}patiques et des m{\'{e}}dicaments responsables}},
url = {http://www.sciencedirect.com/science/article/pii/S0399832004950622},
volume = {28},
year = {2004}
}
@article{Gusenleitner2014b,
abstract = {BACKGROUND: Despite an overall decrease in incidence of and mortality from cancer, about 40{\%} of Americans will be diagnosed with the disease in their lifetime, and around 20{\%} will die of it. Current approaches to test carcinogenic chemicals adopt the 2-year rodent bioassay, which is costly and time-consuming. As a result, fewer than 2{\%} of the chemicals on the market have actually been tested. However, evidence accumulated to date suggests that gene expression profiles from model organisms exposed to chemical compounds reflect underlying mechanisms of action, and that these toxicogenomic models could be used in the prediction of chemical carcinogenicity. RESULTS: In this study, we used a rat-based microarray dataset from the NTP DrugMatrix Database to test the ability of toxicogenomics to model carcinogenicity. We analyzed 1,221 gene-expression profiles obtained from rats treated with 127 well-characterized compounds, including genotoxic and non-genotoxic carcinogens. We built a classifier that predicts a chemical's carcinogenic potential with an AUC of 0.78, and validated it on an independent dataset from the Japanese Toxicogenomics Project consisting of 2,065 profiles from 72 compounds. Finally, we identified differentially expressed genes associated with chemical carcinogenesis, and developed novel data-driven approaches for the molecular characterization of the response to chemical stressors. CONCLUSION: Here, we validate a toxicogenomic approach to predict carcinogenicity and provide strong evidence that, with a larger set of compounds, we should be able to improve the sensitivity and specificity of the predictions. We found that the prediction of carcinogenicity is tissue-dependent and that the results also confirm and expand upon previous studies implicating DNA damage, the peroxisome proliferator-activated receptor, the aryl hydrocarbon receptor, and regenerative pathology in the response to carcinogen exposure.},
author = {Gusenleitner, Daniel and Auerbach, Scott S and Melia, Tisha and G{\'{o}}mez, Harold F and Sherr, David H and Monti, Stefano},
doi = {10.1371/journal.pone.0102579},
issn = {1932-6203},
journal = {PLoS One},
keywords = {*DNA Repair,*Models, Genetic,Animals,Area Under Curve,Carcinogenicity Tests/methods,Carcinogens/*toxicity,DNA Damage,Databases, Factual,Drugs, Investigational/toxicity,Gene Expression Profiling,Gene Expression/drug effects,Male,Organ Specificity,Peroxisome Proliferator-Activated Receptors/geneti,Quantitative Structure-Activity Relationship,Rats,Receptors, Aryl Hydrocarbon/genetics/metabolism,Sensitivity and Specificity,Toxicogenetics},
language = {eng},
month = {jul},
number = {7},
pages = {e102579--e102579},
publisher = {Public Library of Science},
title = {{Genomic models of short-term exposure accurately predict long-term chemical carcinogenicity and identify putative mechanisms of action}},
url = {https://pubmed.ncbi.nlm.nih.gov/25058030 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4109923/},
volume = {9},
year = {2014}
}
@article{Ramos2020b,
abstract = {OBJECTIVE: Data normalization and clustering are mandatory steps in gene expression  and downstream analyses, respectively. However, user-friendly implementations of these methodologies are available exclusively under expensive licensing agreements, or in stand-alone scripts developed, reflecting on a great obstacle for users with less computational skills. RESULTS: We developed an online tool called CORAZON (Correlations Analyses Zipper Online), which implements three unsupervised learning methods to cluster gene expression datasets in a friendly environment. It allows the usage of eight gene expression normalization/transformation methodologies and the attribute's influence. The normalizations requiring the gene length only could be performed to RNA-seq, meanwhile the others can be used with microarray and/or NanoString data. Clustering methodologies performances were evaluated through five models with accuracies between 92 and 100{\%}. We applied our tool to obtain functional insights of non-coding RNAs (ncRNAs) based on Gene Ontology enrichment of clusters in a dataset generated by the ENCODE project. The clusters where the majority of transcripts are coding genes were enriched in Cellular, Metabolic, Transports, and Systems Development categories. Meanwhile, the ncRNAs were enriched in the Detection of Stimulus, Sensory Perception, Immunological System, and Digestion categories. CORAZON source-code is freely available at https://gitlab.com/integrativebioinformatics/corazon and the web-server can be accessed at http://corazon.integrativebioinformatics.me .},
author = {Ramos, Tha{\'{i}}s A R and Maracaja-Coutinho, Vinicius and Ortega, J Miguel and do R{\^{e}}go, Tha{\'{i}}s G},
doi = {10.1186/s13104-020-05171-6},
issn = {1756-0500 (Electronic)},
journal = {BMC Res. Notes},
language = {eng},
month = {jul},
number = {1},
pages = {338},
pmid = {32665017},
title = {{CORAZON: a web server for data normalization and unsupervised clustering based on  expression profiles.}},
volume = {13},
year = {2020}
}
@article{Chen2009,
abstract = {ToppGene Suite (http://toppgene.cchmc.org; this web site is free and open to all users and does not require a login to access) is a one-stop portal for (i) gene list functional enrichment, (ii) candidate gene prioritization using either functional annotations or network analysis and (iii) identification and prioritization of novel disease candidate genes in the interactome. Functional annotation-based disease candidate gene prioritization uses a fuzzy-based similarity measure to compute the similarity between any two genes based on semantic annotations. The similarity scores from individual features are combined into an overall score using statistical meta-analysis. A P-value of each annotation of a test gene is derived by random sampling of the whole genome. The protein-protein interaction network (PPIN)-based disease candidate gene prioritization uses social and Web networks analysis algorithms (extended versions of the PageRank and HITS algorithms, and the K-Step Markov method). We demonstrate the utility of ToppGene Suite using 20 recently reported GWAS-based gene-disease associations (including novel disease genes) representing five diseases. ToppGene ranked 19 of 20 (95{\%}) candidate genes within the top 20{\%}, while ToppNet ranked 12 of 16 (75{\%}) candidate genes among the top 20{\%}.},
author = {Chen, Jing and Bardes, Eric E and Aronow, Bruce J and Jegga, Anil G},
doi = {10.1093/nar/gkp427},
edition = {2009/05/22},
issn = {1362-4962},
journal = {Nucleic Acids Res.},
keywords = {*Genes,*Software,Animals,Disease/*genetics,Humans,Internet,Mice,Protein Interaction Mapping,Proteins/genetics},
language = {eng},
month = {jul},
number = {Web Server issue},
pages = {W305--W311},
publisher = {Oxford University Press},
title = {{ToppGene Suite for gene list enrichment analysis and candidate gene prioritization}},
url = {https://pubmed.ncbi.nlm.nih.gov/19465376 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2703978/},
volume = {37},
year = {2009}
}
@article{Schultz2016,
abstract = {Author Summary Cellular metabolism is defined by a large, intricate network of thousands of components, and plays a fundamental role in many diseases. To study this network in its entirety, metabolic models have been built which encompass all known biochemical reactions in the human metabolism. However, since not all metabolic reactions take place in any given tissue, these generalized models need to be tailored to study specific cell types. Algorithms developed to date to perform this tailoring process have focused on keeping tissue-specific models as concise as possible. This approach, however, can remove essential reactions from the model and hamper subsequent analysis. Here we present CORDA, a tissue-specific building algorithm that yields concise, but not minimalistic, tissue-specific models. CORDA has many advantages over previous methods, including better agreement with experimental data and better model functionality. Using CORDA, we developed a library of 76 healthy and 20 cancer-specific models of metabolism, which we used to identify similarities between healthy and cancerous tissues, as well as metabolic pathways that are unique to cancer. Results of this work provide a broadly applicable tool to model cell- and tissue-specific metabolism, while highlighting potential new pathway targets for cancer therapies.},
author = {Schultz, Andr{\'{e}} and Qutub, Amina A},
journal = {PLOS Comput. Biol.},
month = {mar},
number = {3},
pages = {e1004808},
publisher = {Public Library of Science},
title = {{Reconstruction of Tissue-Specific Metabolic Networks Using CORDA}},
url = {https://doi.org/10.1371/journal.pcbi.1004808},
volume = {12},
year = {2016}
}
@article{Uehara2010c,
abstract = {Abstract Biotechnology advances have provided novel methods for the risk assessment of chemicals. The application of microarray technologies to toxicology, known as toxicogenomics, is becoming an accepted approach for identifying chemicals with potential safety problems. Gene expression profiling is expected to identify the mechanisms that underlie the potential toxicity of chemicals. This technology has also been applied to identify biomarkers of toxicity to predict potential hazardous chemicals. Ultimately, toxicogenomics is expected to aid in risk assessment. The following discussion explores potential applications and features of the Japanese Toxicogenomics Project.},
annote = {https://doi.org/10.1002/mnfr.200900169},
author = {Uehara, Takeki and Ono, Atsushi and Maruyama, Toshiyuki and Kato, Ikuo and Yamada, Hiroshi and Ohno, Yasuo and Urushidani, Tetsuro},
doi = {https://doi.org/10.1002/mnfr.200900169},
issn = {1613-4125},
journal = {Mol. Nutr. Food Res.},
keywords = {Genomic biomarker,Hepatotoxicity,Microarray,Toxicogenomics,Toxicogenomics Project},
month = {feb},
number = {2},
pages = {218--227},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{The Japanese toxicogenomics project: Application of toxicogenomics}},
url = {https://doi.org/10.1002/mnfr.200900169},
volume = {54},
year = {2010}
}
@article{Tao2020b,
abstract = {For accurate gene expression quantification, normalization of gene expression data  against reliable reference genes is required. It is known that the expression levels of commonly used reference genes vary considerably under different experimental conditions, and therefore, their use for data normalization is limited. In this study, an unbiased identification of reference genes in Caenorhabditis elegans was performed based on 145 microarray datasets (2296 gene array samples) covering different developmental stages, different tissues, drug treatments, lifestyle, and various stresses. As a result, thirteen housekeeping genes (rps-23, rps-26, rps-27, rps-16, rps-2, rps-4, rps-17, rpl-24.1, rpl-27, rpl-33, rpl-36, rpl-35, and rpl-15) with enhanced stability were comprehensively identified by using six popular normalization algorithms and RankAggreg method. Functional enrichment analysis revealed that these genes were significantly overrepresented in GO terms or KEGG pathways related to ribosomes. Validation analysis using recently published datasets revealed that the expressions of newly identified candidate reference genes were more stable than the commonly used reference genes. Based on the results, we recommended using rpl-33 and rps-26 as the optimal reference genes for microarray and rps-2 and rps-4 for RNA-sequencing data validation. More importantly, the most stable rps-23 should be a promising reference gene for both data types. This study, for the first time, successfully displays a large-scale microarray data driven genome-wide identification of stable reference genes for normalizing gene expression data and provides a potential guideline on the selection of universal internal reference genes in C. elegans, for quantitative gene expression analysis.},
author = {Tao, Jingxin and Hao, Youjin and Li, Xudong and Yin, Huachun and Nie, Xiner and Zhang, Jie and Xu, Boying and Chen, Qiao and Li, Bo},
doi = {10.3390/cells9030786},
issn = {2073-4409 (Electronic)},
journal = {Cells},
language = {eng},
month = {mar},
number = {3},
pmid = {32213971},
title = {{Systematic Identification of Housekeeping Genes Possibly Used as References in  Caenorhabditis elegans by Large-Scale Data Integration.}},
volume = {9},
year = {2020}
}
@article{Lacroix2018,
abstract = {Polyphenol-rich foods are part of many nutritional interventions aimed at improving health and preventing cardiometabolic diseases (CMDs). Polyphenols have oxidative, inflammatory, and/or metabolic effects. Research into the chemistry and biology of polyphenol bioactives is prolific but knowledge of their molecular interactions with proteins is limited. We mined public data to (i) identify proteins that interact with or metabolize polyphenols, (ii) mapped these proteins to pathways and networks, and (iii) annotated functions enriched within the resulting polyphenol-protein interactome. A total of 1,395 polyphenols and their metabolites were retrieved (using Phenol-Explorer and Dictionary of Natural Products) of which 369 polyphenols interacted with 5,699 unique proteins in 11,987 interactions as annotated in STITCH, Pathway Commons, and BindingDB. Pathway enrichment analysis using the KEGG repository identified a broad coverage of significant pathways of low specificity to particular polyphenol (sub)classes. When compared to drugs or micronutrients, polyphenols have pleiotropic effects across many biological processes related to metabolism and CMDs. These systems-wide effects were also found in the protein interactome of the polyphenol-rich citrus fruits, used as a case study. In sum, these findings provide a knowledgebase for identifying polyphenol classes (and polyphenol-rich foods) that individually or in combination influence metabolism.},
author = {Lacroix, S{\'{e}}bastien and {Klicic Badoux}, Jasna and Scott-Boyer, Marie-Pier and Parolo, Silvia and Matone, Alice and Priami, Corrado and Morine, Melissa J and Kaput, Jim and Moco, Sofia},
doi = {10.1038/s41598-018-20625-5},
issn = {2045-2322},
journal = {Sci. Rep.},
number = {1},
pages = {2232},
title = {{A computationally driven analysis of the polyphenol-protein interactome}},
url = {https://doi.org/10.1038/s41598-018-20625-5},
volume = {8},
year = {2018}
}
@article{Lachmann2018b,
abstract = {RNA sequencing (RNA-seq) is the leading technology for genome-wide transcript quantification. However, publicly available RNA-seq data is currently provided mostly in raw form, a significant barrier for global and integrative retrospective analyses. ARCHS4 is a web resource that makes the majority of published RNA-seq data from human and mouse available at the gene and transcript levels. For developing ARCHS4, available FASTQ files from RNA-seq experiments from the Gene Expression Omnibus (GEO) were aligned using a cloud-based infrastructure. In total 187,946 samples are accessible through ARCHS4 with 103,083 mouse and 84,863 human. Additionally, the ARCHS4 web interface provides intuitive exploration of the processed data through querying tools, interactive visualization, and gene pages that provide average expression across cell lines and tissues, top co-expressed genes for each gene, and predicted biological functions and protein–protein interactions for each gene based on prior knowledge combined with co-expression.},
author = {Lachmann, Alexander and Torre, Denis and Keenan, Alexandra B and Jagodnik, Kathleen M and Lee, Hoyjin J and Wang, Lily and Silverstein, Moshe C and Ma'ayan, Avi},
doi = {10.1038/s41467-018-03751-6},
issn = {2041-1723},
journal = {Nat. Commun.},
number = {1},
pages = {1366},
title = {{Massive mining of publicly available RNA-seq data from human and mouse}},
url = {https://doi.org/10.1038/s41467-018-03751-6},
volume = {9},
year = {2018}
}
@article{Welsh2013,
abstract = {Many gene expression normalization algorithms exist for Affymetrix GeneChip microarrays. The most popular of these is RMA, primarily due to the precision and low noise produced during the process. A significant strength of this and similar approaches is the use of the entire set of arrays during both normalization and model-based estimation of signal. However, this leads to differing estimates of expression based on the starting set of arrays, and estimates can change when a single, additional chip is added to the set. Additionally, outlier chips can impact the signals of other arrays, and can themselves be skewed by the majority of the population.},
author = {Welsh, Eric A and Eschrich, Steven A and Berglund, Anders E and Fenstermacher, David A},
doi = {10.1186/1471-2105-14-153},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {1},
pages = {153},
title = {{Iterative rank-order normalization of gene expression microarray data}},
url = {https://doi.org/10.1186/1471-2105-14-153},
volume = {14},
year = {2013}
}
@article{Blayney2016,
abstract = {Here, we describe gene expression compositional assignment (GECA), a powerful, yet simple method based on compositional statistics that can validate the transfer of prior knowledge, such as gene lists, into independent data sets, platforms and technologies. Transcriptional profiling has been used to derive gene lists that stratify patients into prognostic molecular subgroups and assess biomarker performance in the pre-clinical setting. Archived public data sets are an invaluable resource for subsequent in silico validation, though their use can lead to data integration issues. We show that GECA can be used without the need for normalising expression levels between data sets and can outperform rank-based correlation methods. To validate GECA, we demonstrate its success in the cross-platform transfer of gene lists in different domains including: bladder cancer staging, tumour site of origin and mislabelled cell lines. We also show its effectiveness in transferring an epithelial ovarian cancer prognostic gene signature across technologies, from a microarray to a next-generation sequencing setting. In a final case study, we predict the tumour site of origin and histopathology of epithelial ovarian cancer cell lines. In particular, we identify and validate the commonly-used cell line OVCAR-5 as non-ovarian, being gastrointestinal in origin. GECA is available as an open-source R package.},
author = {Blayney, Jaine K and Davison, Timothy and McCabe, Nuala and Walker, Steven and Keating, Karen and Delaney, Thomas and Greenan, Caroline and Williams, Alistair R and McCluggage, W Glenn and Capes-Davis, Amanda and Harkin, D Paul and Gourley, Charlie and Kennedy, Richard D},
doi = {10.1093/nar/gkw578},
issn = {0305-1048},
journal = {Nucleic Acids Res.},
month = {jun},
number = {17},
pages = {e137--e137},
title = {{Prior knowledge transfer across transcriptional data sets and technologies using compositional statistics yields new mislabelled ovarian cell line}},
url = {https://doi.org/10.1093/nar/gkw578},
volume = {44},
year = {2016}
}
@article{huang_benchmarking_2006,
abstract = {Ligand enrichment among top-ranking hits is a key metric of molecular docking. To avoid bias, decoys should resemble ligands physically, so that enrichment is not simply a separation of gross features, yet be chemically distinct from them, so that they are unlikely to be binders. We have assembled a directory of useful decoys (DUD), with 2950 ligands for 40 different targets. Every ligand has 36 decoy molecules that are physically similar but topologically distinct, leading to a database of 98 266 compounds. For most targets, enrichment was at least half a log better with uncorrected databases such as the MDDR than with DUD, evidence of bias in the former. These calculations also allowed 40 × 40 cross-docking, where the enrichments of each ligand set could be compared for all 40 targets, enabling a specificity metric for the docking screens. DUD is freely available online as a benchmarking set for docking at http://blaster.docking.org/dud/. {\textcopyright} 2006 American Chemical Society.},
author = {Huang, Niu and Shoichet, Brian K. and Irwin, John J.},
doi = {10.1021/jm0608356},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Shoichet, Irwin - 2006 - Benchmarking sets for molecular docking.pdf:pdf},
issn = {00222623},
journal = {J. Med. Chem.},
number = {23},
pages = {6789--6801},
pmid = {17154509},
title = {{Benchmarking sets for molecular docking}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3383317/},
volume = {49},
year = {2006}
}
@article{Tao2020d,
abstract = {For accurate gene expression quantification, normalization of gene expression data  against reliable reference genes is required. It is known that the expression levels of commonly used reference genes vary considerably under different experimental conditions, and therefore, their use for data normalization is limited. In this study, an unbiased identification of reference genes in Caenorhabditis elegans was performed based on 145 microarray datasets (2296 gene array samples) covering different developmental stages, different tissues, drug treatments, lifestyle, and various stresses. As a result, thirteen housekeeping genes (rps-23, rps-26, rps-27, rps-16, rps-2, rps-4, rps-17, rpl-24.1, rpl-27, rpl-33, rpl-36, rpl-35, and rpl-15) with enhanced stability were comprehensively identified by using six popular normalization algorithms and RankAggreg method. Functional enrichment analysis revealed that these genes were significantly overrepresented in GO terms or KEGG pathways related to ribosomes. Validation analysis using recently published datasets revealed that the expressions of newly identified candidate reference genes were more stable than the commonly used reference genes. Based on the results, we recommended using rpl-33 and rps-26 as the optimal reference genes for microarray and rps-2 and rps-4 for RNA-sequencing data validation. More importantly, the most stable rps-23 should be a promising reference gene for both data types. This study, for the first time, successfully displays a large-scale microarray data driven genome-wide identification of stable reference genes for normalizing gene expression data and provides a potential guideline on the selection of universal internal reference genes in C. elegans, for quantitative gene expression analysis.},
author = {Tao, Jingxin and Hao, Youjin and Li, Xudong and Yin, Huachun and Nie, Xiner and Zhang, Jie and Xu, Boying and Chen, Qiao and Li, Bo},
doi = {10.3390/cells9030786},
issn = {2073-4409 (Electronic)},
journal = {Cells},
language = {eng},
month = {mar},
number = {3},
pmid = {32213971},
title = {{Systematic Identification of Housekeeping Genes Possibly Used as References in  Caenorhabditis elegans by Large-Scale Data Integration.}},
volume = {9},
year = {2020}
}
@article{Yasuo2019,
abstract = {Virtual screening is a promising method for obtaining novel hit compounds in drug discovery. It aims to enrich potentially active compounds from a large chemical library for further biological experiments. However, the accuracy of current virtual screening methods is insufficient. In this study, we develop a new virtual screening method named Similarity of Interaction Energy VEctor Score (SIEVE-Score), in which protein-ligand interaction energies are extracted to represent docking poses for machine learning. SIEVE-Score offers substantial improvements compared to other state-of-the-art virtual screening methods, namely, other machine-learning-based scoring functions, interaction fingerprints, and docking software, for the enrichment factor 1{\%} results on the Directory of Useful Decoys, Enhanced (DUD-E). The screening results are also human-interpretable in the form of important interactions for distinguishing between active and inactive compounds. The source code is available at https://github.com/sekijima-lab/SIEVE-Score.},
author = {Yasuo, Nobuaki and Sekijima, Masakazu},
doi = {10.1021/acs.jcim.8b00673},
issn = {15205142},
journal = {J. Chem. Inf. Model.},
month = {feb},
number = {3},
pages = {1050--1061},
publisher = {American Chemical Society},
title = {{Improved Method of Structure-Based Virtual Screening via Interaction-Energy-Based Learning}},
volume = {59},
year = {2019}
}
@article{Singh2020,
abstract = {The interplay between life sciences and advancing technology drives a continuous cycle of chemical data growth; these data are most often stored in open or partially open databases. In parallel, many different types of algorithms are being developed to manipulate these chemical objects and associated bioactivity data. Virtual screening methods are among the most popular computational approaches in pharmaceutical research. Today, user-friendly web-based tools are available to help scientists perform virtual screening experiments. This article provides an overview of internet resources enabling and supporting chemical biology and early drug discovery with a main emphasis on web servers dedicated to virtual ligand screening and small-molecule docking. This survey first introduces some key concepts and then presents recent and easily accessible virtual screening and related target-fishing tools as well as briefly discusses case studies enabled by some of these web services. Notwithstanding further improvements, already available web-based tools not only contribute to the design of bioactive molecules and assist drug repositioning but also help to generate new ideas and explore different hypotheses in a timely fashion while contributing to teaching in the field of drug development.},
author = {Singh, Natesh and Chaput, Ludovic and Villoutreix, Bruno O},
doi = {10.1093/bib/bbaa034},
issn = {1477-4054},
journal = {Brief. Bioinform.},
month = {mar},
title = {{Virtual screening web servers: designing chemical probes and drug candidates in the cyberspace}},
url = {https://doi.org/10.1093/bib/bbaa034},
year = {2020}
}
@article{lionta_structure-based_2014,
abstract = {Structure-based drug discovery (SBDD) is becoming an essential tool in assisting fast and cost-efficient lead discovery and optimization. The application of rational, structure-based drug design is proven to be more efficient than the traditional way of drug discovery since it aims to understand the molecular basis of a disease and utilizes the knowledge of the three-dimensional structure of the biological target in the process. In this review, we focus on the principles and applications of Virtual Screening (VS) within the context of SBDD and examine different procedures ranging from the initial stages of the process that include receptor and library pre-processing, to docking, scoring and post-processing of topscoring hits. Recent improvements in structure-based virtual screening (SBVS) efficiency through ensemble docking, induced fit and consensus docking are also discussed. The review highlights advances in the field within the framework of several success studies that have led to nM inhibition directly from VS and provides recent trends in library design as well as discusses limitations of the method. Applications of SBVS in the design of substrates for engineered proteins that enable the discovery of new metabolic and signal transduction pathways and the design of inhibitors of multifunctional proteins are also reviewed. Finally, we contribute two promising VS protocols recently developed by us that aim to increase inhibitor selectivity. In the first protocol, we describe the discovery of micromolar inhibitors through SBVS designed to inhibit the mutant H1047R PI3K$\alpha$ kinase. Second, we discuss a strategy for the identification of selective binders for the RXR$\alpha$ nuclear receptor. In this protocol, a set of target structures is constructed for ensemble docking based on binding site shape characterization and clustering, aiming to enhance the hit rate of selective inhibitors for the desired protein target through the SBVS process.},
author = {Lionta, Evanthia and Spyrou, George and Vassilatis, Demetrios and Cournia, Zoe},
doi = {10.2174/1568026614666140929124445},
issn = {15680266},
journal = {Curr. Top. Med. Chem.},
keywords = {*Drug Discovery,Humans,Molecular Structure,Phosphatidylinositol 3-Kinases/*analysis/metaboli,Protein Kinase Inhibitors/chemical synthesis/chem,Structure-Activity Relationship},
number = {16},
pages = {1923--1938},
pmid = {25262799},
title = {{Structure-Based Virtual Screening for Drug Discovery: Principles, Applications and Recent Advances}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/25262799},
volume = {14},
year = {2014}
}
@article{ballester_does_2014,
abstract = {Predicting the binding affinities of large sets of diverse molecules against a range of macromolecular targets is an extremely challenging task. The scoring functions that attempt such computational prediction are essential for exploiting and analyzing the outputs of docking, which is in turn an important tool in problems such as structure-based drug design. Classical scoring functions assume a predetermined theory-inspired functional form for the relationship between the variables that describe an experimentally determined or modeled structure of a protein-ligand complex and its binding affinity. The inherent problem of this approach is in the difficulty of explicitly modeling the various contributions of intermolecular interactions to binding affinity. New scoring functions based on machine-learning regression models, which are able to exploit effectively much larger amounts of experimental data and circumvent the need for a predetermined functional form, have already been shown to outperform a broad range of state-of-the-art scoring functions in a widely used benchmark. Here, we investigate the impact of the chemical description of the complex on the predictive power of the resulting scoring function using a systematic battery of numerical experiments. The latter resulted in the most accurate scoring function to date on the benchmark. Strikingly, we also found that a more precise chemical description of the protein-ligand complex does not generally lead to a more accurate prediction of binding affinity. We discuss four factors that may contribute to this result: modeling assumptions, codependence of representation and regression, data restricted to the bound state, and conformational heterogeneity in data. {\textcopyright} 2014 American Chemical Society.},
author = {Ballester, Pedro J. and Schreyer, Adrian and Blundell, Tom L.},
doi = {10.1021/ci500091r},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ballester, Schreyer, Blundell - 2014 - Does a more precise chemical description of protein-ligand complexes lead to more accurate predic.pdf:pdf},
issn = {15205142},
journal = {J. Chem. Inf. Model.},
number = {3},
pages = {944--955},
title = {{Does a more precise chemical description of protein-ligand complexes lead to more accurate prediction of binding affinity?}},
url = {http://pubs.acs.org/doi/10.1021/ci500091r},
volume = {54},
year = {2014}
}
@article{Xu2015,
annote = {doi: 10.1021/acs.jcim.5b00238},
author = {Xu, Youjun and Dai, Ziwei and Chen, Fangjin and Gao, Shuaishi and Pei, Jianfeng and Lai, Luhua},
doi = {10.1021/acs.jcim.5b00238},
issn = {1549-9596},
journal = {J. Chem. Inf. Model.},
month = {oct},
number = {10},
pages = {2085--2093},
publisher = {American Chemical Society},
title = {{Deep Learning for Drug-Induced Liver Injury}},
url = {https://doi.org/10.1021/acs.jcim.5b00238},
volume = {55},
year = {2015}
}
@article{li_overview_2019,
abstract = {Currently, molecular docking is becoming a key tool in drug discovery and molecular modeling applications. The reliability of molecular docking depends on the accuracy of the adopted scoring function, which can guide and determine the ligand poses when thousands of possible poses of ligand are generated. The scoring function can be used to determine the binding mode and site of a ligand, predict binding affinity and identify the potential drug leads for a given protein target. Despite intensive research over the years, accurate and rapid prediction of protein–ligand interactions is still a challenge in molecular docking. For this reason, this study reviews four basic types of scoring functions, physics-based, empirical, knowledge-based, and machine learning-based scoring functions, based on an up-to-date classification scheme. We not only discuss the foundations of the four types scoring functions, suitable application areas and shortcomings, but also discuss challenges and potential future study directions.},
author = {Li, Jin and Fu, Ailing and Zhang, Le},
doi = {10.1007/s12539-019-00327-w},
issn = {18671462},
journal = {Interdiscip. Sci. Comput. Life Sci.},
keywords = {Binding affinity,Ligand pose,Molecular docking,Protein–ligand interaction,Scoring function},
number = {2},
pages = {320--328},
title = {{An Overview of Scoring Functions Used for Protein–Ligand Interactions in Molecular Docking}},
url = {http://link.springer.com/10.1007/s12539-019-00327-w},
volume = {11},
year = {2019}
}
@article{Blayney2016,
abstract = {Here, we describe gene expression compositional assignment (GECA), a powerful, yet simple method based on compositional statistics that can validate the transfer of prior knowledge, such as gene lists, into independent data sets, platforms and technologies. Transcriptional profiling has been used to derive gene lists that stratify patients into prognostic molecular subgroups and assess biomarker performance in the pre-clinical setting. Archived public data sets are an invaluable resource for subsequent in silico validation, though their use can lead to data integration issues. We show that GECA can be used without the need for normalising expression levels between data sets and can outperform rank-based correlation methods. To validate GECA, we demonstrate its success in the cross-platform transfer of gene lists in different domains including: bladder cancer staging, tumour site of origin and mislabelled cell lines. We also show its effectiveness in transferring an epithelial ovarian cancer prognostic gene signature across technologies, from a microarray to a next-generation sequencing setting. In a final case study, we predict the tumour site of origin and histopathology of epithelial ovarian cancer cell lines. In particular, we identify and validate the commonly-used cell line OVCAR-5 as non-ovarian, being gastrointestinal in origin. GECA is available as an open-source R package.},
author = {Blayney, Jaine K and Davison, Timothy and McCabe, Nuala and Walker, Steven and Keating, Karen and Delaney, Thomas and Greenan, Caroline and Williams, Alistair R and McCluggage, W Glenn and Capes-Davis, Amanda and Harkin, D Paul and Gourley, Charlie and Kennedy, Richard D},
doi = {10.1093/nar/gkw578},
issn = {0305-1048},
journal = {Nucleic Acids Res.},
month = {jun},
number = {17},
pages = {e137--e137},
title = {{Prior knowledge transfer across transcriptional data sets and technologies using compositional statistics yields new mislabelled ovarian cell line}},
url = {https://doi.org/10.1093/nar/gkw578},
volume = {44},
year = {2016}
}
@article{Joshi2020,
abstract = {Author summary Integration of transcriptomics data with genome-scale metabolic models is appealing but challenging due to the number of parametric decisions required to be made to by the user. This is further exacerbated by models failing to capture functionalities which are important for cellular maintenance. In this study, we propose a thresholding method for functionally qualifying a metabolic reaction to be active. We used our method to extract models of NCI-60 cancer cell lines, human tissues, and C. elegans cell types. We show that our thresholding method improves the coverage of functions required for cellular maintenance. We also validated and compared models built with our approach against those with existing approaches using CRISPR-Cas9 essentiality screens. Overall, our study provides novel insights into how cells may deal with context-specific and ubiquitous functions.},
author = {Joshi, Chintan J and Schinn, Song-Min and Richelle, Anne and Shamie, Isaac and O'Rourke, Eyleen J and Lewis, Nathan E},
journal = {PLOS Comput. Biol.},
month = {may},
number = {5},
pages = {e1007764},
publisher = {Public Library of Science},
title = {{StanDep: Capturing transcriptomic variability improves context-specific metabolic models}},
url = {https://doi.org/10.1371/journal.pcbi.1007764},
volume = {16},
year = {2020}
}
@article{ain_machine-learning_2015,
abstract = {Docking tools to predict whether and how a small molecule binds to a target can be applied if a structural model of such target is available. The reliability of docking depends, however, on the accuracy of the adopted scoring function (SF). Despite intense research over the years, improving the accuracy of SFs for structure-based binding affinity prediction or virtual screening has proven to be a challenging task for any class of method. New SFs based on modern machine-learning regression models, which do not impose a predetermined functional form and thus are able to exploit effectively much larger amounts of experimental data, have recently been introduced. These machine-learning SFs have been shown to outperform a wide range of classical SFs at both binding affinity prediction and virtual screening. The emerging picture from these studies is that the classical approach of using linear regression with a small number of expert-selected structural features can be strongly improved by a machine-learning approach based on nonlinear regression allied with comprehensive data-driven feature selection. Furthermore, the performance of classical SFs does not grow with larger training datasets and hence this performance gap is expected to widen as more training data becomes available in the future. Other topics covered in this review include predicting the reliability of a SF on a particular target class, generating synthetic data to improve predictive performance and modeling guidelines for SF development.},
author = {Ain, Qurrat Ul and Aleksandrova, Antoniya and Roessler, Florian D. and Ballester, Pedro J.},
doi = {10.1002/wcms.1225},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ain et al. - 2015 - Machine-learning scoring functions to improve structure-based binding affinity prediction and virtual screening.pdf:pdf;:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ain et al. - 2015 - Machine-learning scoring functions to improve structure-based binding affinity prediction and virtual screening.html:html},
issn = {17590884},
journal = {Wiley Interdiscip. Rev. Comput. Mol. Sci.},
number = {6},
pages = {405--424},
title = {{Machine-learning scoring functions to improve structure-based binding affinity prediction and virtual screening}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1225},
volume = {5},
year = {2015}
}
@article{gaulton_chembl_2017,
abstract = {ChEMBL is an open large-scale bioactivity database (https://www.ebi.ac.uk/chembl), previously described in the 2012 and 2014 Nucleic Acids Research Database Issues. Since then, alongside the continued extraction of data from the medicinal chemistry literature, new sources of bioactivity data have also been added to the database. These include: deposited data sets from neglected disease screening; crop protection data; drug metabolism and disposition data and bioactivity data from patents. A number of improvements and new features have also been incorporated. These include the annotation of assays and targets using ontologies, the inclusion of targets and indications for clinical candidates, addition of metabolic pathways for drugs and calculation of structural alerts. The ChEMBL data can be accessed via a web-interface, RDF distribution, data downloads and RESTful web-services.},
author = {Gaulton, Anna and Hersey, Anne and Nowotka, Micha L. and {Patricia Bento}, A. and Chambers, Jon and Mendez, David and Mutowo, Prudence and Atkinson, Francis and Bellis, Louisa J. and Cibrian-Uhalte, Elena and Davies, Mark and Dedman, Nathan and Karlsson, Anneli and Magarinos, Maŕia Paula and Overington, John P. and Papadatos, George and Smit, Ines and Leach, Andrew R.},
doi = {10.1093/nar/gkw1074},
issn = {13624962},
journal = {Nucleic Acids Res.},
keywords = {*Databases,*Search Engine,Chemical,Computational Biology/methods,Crop Protection,Drug Discovery,Gene Ontology,Humans,Molecular Sequence Annotation,Nucleic Acid,Pharmacology/methods,User-Computer Interface,Web Browser},
number = {D1},
pages = {D945--D954},
title = {{The ChEMBL database in 2017}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/27899562},
volume = {45},
year = {2017}
}
@article{ericksen_machine_2017,
abstract = {In structure-based virtual screening, compound ranking through a consensus of scores from a variety of docking programs or scoring functions, rather than ranking by scores from a single program, provides better predictive performance and reduces target performance variability. Here we compare traditional consensus scoring methods with a novel, unsupervised gradient boosting approach. We also observed increased score variation among active ligands and developed a statistical mixture model consensus score based on combining score means and variances. To evaluate performance, we used the common performance metrics ROCAUC and EF1 on 21 benchmark targets from DUD-E. Traditional consensus methods, such as taking the mean of quantile normalized docking scores, outperformed individual docking methods and are more robust to target variation. The mixture model and gradient boosting provided further improvements over the traditional consensus methods. These methods are readily applicable to new targets in academic research and overcome the potentially poor performance of using a single docking method on a new target.},
author = {Ericksen, Spencer S. and Wu, Haozhen and Zhang, Huikun and Michael, Lauren A. and Newton, Michael A. and Hoffmann, F. Michael and Wildman, Scott A.},
doi = {10.1021/acs.jcim.7b00153},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ericksen et al. - 2017 - Machine Learning Consensus Scoring Improves Performance Across Targets in Structure-Based Virtual Screening.pdf:pdf},
issn = {15205142},
journal = {J. Chem. Inf. Model.},
number = {7},
pages = {1579--1590},
pmid = {28654262},
title = {{Machine Learning Consensus Scoring Improves Performance Across Targets in Structure-Based Virtual Screening}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5872818/},
volume = {57},
year = {2017}
}
@article{Swainston2016,
abstract = {INTRODUCTION: The human genome-scale metabolic reconstruction details all known  metabolic reactions occurring in humans, and thereby holds substantial promise for studying complex diseases and phenotypes. Capturing the whole human metabolic reconstruction is an on-going task and since the last community effort generated a consensus reconstruction, several updates have been developed. OBJECTIVES: We report a new consensus version, Recon 2.2, which integrates various alternative versions with significant additional updates. In addition to re-establishing a consensus reconstruction, further key objectives included providing more comprehensive annotation of metabolites and genes, ensuring full mass and charge balance in all reactions, and developing a model that correctly predicts ATP production on a range of carbon sources. METHODS: Recon 2.2 has been developed through a combination of manual curation and automated error checking. Specific and significant manual updates include a respecification of fatty acid metabolism, oxidative phosphorylation and a coupling of the electron transport chain to ATP synthase activity. All metabolites have definitive chemical formulae and charges specified, and these are used to ensure full mass and charge reaction balancing through an automated linear programming approach. Additionally, improved integration with transcriptomics and proteomics data has been facilitated with the updated curation of relationships between genes, proteins and reactions. RESULTS: Recon 2.2 now represents the most predictive model of human metabolism to date as demonstrated here. Extensive manual curation has increased the reconstruction size to 5324 metabolites, 7785 reactions and 1675 associated genes, which now are mapped to a single standard. The focus upon mass and charge balancing of all reactions, along with better representation of energy generation, has produced a flux model that correctly predicts ATP yield on different carbon sources. CONCLUSION: Through these updates we have achieved the most complete and best annotated consensus human metabolic reconstruction available, thereby increasing the ability of this resource to provide novel insights into normal and disease states in human. The model is freely available from the Biomodels database (http://identifiers.org/biomodels.db/MODEL1603150001).},
author = {Swainston, Neil and Smallbone, Kieran and Hefzi, Hooman and Dobson, Paul D and Brewer, Judy and Hanscho, Michael and Zielinski, Daniel C and Ang, Kok Siong and Gardiner, Natalie J and Gutierrez, Jahir M and Kyriakopoulos, Sarantos and Lakshmanan, Meiyappan and Li, Shangzhong and Liu, Joanne K and Mart{\'{i}}nez, Veronica S and Orellana, Camila A and Quek, Lake-Ee and Thomas, Alex and Zanghellini, Juergen and Borth, Nicole and Lee, Dong-Yup and Nielsen, Lars K and Kell, Douglas B and Lewis, Nathan E and Mendes, Pedro},
doi = {10.1007/s11306-016-1051-4},
issn = {1573-3882 (Print)},
journal = {Metabolomics},
language = {eng},
pages = {109},
pmid = {27358602},
title = {{Recon 2.2: from reconstruction to model of human metabolism.}},
volume = {12},
year = {2016}
}
@article{Chen2009,
abstract = {ToppGene Suite (http://toppgene.cchmc.org; this web site is free and open to all users and does not require a login to access) is a one-stop portal for (i) gene list functional enrichment, (ii) candidate gene prioritization using either functional annotations or network analysis and (iii) identification and prioritization of novel disease candidate genes in the interactome. Functional annotation-based disease candidate gene prioritization uses a fuzzy-based similarity measure to compute the similarity between any two genes based on semantic annotations. The similarity scores from individual features are combined into an overall score using statistical meta-analysis. A P-value of each annotation of a test gene is derived by random sampling of the whole genome. The protein-protein interaction network (PPIN)-based disease candidate gene prioritization uses social and Web networks analysis algorithms (extended versions of the PageRank and HITS algorithms, and the K-Step Markov method). We demonstrate the utility of ToppGene Suite using 20 recently reported GWAS-based gene-disease associations (including novel disease genes) representing five diseases. ToppGene ranked 19 of 20 (95{\%}) candidate genes within the top 20{\%}, while ToppNet ranked 12 of 16 (75{\%}) candidate genes among the top 20{\%}.},
author = {Chen, Jing and Bardes, Eric E and Aronow, Bruce J and Jegga, Anil G},
doi = {10.1093/nar/gkp427},
edition = {2009/05/22},
issn = {1362-4962},
journal = {Nucleic Acids Res.},
keywords = {*Genes,*Software,Animals,Disease/*genetics,Humans,Internet,Mice,Protein Interaction Mapping,Proteins/genetics},
language = {eng},
month = {jul},
number = {Web Server issue},
pages = {W305--W311},
publisher = {Oxford University Press},
title = {{ToppGene Suite for gene list enrichment analysis and candidate gene prioritization}},
url = {https://pubmed.ncbi.nlm.nih.gov/19465376 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2703978/},
volume = {37},
year = {2009}
}
@article{Latti2016,
abstract = {Receiver operating characteristics (ROC) curve with the calculation of area under curve (AUC) is a useful tool to evaluate the performance of biomedical and chemoinformatics data. For example, in virtual drug screening ROC curves are very often used to visualize the efficiency of the used application to separate active ligands from inactive molecules. Unfortunately, most of the available tools for ROC analysis are implemented into commercially available software packages, or are plugins in statistical software, which are not always the easiest to use. Here, we present Rocker, a simple ROC curve visualization tool that can be used for the generation of publication quality images. Rocker also includes an automatic calculation of the AUC for the ROC curve and Boltzmann-enhanced discrimination of ROC (BEDROC). Furthermore, in virtual screening campaigns it is often important to understand the early enrichment of active ligand identification, for this Rocker offers automated calculation routine. To enable further development of Rocker, it is freely available (MIT-GPL license) for use and modifications from our web-site (http://www.jyu.fi/rocker). Graphical Abstract:},
author = {L{\"{a}}tti, Sakari and Niinivehmas, Sanna and Pentik{\"{a}}inen, Olli T.},
doi = {10.1186/s13321-016-0158-y},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\"{a}}tti, Niinivehmas, Pentik{\"{a}}inen - 2016 - Rocker Open source, easy-to-use tool for AUC and enrichment calculations and ROC visualization.pdf:pdf},
issn = {17582946},
journal = {J. Cheminform.},
keywords = {Computational Biology/Bioinformatics,Computer Applications in Chemistry,Documentation and Information in Chemistry,Theoretical and Computational Chemistry},
month = {dec},
number = {1},
pages = {45},
publisher = {BioMed Central},
title = {{Rocker: Open source, easy-to-use tool for AUC and enrichment calculations and ROC visualization}},
url = {https://jcheminf.biomedcentral.com/articles/10.1186/s13321-016-0158-y},
volume = {8},
year = {2016}
}
@article{Chen2018d,
abstract = {Over the past decade, deep learning has achieved remarkable success in various artificial intelligence research areas. Evolved from the previous research on artificial neural networks, this technology has shown superior performance to other machine learning algorithms in areas such as image and voice recognition, natural language processing, among others. The first wave of applications of deep learning in pharmaceutical research has emerged in recent years, and its utility has gone beyond bioactivity predictions and has shown promise in addressing diverse problems in drug discovery. Examples will be discussed covering bioactivity prediction, de novo molecular design, synthesis prediction and biological image analysis.},
author = {Chen, Hongming and Engkvist, Ola and Wang, Yinhai and Olivecrona, Marcus and Blaschke, Thomas},
doi = {https://doi.org/10.1016/j.drudis.2018.01.039},
issn = {1359-6446},
journal = {Drug Discov. Today},
number = {6},
pages = {1241--1250},
title = {{The rise of deep learning in drug discovery}},
url = {http://www.sciencedirect.com/science/article/pii/S1359644617303598},
volume = {23},
year = {2018}
}
@article{Jerby2012,
abstract = {The metabolism of cancer cells is reprogrammed in various ways to support their growth and survival. Studying these phenomena to develop noninvasive diagnostic tools and selective treatments is a promising avenue. Metabolic modeling has recently emerged as a new way to study human metabolism in a systematic, genome-scale manner by using pertinent high-throughput omics data. This method has been shown in various studies to provide fairly accurate estimates of the metabolic phenotype and its modifications following genetic and environmental perturbations. Here, we provide an overview of genome-scale metabolic modeling and its current use to model human metabolism in health and disease. We then describe the initial steps made using it to study cancer metabolism and how it may be harnessed to enhance ongoing experimental efforts to identify drug targets and biomarkers for cancer in a rationale-based manner. Clin Cancer Res; 18(20); 5572–84. {\textcopyright}2012 AACR.},
author = {Jerby, Livnat and Ruppin, Eytan},
doi = {10.1158/1078-0432.CCR-12-1856},
journal = {Clin. Cancer Res.},
month = {oct},
number = {20},
pages = {5572 LP  -- 5584},
title = {{Predicting Drug Targets and Biomarkers of Cancer via Genome-Scale Metabolic Modeling}},
url = {http://clincancerres.aacrjournals.org/content/18/20/5572.abstract},
volume = {18},
year = {2012}
}
@article{li_improving_2015,
abstract = {There is a growing body of evidence showing that machine learning regression results in more accurate structure-based prediction of protein-ligand binding affinity. Docking methods that aim at optimizing the affinity of ligands for a target rely on how accurate their predicted ranking is. However, despite their proven advantages, machine-learning scoring functions are still not widely applied. This seems to be due to insufficient understanding of their properties and the lack of user-friendly software implementing them. Here we present a study where the accuracy of AutoDock Vina, arguably the most commonly-used docking software, is strongly improved by following a machine learning approach. We also analyse the factors that are responsible for this improvement and their generality. Most importantly, with the help of a proposed benchmark, we demonstrate that this improvement will be larger as more data becomes available for training Random Forest models, as regression models implying additive functional forms do not improve with more training data. We discuss how the latter opens the door to new opportunities in scoring function development. In order to facilitate the translation of this advance to enhance structure-based molecular design, we provide software to directly re-score Vina-generated poses and thus strongly improve their predicted binding affinity. The software is available at http://istar.cse.cuhk.edu.hk/rf-score-3.tgz and http://crcm. marseille.inserm.fr/fileadmin/rf-score-3.tgz},
author = {Li, Hongjian and Leung, Kwong Sak and Wong, Man Hon and Ballester, Pedro J.},
doi = {10.1002/minf.201400132},
issn = {18681751},
journal = {Mol. Inform.},
keywords = {Docking,Drug lead optimization,Machine learning},
number = {2-3},
pages = {115--126},
shorttitle = {Improving {\{}AutoDock{\}} {\{}Vina{\}} {\{}Using{\}} {\{}Random{\}} {\{}Fore}},
title = {{Improving autodock vina using random forest: The growing accuracy of binding affinity prediction by the effective exploitation of larger data sets}},
url = {http://doi.wiley.com/10.1002/minf.201400132},
volume = {34},
year = {2015}
}
@article{coleman_ligand_2013,
abstract = {Molecular docking remains an important tool for structure-based screening to find new ligands and chemical probes. As docking ambitions grow to include new scoring function terms, and to address ever more targets, the reliability and extendability of the orientation sampling, and the throughput of the method, become pressing. Here we explore sampling techniques that eliminate stochastic behavior in DOCK3.6, allowing us to optimize the method for regularly variable sampling of orientations. This also enabled a focused effort to optimize the code for efficiency, with a three-fold increase in the speed of the program. This, in turn, facilitated extensive testing of the method on the 102 targets, 22,805 ligands and 1,411,214 decoys of the Directory of Useful Decoys - Enhanced (DUD-E) benchmarking set, at multiple levels of sampling. Encouragingly, we observe that as sampling increases from 50 to 500 to 2000 to 5000 to 20000 molecular orientations in the binding site (and so from about 1×1010 to 4×1010 to 1×1011 to 2×1011 to 5×1011 mean atoms scored per target, since multiple conformations are sampled per orientation), the enrichment of ligands over decoys monotonically increases for most DUD-E targets. Meanwhile, including internal electrostatics in the evaluation ligand conformational energies, and restricting aromatic hydroxyls to low energy rotamers, further improved enrichment values. Several of the strategies used here to improve the efficiency of the code are broadly applicable in the field. {\textcopyright} 2013 Coleman et al.},
author = {Coleman, Ryan G. and Carchia, Michael and Sterling, Teague and Irwin, John J. and Shoichet, Brian K.},
doi = {10.1371/journal.pone.0075992},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Coleman et al. - 2013 - Ligand Pose and Orientational Sampling in Molecular Docking.pdf:pdf;:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Coleman et al. - 2013 - Ligand Pose and Orientational Sampling in Molecular Docking.html:html},
issn = {19326203},
journal = {PLoS One},
keywords = {Algorithms,Computer software,Electrostatics,Interpolation,Library screening,Molecular docking,Protein kinases,Small molecules},
number = {10},
pages = {e75992},
title = {{Ligand Pose and Orientational Sampling in Molecular Docking}},
url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0075992},
volume = {8},
year = {2013}
}
@article{mysinger_directory_2012,
abstract = {A key metric to assess molecular docking remains ligand enrichment against challenging decoys. Whereas the directory of useful decoys (DUD) has been widely used, clear areas for optimization have emerged. Here we describe an improved benchmarking set that includes more diverse targets such as GPCRs and ion channels, totaling 102 proteins with 22886 clustered ligands drawn from ChEMBL, each with 50 property-matched decoys drawn from ZINC. To ensure chemotype diversity, we cluster each target's ligands by their Bemis-Murcko atomic frameworks. We add net charge to the matched physicochemical properties and include only the most dissimilar decoys, by topology, from the ligands. An online automated tool (http://decoys.docking.org) generates these improved matched decoys for user-supplied ligands. We test this data set by docking all 102 targets, using the results to improve the balance between ligand desolvation and electrostatics in DOCK 3.6. The complete DUD-E benchmarking set is freely available at http://dude.docking.org. {\textcopyright} 2012 American Chemical Society.},
author = {Mysinger, Michael M. and Carchia, Michael and Irwin, John J. and Shoichet, Brian K.},
doi = {10.1021/jm300687e},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mysinger et al. - 2012 - Directory of useful decoys, enhanced (DUD-E) Better ligands and decoys for better benchmarking.pdf:pdf;:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mysinger et al. - 2012 - Directory of useful decoys, enhanced (DUD-E) Better ligands and decoys for better benchmarking.html:html},
issn = {00222623},
journal = {J. Med. Chem.},
number = {14},
pages = {6582--6594},
shorttitle = {Directory of {\{}Useful{\}} {\{}Decoys{\}}, {\{}Enhanced{\}} ({\{}DUD{\}}-},
title = {{Directory of useful decoys, enhanced (DUD-E): Better ligands and decoys for better benchmarking}},
url = {https://doi.org/10.1021/jm300687e},
volume = {55},
year = {2012}
}
@article{Alonso-Betanzos2019d,
abstract = {The advent of DNA microarray datasets has stimulated a new line of research both in  bioinformatics and in machine learning. This type of data is used to collect information from tissue and cell samples regarding gene expression differences that could be useful for disease diagnosis or for distinguishing specific types of tumor. Microarray data classification is a difficult challenge for machine learning researchers due to its high number of features and the small sample sizes. This chapter is devoted to reviewing the microarray databases most frequently used in the literature. We also make the interested reader aware of the problematic of data characteristics in this domain, such as the imbalance of the data, their complexity, and the so-called dataset shift.},
author = {Alonso-Betanzos, Amparo and Bol{\'{o}}n-Canedo, Ver{\'{o}}nica and Mor{\'{a}}n-Fern{\'{a}}ndez, Laura and S{\'{a}}nchez-Maro{\~{n}}o, Noelia},
doi = {10.1007/978-1-4939-9442-7_4},
issn = {1940-6029 (Electronic)},
journal = {Methods Mol. Biol.},
keywords = {Databases, Genetic,Humans,Neoplasms,Oligonucleotide Array Sequence Analysis,Sample Size,genetics},
language = {eng},
pages = {65--85},
pmid = {31115885},
title = {{A Review of Microarray Datasets: Where to Find Them and Specific Characteristics.}},
volume = {1986},
year = {2019}
}
@article{Low2011,
abstract = {Quantitative structure-activity relationship (QSAR) modeling and toxicogenomics are typically used independently as predictive tools in toxicology. In this study, we evaluated the power of several statistical models for predicting drug hepatotoxicity in rats using different descriptors of drug molecules, namely, their chemical descriptors and toxicogenomics profiles. The records were taken from the Toxicogenomics Project rat liver microarray database containing information on 127 drugs (http://toxico.nibio.go.jp/datalist.html). The model end point was hepatotoxicity in the rat following 28 days of continuous exposure, established by liver histopathology and serum chemistry. First, we developed multiple conventional QSAR classification models using a comprehensive set of chemical descriptors and several classification methods (k nearest neighbor, support vector machines, random forests, and distance weighted discrimination). With chemical descriptors alone, external predictivity (correct classification rate, CCR) from 5-fold external cross-validation was 61{\%}. Next, the same classification methods were employed to build models using only toxicogenomics data (24 h after a single exposure) treated as biological descriptors. The optimized models used only 85 selected toxicogenomics descriptors and had CCR as high as 76{\%}. Finally, hybrid models combining both chemical descriptors and transcripts were developed; their CCRs were between 68 and 77{\%}. Although the accuracy of hybrid models did not exceed that of the models based on toxicogenomics data alone, the use of both chemical and biological descriptors enriched the interpretation of the models. In addition to finding 85 transcripts that were predictive and highly relevant to the mechanisms of drug-induced liver injury, chemical structural alerts for hepatotoxicity were identified. These results suggest that concurrent exploration of the chemical features and acute treatment-induced changes in transcript levels will both enrich the mechanistic understanding of subchronic liver injury and afford models capable of accurate prediction of hepatotoxicity from chemical structure and short-term assay results. {\textcopyright} 2011 American Chemical Society.},
author = {Low, Yen and Uehara, Takeki and Minowa, Yohsuke and Yamada, Hiroshi and Ohno, Yasuo and Urushidani, Tetsuro and Sedykh, Alexander and Muratov, Eugene and Kuzmin, Viktor and Fourches, Denis and Zhu, Hao and Rusyn, Ivan and Tropsha, Alexander},
doi = {10.1021/tx200148a},
issn = {0893228X},
journal = {Chem. Res. Toxicol.},
month = {aug},
number = {8},
pages = {1251--1262},
publisher = {NIH Public Access},
title = {{Predicting drug-induced hepatotoxicity using QSAR and toxicogenomics approaches}},
volume = {24},
year = {2011}
}
@article{lagarde_benchmarking_2015,
abstract = {Virtual screening methods are commonly used nowadays in drug discovery processes. However, to ensure their reliability, they have to be carefully evaluated. The evaluation of these methods is often realized in a retrospective way, notably by studying the enrichment of benchmarking data sets. To this purpose, numerous benchmarking data sets were developed over the years, and the resulting improvements led to the availability of high quality benchmarking data sets. However, some points still have to be considered in the selection of the active compounds, decoys, and protein structures to obtain optimal benchmarking data sets. (Figure Presented).},
author = {Lagarde, Nathalie and Zagury, Jean Fran{\c{c}}ois and Montes, Matthieu},
doi = {10.1021/acs.jcim.5b00090},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lagarde, Zagury, Montes - 2015 - Benchmarking Data Sets for the Evaluation of Virtual Ligand Screening Methods Review and Perspectives.pdf:pdf},
issn = {15205142},
journal = {J. Chem. Inf. Model.},
number = {7},
pages = {1297--1307},
shorttitle = {Benchmarking {\{}Data{\}} {\{}Sets{\}} for the {\{}Evaluation{\}} of},
title = {{Benchmarking Data Sets for the Evaluation of Virtual Ligand Screening Methods: Review and Perspectives}},
url = {http://pubs.acs.org/doi/10.1021/acs.jcim.5b00090},
volume = {55},
year = {2015}
}
@article{koes_lessons_2013,
abstract = {We describe a general methodology for designing an empirical scoring function and provide smina, a version of AutoDock Vina specially optimized to support high-throughput scoring and user-specified custom scoring functions. Using our general method, the unique capabilities of smina, a set of default interaction terms from AutoDock Vina, and the CSAR (Community Structure-Activity Resource) 2010 data set, we created a custom scoring function and evaluated it in the context of the CSAR 2011 benchmarking exercise. We find that our custom scoring function does a better job sampling low RMSD poses when crossdocking compared to the default AutoDock Vina scoring function. The design and application of our method and scoring function reveal several insights into possible improvements and the remaining challenges when scoring and ranking putative ligands. {\textcopyright} 2013 American Chemical Society.},
author = {Koes, David Ryan and Baumgartner, Matthew P. and Camacho, Carlos J.},
doi = {10.1021/ci300604z},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Koes, Baumgartner, Camacho - 2013 - Lessons learned in empirical scoring with smina from the CSAR 2011 benchmarking exercise.pdf:pdf},
issn = {15499596},
journal = {J. Chem. Inf. Model.},
number = {8},
pages = {1893--1904},
title = {{Lessons learned in empirical scoring with smina from the CSAR 2011 benchmarking exercise}},
url = {http://pubs.acs.org/doi/10.1021/ci300604z},
volume = {53},
year = {2013}
}
@article{Lamb2006,
abstract = {To pursue a systematic approach to the discovery of functional connections among diseases, genetic perturbation, and drug action, we have created the first installment of a reference collection of gene-expression profiles from cultured human cells treated with bioactive small molecules, together with pattern-matching software to mine these data. We demonstrate that this "Connectivity Map" resource can be used to find connections among small molecules sharing a mechanism of action, chemicals and physiological processes, and diseases and drugs. These results indicate the feasibility of the approach and suggest the value of a large-scale community Connectivity Map project.},
author = {Lamb, Justin and Crawford, Emily D. and Peck, David and Modell, Joshua W. and Blat, Irene C. and Wrobel, Matthew J. and Lerner, Jim and Brunet, Jean Philippe and Subramanian, Aravind and Ross, Kenneth N. and Reich, Michael and Hieronymus, Haley and Wei, Guo and Armstrong, Scott A. and Haggarty, Stephen J. and Clemons, Paul A. and Wei, Ru and Carr, Steven A. and Lander, Eric S. and Golub, Todd R.},
doi = {10.1126/science.1132939},
issn = {00368075},
journal = {Science (80-. ).},
month = {sep},
number = {5795},
pages = {1929--1935},
pmid = {17008526},
title = {{The connectivity map: Using gene-expression signatures to connect small molecules, genes, and disease}},
url = {https://www.sciencemag.org/lookup/doi/10.1126/science.1132939},
volume = {313},
year = {2006}
}
@article{Zhang2015,
abstract = {Predicting drug side effects is an important topic in the drug discovery. Although several machine learning methods have been proposed to predict side effects, there is still space for improvements. Firstly, the side effect prediction is a multi-label learning task, and we can adopt the multi-label learning techniques for it. Secondly, drug-related features are associated with side effects, and feature dimensions have specific biological meanings. Recognizing critical dimensions and reducing irrelevant dimensions may help to reveal the causes of side effects.},
author = {Zhang, Wen and Liu, Feng and Luo, Longqiang and Zhang, Jingxia},
doi = {10.1186/s12859-015-0774-y},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {1},
pages = {365},
title = {{Predicting drug side effects by multi-label learning and ensemble learning}},
url = {https://doi.org/10.1186/s12859-015-0774-y},
volume = {16},
year = {2015}
}
@article{Bacher2017,
abstract = {The normalization of RNA-seq data is essential for accurate downstream inference, but the assumptions upon which most normalization methods are based are not applicable in the single-cell setting. Consequently, applying existing normalization methods to single-cell RNA-seq data introduces artifacts that bias downstream analyses. To address this, we introduce SCnorm for accurate and efficient normalization of single-cell RNA-seq data.},
author = {Bacher, Rhonda and Chu, Li Fang and Leng, Ning and Gasch, Audrey P. and Thomson, James A. and Stewart, Ron M. and Newton, Michael and Kendziorski, Christina},
doi = {10.1038/nmeth.4263},
issn = {15487105},
journal = {Nat. Methods},
month = {may},
number = {6},
pages = {584--586},
publisher = {Nature Publishing Group},
title = {{SCnorm: Robust normalization of single-cell RNA-seq data}},
url = {http://www.nature.com/articles/nmeth.4263},
volume = {14},
year = {2017}
}
@article{Basu2019,
author = {Basu, Niladri and Crump, Doug and Head, Jessica and Hickey, Gordon and Hogan, Natacha and Maguire, Steve and Xia, Jianguo and Hecker, Markus},
doi = {10.1002/etc.4309},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Basu et al. - 2019 - EcoToxChip A next‐generation toxicogenomics tool for chemical prioritization and environmental management.pdf:pdf},
issn = {0730-7268},
journal = {Environ. Toxicol. Chem.},
month = {feb},
number = {2},
pages = {279--288},
publisher = {Wiley Blackwell},
title = {{EcoToxChip: A next‐generation toxicogenomics tool for chemical prioritization and environmental management}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/etc.4309},
volume = {38},
year = {2019}
}
@article{Sarfraz2020d,
abstract = {Gene expression microarrays capture a complete image of all the transcriptional activity in a biological sample. Microarrays produce a large amount of data, which becomes a challenge when it comes to exploring and interpreting using modern computational and statistical tools. We propose the Microarray Analysis (MiCA) tool that outperforms other similar tools both in terms of ease of use and statistical features requiring minimal input to conduct an analysis. MiCA is an integrated, interactive, and streamlined desktop software for the analysis of microarray gene expression data. MiCA consists of a complete microarray analysis pipeline including but not limited to fetching data directly from GEO, normalization, interactive quality control, batch-effect correction, regression analysis, surrogate variable analysis and functional annotation methods such as GSVA using known existing R packages. We compare the features offered by MiCA and other similar tools while performing differential expression analysis using previously published datasets. MiCA offers additional statistical and visualization methods to conduct a microarray data analysis compared to other available microarray analysis tools. MiCA minimizes the need for technical knowledge by providing a very intuitive and versatile interface that integrates all necessary tasks and features required for basic microarray data analysis. We analyzed multiple published datasets and showed that the features offered by MiCA not only simplify the analysis pipeline but also provide additional interpretation to the data.},
author = {Sarfraz, Irzam and Asif, Muhammad and Hijazi, Kahkeshan},
doi = {https://doi.org/10.1016/j.compbiomed.2019.103561},
issn = {0010-4825},
journal = {Comput. Biol. Med.},
keywords = {Data analysis,Differential expression,Functional enrichment,Gene expression omnibus,Interactive environment,Microarray,Quality control},
pages = {103561},
title = {{MiCA: An extended tool for microarray gene expression analysis}},
url = {http://www.sciencedirect.com/science/article/pii/S0010482519304160},
volume = {116},
year = {2020}
}
@article{Blucher2019,
author = {Blucher, A S and McWeeney, S K and Stein, L and Wu, G},
doi = {10.12688/f1000research.19592.1},
journal = {F1000Research},
number = {908},
title = {{Visualization of drug target interactions in the contexts of pathways and networks with ReactomeFIViz [version 1; peer review: 3 approved]}},
url = {http://openr.es/gkq},
volume = {8},
year = {2019}
}
@article{Risso2014,
abstract = {Remove unwanted variation (RUV) is a new statistical method for RNA-seq data normalization that uses control genes or samples to improve differential expression analysis.},
author = {Risso, Davide and Ngai, John and Speed, Terence P and Dudoit, Sandrine},
doi = {10.1038/nbt.2931},
issn = {1546-1696},
journal = {Nat. Biotechnol.},
number = {9},
pages = {896--902},
title = {{Normalization of RNA-seq data using factor analysis of control genes or samples}},
url = {https://doi.org/10.1038/nbt.2931},
volume = {32},
year = {2014}
}
@article{Zhang2019d,
abstract = {Abstract Primary Sj{\"{o}}gren's syndrome (pSS) is a chronic systemic autoimmune disease that affects exocrine glands. To study the molecular mechanism and identify crucial genes/pathways in pSS pathogenesis, the microarray-based whole-genome gene expression profiles from salivary glands of patients with pSS and non-sicca controls were retrieved. After normalization and subsequent batch effect adjustment, significance analysis of microarrays method was applied to five available datasets, and 379 differentially expressed genes (DEGs) were identified. The 300 upregulated DEGs were enriched in Gene Ontology terms of immune and inflammatory responses, including antigen processing and presentation, interferon-mediated signaling pathway, and chemotaxis. Previously reported pSS-associated genes, including HLA-DRA, TAP2, PRDM1, and IFI16, were found to be significantly upregulated. The downregulated DEGs were enriched in pathways of salivary secretion, carbohydrate digestion and absorption, and starch and sucrose metabolism, implying dysfunction of salivary glands during pathogenesis. Next, a protein-protein interaction network was constructed, and B2M, an upregulated DEG, was shown to be a hub, suggesting its potential involvement in pSS development. In summary, we found the activation of pSS-associated genes in pathogenesis, and provide clues for salivary glands dysfunction. Experimental investigation on the identified DEGs in this study will deepen our understanding on pSS.},
annote = {doi: 10.1002/jcb.29001},
author = {Zhang, Lei and Xu, Poshi and Wang, Xiaoyu and Zhang, Zongshan and Zhao, Wenxin and Li, Zhengmin and Yang, Guangxia and Liu, Panpan},
doi = {10.1002/jcb.29001},
issn = {0730-2312},
journal = {J. Cell. Biochem.},
keywords = {differentially expressed genes,gene expression microarray,meta-analysis,primary Sj{\"{o}}gren's syndrome,salivary glands},
month = {oct},
number = {10},
pages = {17368--17377},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Identification of differentially expressed genes in primary Sj{\"{o}}gren's syndrome}},
url = {https://doi.org/10.1002/jcb.29001},
volume = {120},
year = {2019}
}
@article{guba_torsion_2016,
abstract = {The Torsion Library contains hundreds of rules for small molecule conformations which have been derived from the Cambridge Structural Database (CSD) and are curated by molecular design experts. The torsion rules are encoded as SMARTS patterns and categorize rotatable bonds via a traffic light coloring scheme. We have systematically revised all torsion rules to better identify highly strained conformations and minimize the number of false alerts for CSD small molecule X-ray structures. For this new release, we added or substantially modified 78 torsion patterns and reviewed all angles and tolerance intervals. The overall number of red alerts for a filtered CSD data set with 130 000 structures was reduced by a factor of 4 compared to the predecessor. This is of clear advantage in 3D virtual screening where hits should only be removed by a conformational filter if they are in energetically inaccessible conformations.},
author = {Guba, Wolfgang and Meyder, Agnes and Rarey, Matthias and Hert, J{\'{e}}ro{\^{i}}me},
doi = {10.1021/acs.jcim.5b00522},
issn = {15205142},
journal = {J. Chem. Inf. Model.},
number = {1},
pages = {1--5},
shorttitle = {Torsion {\{}Library{\}} {\{}Reloaded{\}}},
title = {{Torsion Library Reloaded: A New Version of Expert-Derived SMARTS Rules for Assessing Conformations of Small Molecules}},
url = {http://pubs.acs.org/doi/10.1021/acs.jcim.5b00522},
volume = {56},
year = {2016}
}
@article{Ji2018,
abstract = {SUMMARY: In this work, we present eMolTox, a web server for the prediction of  potential toxicity associated with a given molecule. A total of 174 toxicology-related in vitro/vivo experimental datasets were used for model construction and Mondrian conformal prediction was used to estimate the confidence of the resulting predictions. Toxic substructure analysis is also implemented in eMolTox. eMolTox predicts and displays a wealth of information of potential molecular toxicities for safety analysis in drug development. AVAILABILITY AND IMPLEMENTATION: The eMolTox Server is freely available for use on the web at http://xundrug.cn/moltox. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
author = {Ji, Changge and Svensson, Fredrik and Zoufir, Azedine and Bender, Andreas},
doi = {10.1093/bioinformatics/bty135},
issn = {1367-4811 (Electronic)},
journal = {Bioinformatics},
keywords = {Animals,Carcinogens,Humans,Mutagens,Software,Toxicology,methods,toxicity},
language = {eng},
month = {jul},
number = {14},
pages = {2508--2509},
pmid = {29522123},
title = {{eMolTox: prediction of molecular toxicity with confidence.}},
volume = {34},
year = {2018}
}
@article{Shlomi2008,
abstract = {Direct in vivo investigation of mammalian metabolism is complicated by the distinct  metabolic functions of different tissues. We present a computational method that successfully describes the tissue specificity of human metabolism on a large scale. By integrating tissue-specific gene- and protein-expression data with an existing comprehensive reconstruction of the global human metabolic network, we predict tissue-specific metabolic activity in ten human tissues. This reveals a central role for post-transcriptional regulation in shaping tissue-specific metabolic activity profiles. The predicted tissue specificity of genes responsible for metabolic diseases and tissue-specific differences in metabolite exchange with biofluids extend markedly beyond tissue-specific differences manifest in enzyme-expression data, and are validated by large-scale mining of tissue-specificity data. Our results establish a computational basis for the genome-wide study of normal and abnormal human metabolism in a tissue-specific manner.},
author = {Shlomi, Tomer and Cabili, Moran N and Herrg{\aa}rd, Markus J and Palsson, Bernhard {\O} and Ruppin, Eytan},
doi = {10.1038/nbt.1487},
issn = {1546-1696 (Electronic)},
journal = {Nat. Biotechnol.},
keywords = {Cell Physiological Phenomena,Computational Biology,Databases, Protein,Gene Expression Profiling,Gene Expression Regulation,Genome, Human,Humans,Metabolic Networks and Pathways,Models, Genetic,Models, Statistical,Reproducibility of Results,Software,genetics,methods,physiology},
language = {eng},
month = {sep},
number = {9},
pages = {1003--1010},
pmid = {18711341},
title = {{Network-based prediction of human tissue-specific metabolism.}},
volume = {26},
year = {2008}
}
@article{Carbonell2017,
abstract = {The present study applies a systems biology approach for the in silico predictive modeling of drug toxicity on the basis of high-quality preclinical drug toxicity data with the aim of increasing the mechanistic understanding of toxic effects of compounds at different levels (pathway, cell, tissue, organ). The model development was carried out using 77 compounds for which gene expression data for treated primary human hepatocytes is available in the LINCS database and for which rodent in vivo hepatotoxicity information is available in the eTOX database. The data from LINCS were used to determine the type and number of pathways disturbed by each compound and to estimate the extent of disturbance (network perturbation elasticity), and were used to analyze the correspondence with the in vivo information from eTOX. Predictive models were developed through this integrative analysis, and their specificity and sensitivity were assessed. The quality of the predictions was determined on the basis of the area under the curve (AUC) of plots of true positive vs. false positive rates (ROC curves). The ROC AUC reached values of up to 0.9 (out of 1.0) for some hepatotoxicity endpoints. Moreover, the most frequently disturbed metabolic pathways were determined across the studied toxicants. They included, e.g., mitochondrial beta-oxidation of fatty acids and amino acid metabolism. The process was exemplified by successful predictions on various statins. In conclusion, an entirely new approach linking gene expression alterations to the prediction of complex organ toxicity was developed and evaluated.},
author = {Carbonell, Pablo and Lopez, Oriol and Amberg, Alexander and Pastor, Manuel and Sanz, Ferran},
doi = {10.14573/altex.1602071},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Carbonell et al. - 2017 - Hepatotoxicity prediction by systems biology modeling of disturbed metabolic pathways using gene expression da.pdf:pdf},
issn = {18688551},
journal = {ALTEX},
keywords = {Drug toxicity,Gene regulation,Hepatotoxicity,Predictive modeling,Systems biology},
month = {may},
number = {2},
pages = {219--234},
publisher = {Elsevier GmbH},
title = {{Hepatotoxicity prediction by systems biology modeling of disturbed metabolic pathways using gene expression data}},
volume = {34},
year = {2017}
}
@article{chaput_benchmark_2016,
abstract = {Background: In a structure-based virtual screening, the choice of the docking program is essential for the success of a hit identification. Benchmarks are meant to help in guiding this choice, especially when undertaken on a large variety of protein targets. Here, the performance of four popular virtual screening programs, Gold, Glide, Surflex and FlexX, is compared using the Directory of Useful Decoys-Enhanced database (DUD-E), which includes 102 targets with an average of 224 ligands per target and 50 decoys per ligand, generated to avoid biases in the benchmarking. Then, a relationship between these program performances and the properties of the targets or the small molecules was investigated. Results: The comparison was based on two metrics, with three different parameters each. The BEDROC scores with $\alpha$ = 80.5, indicated that, on the overall database, Glide succeeded (score {\textgreater} 0.5) for 30 targets, Gold for 27, FlexX for 14 and Surflex for 11. The performance did not depend on the hydrophobicity nor the openness of the protein cavities, neither on the families to which the proteins belong. However, despite the care in the construction of the DUD-E database, the small differences that remain between the actives and the decoys likely explain the successes of Gold, Surflex and FlexX. Moreover, the similarity between the actives of a target and its crystal structure ligand seems to be at the basis of the good performance of Glide. When all targets with significant biases are removed from the benchmarking, a subset of 47 targets remains, for which Glide succeeded for only 5 targets, Gold for 4 and FlexX and Surflex for 2. Conclusion: The performance dramatic drop of all four programs when the biases are removed shows that we should beware of virtual screening benchmarks, because good performances may be due to wrong reasons. Therefore, benchmarking would hardly provide guidelines for virtual screening experiments, despite the tendency that is maintained, i.e., Glide and Gold display better performance than FlexX and Surflex. We recommend to always use several programs and combine their results. Graphical Abstract Summary of the results obtained by virtual screening with the four programs, Glide, Gold, Surflex and FlexX, on the 102 targets of the DUD-E database. The percentage of targets with successful results, i.e., with BDEROC($\alpha$ = 80.5) {\textgreater} 0.5, when the entire database is considered are in Blue, and when targets with biased chemical libraries are removed are in Red.},
author = {Chaput, Ludovic and Martinez-Sanz, Juan and Saettel, Nicolas and Mouawad, Liliane},
doi = {10.1186/s13321-016-0167-x},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chaput et al. - 2016 - Benchmark of four popular virtual screening programs construction of the activedecoy dataset remains a major dete.pdf:pdf},
issn = {17582946},
journal = {J. Cheminform.},
keywords = {BEDROC,Benchmark,DUD-E,Docking,FlexX,Glide,Gold,Structure-based virtual screening,Surflex},
number = {1},
pages = {1--17},
shorttitle = {Benchmark of four popular virtual screening progra},
title = {{Benchmark of four popular virtual screening programs: construction of the active/decoy dataset remains a major determinant of measured performance}},
url = {http://jcheminf.springeropen.com/articles/10.1186/s13321-016-0167-x},
volume = {8},
year = {2016}
}
@article{Ellinger-Ziegelbauer2011,
abstract = {The InnoMed PredTox consortium was formed to evaluate whether conventional preclinical safety assessment can be significantly enhanced by incorporation of molecular profiling (“omics”) technologies. In short-term toxicological studies in rats, transcriptomics, proteomics and metabolomics data were collected and analyzed in relation to routine clinical chemistry and histopathology. Four of the sixteen hepato- and/or nephrotoxicants given to rats for 1, 3, or 14days at two dose levels induced similar histopathological effects. These were characterized by bile duct necrosis and hyperplasia and/or increased bilirubin and cholestasis, in addition to hepatocyte necrosis and regeneration, hepatocyte hypertrophy, and hepatic inflammation. Combined analysis of liver transcriptomics data from these studies revealed common gene expression changes which allowed the development of a potential sequence of events on a mechanistic level in accordance with classical endpoint observations. This included genes implicated in early stress responses, regenerative processes, inflammation with inflammatory cell immigration, fibrotic processes, and cholestasis encompassing deregulation of certain membrane transporters. Furthermore, a preliminary classification analysis using transcriptomics data suggested that prediction of cholestasis may be possible based on gene expression changes seen at earlier time-points. Targeted bile acid analysis, based on LC-MS metabonomics data demonstrating increased levels of conjugated or unconjugated bile acids in response to individual compounds, did not provide earlier detection of toxicity as compared to conventional parameters, but may allow distinction of different types of hepatobiliary toxicity. Overall, liver transcriptomics data delivered mechanistic and molecular details in addition to the classical endpoint observations which were further enhanced by targeted bile acid analysis using LC/MS metabonomics.},
author = {Ellinger-Ziegelbauer, Heidrun and Adler, Melanie and Amberg, Alexander and Brandenburg, Arnd and Callanan, John J and Connor, Susan and Fountoulakis, Michael and Gmuender, Hans and Gruhler, Albrecht and Hewitt, Philip and Hodson, Mark and Matheis, Katja A and McCarthy, Diane and Raschke, Marian and Riefke, Bj{\"{o}}rn and Schmitt, Christina S and Sieber, Max and Sposny, Alexandra and Suter, Laura and Sweatman, Brian and Mally, Angela},
doi = {https://doi.org/10.1016/j.taap.2010.09.022},
issn = {0041-008X},
journal = {Toxicol. Appl. Pharmacol.},
keywords = {Drug-induced hepatotoxicity,Liver,Metabonomics,Preclinical safety assessment,Toxicogenomics},
number = {2},
pages = {97--111},
title = {{The enhanced value of combining conventional and “omics” analyses in early assessment of drug-induced hepatobiliary injury}},
url = {http://www.sciencedirect.com/science/article/pii/S0041008X10003649},
volume = {252},
year = {2011}
}
@article{Canault2017,
abstract = {In the last decade, many statistical-based approaches have been developed to improve poor pharmacokinetics (PK) and to reduce toxicity of lead compounds, which are one of the main causes of high failure rate in drug development. Predictive QSAR models are not always very efficient due to the low number of available biological data and the differences in the experimental protocols. Fortunately, the number of available databases continues to grow every year. However, it remains a challenge to determine the source and the quality of the original data. The main goal is to identify the relevant databases required to generate the most robust predictive models. In this study, an interactive network of databases was proposed to easily find online data sources related to ADME-Tox parameters data. In this map, relevant information regarding scope of application, data availability and data redundancy can be obtained for each data source. To illustrate the usage of data mining from the network, a dataset on plasma protein binding is selected based on various sources such as DrugBank, PubChem and ChEMBL databases. A total of 2,606 unique molecules with experimental values of PPB were extracted and can constitute a consistent dataset for QSAR modeling.},
author = {Canault, Baptiste and Bourg, St{\'{e}}phane and Vayer, Philippe and Bonnet, Pascal},
doi = {10.1002/minf.201700029},
issn = {18681751},
journal = {Mol. Inform.},
keywords = {ADME-Tox,Database,Network,PPB},
month = {oct},
number = {10},
pages = {1700029},
publisher = {Wiley-VCH Verlag},
title = {{Comprehensive Network Map of ADME-Tox Databases}},
url = {http://doi.wiley.com/10.1002/minf.201700029},
volume = {36},
year = {2017}
}
@article{Dhawan2019,
abstract = {With the increased use of next-generation sequencing generating large amounts of  genomic data, gene expression signatures are becoming critically important tools for the interpretation of these data, and are poised to have a substantial effect on diagnosis, management, and prognosis for a number of diseases. It is becoming crucial to establish whether the expression patterns and statistical properties of sets of genes, or gene signatures, are conserved across independent datasets. Conversely, it is necessary to compare established signatures on the same dataset to better understand how they capture different clinical or biological characteristics. Here we describe how to use sigQC, a tool that enables a streamlined, systematic approach for the evaluation of previously obtained gene signatures across multiple gene expression datasets. We implemented sigQC in an R package, making it accessible to users who have knowledge of file input/output and matrix manipulation in R and a moderate grasp of core statistical principles. SigQC has been adopted in basic biology and translational studies, including, but not limited to, the evaluation of multiple gene signatures for potential clinical use as cancer biomarkers. This protocol uses a previously obtained signature for breast cancer metastasis as an example to illustrate the critical quality control steps involved in evaluating its expression, variability, and structure in breast tumor RNA-sequencing data, a different dataset from that in which the signature was originally derived. We demonstrate how the outputs created from sigQC can be used for the evaluation of gene signatures on large-scale gene expression datasets.},
author = {Dhawan, Andrew and Barberis, Alessandro and Cheng, Wei-Chen and Domingo, Enric and West, Catharine and Maughan, Tim and Scott, Jacob G and Harris, Adrian L and Buffa, Francesca M},
doi = {10.1038/s41596-019-0136-8},
issn = {1750-2799 (Electronic)},
journal = {Nat. Protoc.},
keywords = {Biomarkers, Tumor,Databases, Genetic,Gene Expression Profiling,Genomics,High-Throughput Nucleotide Sequencing,Humans,Sequence Analysis, DNA,Software,genetics,methods},
language = {eng},
month = {may},
number = {5},
pages = {1377--1400},
pmid = {30971781},
title = {{Guidelines for using sigQC for systematic evaluation of gene signatures.}},
volume = {14},
year = {2019}
}
@article{Kuleshov2016,
abstract = {Enrichment analysis is a popular method for analyzing gene sets generated by genome-wide experiments. Here we present a significant update to one of the tools in this domain called Enrichr. Enrichr currently contains a large collection of diverse gene set libraries available for analysis and download. In total, Enrichr currently contains 180 184 annotated gene sets from 102 gene set libraries. New features have been added to Enrichr including the ability to submit fuzzy sets, upload BED files, improved application programming interface and visualization of the results as clustergrams. Overall, Enrichr is a comprehensive resource for curated gene sets and a search engine that accumulates biological knowledge for further biological discoveries. Enrichr is freely available at: http://amp.pharm.mssm.edu/Enrichr.},
author = {Kuleshov, Maxim V and Jones, Matthew R and Rouillard, Andrew D and Fernandez, Nicolas F and Duan, Qiaonan and Wang, Zichen and Koplev, Simon and Jenkins, Sherry L and Jagodnik, Kathleen M and Lachmann, Alexander and McDermott, Michael G and Monteiro, Caroline D and Gundersen, Gregory W and Ma'ayan, Avi},
doi = {10.1093/nar/gkw377},
issn = {0305-1048},
journal = {Nucleic Acids Res.},
month = {may},
number = {W1},
pages = {W90--W97},
title = {{Enrichr: a comprehensive gene set enrichment analysis web server 2016 update}},
url = {https://doi.org/10.1093/nar/gkw377},
volume = {44},
year = {2016}
}
@article{ballester_machine_2010,
abstract = {Motivation: Accurately predicting the binding affinities of large sets of diverse protein-ligand complexes is an extremely challenging task. The scoring functions that attempt such computational prediction are essential for analysing the outputs of molecular docking, which in turn is an important technique for drug discovery, chemical biology and structural biology. Each scoring function assumes a predetermined theory-inspired functional form for the relationship between the variables that characterize the complex, which also include parameters fitted to experimental or simulation data and its predicted binding affinity. The inherent problem of this rigid approach is that it leads to poor predictivity for those complexes that do not conform to the modelling assumptions. Moreover, resampling strategies, such as cross-validation or bootstrapping, are still not systematically used to guard against the overfitting of calibration data in parameter estimation for scoring functions. Results: We propose a novel scoring function (RF-Score) that circumvents the need for problematic modelling assumptions via non-parametric machine learning. In particular, Random Forest was used to implicitly capture binding effects that are hard to model explicitly. RF-Score is compared with the state of the art on the demanding PDBbind benchmark. Results show that RF-Score is a very competitive scoring function. Importantly, RF-Score's performance was shown to improve dramatically with training set size and hence the future availability of more high-quality structural and interaction data is expected to lead to improved versions of RF-Score. Contact: pedro.ballester@ebi.ac.uk; jbom@st-andrews.ac.uk. Supplementary information: Supplementary data are available at Bioinformatics online. {\textcopyright} The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org.},
author = {Ballester, Pedro J. and Mitchell, John B.O.},
doi = {10.1093/bioinformatics/btq112},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ballester, Mitchell - 2010 - A machine learning approach to predicting protein-ligand binding affinity with applications to molecular do.pdf:pdf},
issn = {13674803},
journal = {Bioinformatics},
number = {9},
pages = {1169--1175},
pmid = {20236947},
title = {{A machine learning approach to predicting protein-ligand binding affinity with applications to molecular docking}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3524828/},
volume = {26},
year = {2010}
}
@article{Bordbar2014d,
author = {Bordbar, Aarash and Monk, Jonathan and King, Zachary and Palsson, Bernhard},
doi = {10.1038/nrg3643},
journal = {Nat. Rev. Genet.},
month = {feb},
pages = {107--120},
title = {{Constraint-based models predict metabolic and associated cellular functions}},
volume = {15},
year = {2014}
}
@article{baell_new_2010,
abstract = {This report describes a number of substructural features which can help to identify compounds that appear as frequent hitters (promiscuous compounds) in many biochemical high throughput screens. The compounds identified by such substructural features are not recognized by filters commonly used to identify reactive compounds. Even though these substructural features were identified using only one assay detection technology, such compounds have been reported to be active from many different assays. In fact, these compounds are increasingly prevalent in the literature as potential starting points for further exploration, whereas they may not be. {\textcopyright} 2010 American Chemical Society.},
author = {Baell, Jonathan B. and Holloway, Georgina A.},
doi = {10.1021/jm901137j},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Baell, Holloway - 2010 - New substructure filters for removal of pan assay interference compounds (PAINS) from screening libraries and f.pdf:pdf},
issn = {00222623},
journal = {J. Med. Chem.},
number = {7},
pages = {2719--2740},
pmid = {20131845},
title = {{New substructure filters for removal of pan assay interference compounds (PAINS) from screening libraries and for their exclusion in bioassays}},
url = {https://pubs.acs.org/doi/10.1021/jm901137j},
volume = {53},
year = {2010}
}
@article{Fundel2008d,
abstract = {INTRODUCTION: Numerous methods exist for basic processing, e.g. normalization, of  microarray gene expression data. These methods have an important effect on the final analysis outcome. Therefore, it is crucial to select methods appropriate for a given dataset in order to assure the validity and reliability of expression data analysis. Furthermore, biological interpretation requires expression values for genes, which are often represented by several spots or probe sets on a microarray. How to best integrate spot/probe set values into gene values has so far been a somewhat neglected problem. RESULTS: We present a case study comparing different between-array normalization methods with respect to the identification of differentially expressed genes. Our results show that it is feasible and necessary to use prior knowledge on gene expression measurements to select an adequate normalization method for the given data. Furthermore, we provide evidence that combining spot/probe set p-values into gene p-values for detecting differentially expressed genes has advantages compared to combining expression values for spots/probe sets into gene expression values. The comparison of different methods suggests to use Stouffer's method for this purpose. The study has been conducted on gene expression experiments investigating human joint cartilage samples of osteoarthritis related groups: a cDNA microarray (83 samples, four groups) and an Affymetrix (26 samples, two groups) data set. CONCLUSION: The apparently straight forward steps of gene expression data analysis, e.g. between-array normalization and detection of differentially regulated genes, can be accomplished by numerous different methods. We analyzed multiple methods and the possible effects and thereby demonstrate the importance of the single decisions taken during data processing. We give guidelines for evaluating normalization outcomes. An overview of these effects via appropriate measures and plots compared to prior knowledge is essential for the biological interpretation of gene expression measurements.},
author = {Fundel, Katrin and K{\"{u}}ffner, Robert and Aigner, Thomas and Zimmer, Ralf},
doi = {10.4137/bbi.s441},
issn = {1177-9322 (Electronic)},
journal = {Bioinform. Biol. Insights},
language = {eng},
month = {may},
pages = {291--305},
pmid = {19812783},
title = {{Normalization and gene p-value estimation: issues in microarray data processing.}},
volume = {2},
year = {2008}
}
@article{Mysinger2012,
abstract = {A key metric to assess molecular docking remains ligand enrichment against challenging decoys. Whereas the directory of useful decoys (DUD) has been widely used, clear areas for optimization have emerged. Here we describe an improved benchmarking set that includes more diverse targets such as GPCRs and ion channels, totaling 102 proteins with 22886 clustered ligands drawn from ChEMBL, each with 50 property-matched decoys drawn from ZINC. To ensure chemotype diversity, we cluster each target's ligands by their Bemis-Murcko atomic frameworks. We add net charge to the matched physicochemical properties and include only the most dissimilar decoys, by topology, from the ligands. An online automated tool (http://decoys.docking.org) generates these improved matched decoys for user-supplied ligands. We test this data set by docking all 102 targets, using the results to improve the balance between ligand desolvation and electrostatics in DOCK 3.6. The complete DUD-E benchmarking set is freely available at http://dude.docking.org. {\textcopyright} 2012 American Chemical Society.},
author = {Mysinger, Michael M. and Carchia, Michael and Irwin, John J. and Shoichet, Brian K.},
doi = {10.1021/jm300687e},
isbn = {0022-2623},
issn = {00222623},
journal = {J. Med. Chem.},
month = {jul},
number = {14},
pages = {6582--6594},
shorttitle = {Directory of Useful Decoys, Enhanced (DUD-E)},
title = {{Directory of useful decoys, enhanced (DUD-E): Better ligands and decoys for better benchmarking}},
volume = {55},
year = {2012}
}
@article{Lim2010,
abstract = {In an effort to capture meaningful biological, chemical and mechanistic information about clinically relevant, commonly encountered or important toxins, we have developed the Toxin and Toxin-Target Database (T3DB). The T3DB is a unique bioinformatics resource that compiles comprehensive information about common or ubiquitous toxins and their toxin-targets into a single electronic repository. The database currently contains over 2900 small molecule and peptide toxins, 1300 toxin-targets and more than 33,000 toxin-target associations. Each T3DB record (ToxCard) contains over 80 data fields providing detailed information on chemical properties and descriptors, toxicity values, protein and gene sequences (for both targets and toxins), molecular and cellular interaction data, toxicological data, mechanistic information and references. This information has been manually extracted and manually verified from numerous sources, including other electronic databases, government documents, textbooks and scientific journals. A key focus of the T3DB is on providing 'depth' over 'breadth' with detailed descriptions, mechanisms of action, and information on toxins and toxin-targets. T3DB is fully searchable and supports extensive text, sequence, chemical structure and relational query searches, similar to those found in the Human Metabolome Database (HMDB) and DrugBank. Potential applications of the T3DB include clinical metabolomics, toxin target prediction, toxicity prediction and toxicology education. The T3DB is available online at http://www.t3db.org.},
author = {Lim, Emilia and Pon, Allison and Djoumbou, Yannick and Knox, Craig and Shrivastava, Savita and Guo, An Chi and Neveu, Vanessa and Wishart, David S},
doi = {10.1093/nar/gkp934},
edition = {2009/11/06},
issn = {1362-4962},
journal = {Nucleic Acids Res.},
keywords = {*Databases, Factual,*Databases, Protein,Computational Biology/*methods/trends,Drug Design,Drug-Related Side Effects and Adverse Reactions,Humans,Information Storage and Retrieval/methods,Internet,Pharmaceutical Preparations/*chemistry,Pharmacology/methods,Quality Control,Reproducibility of Results,Software,Toxins, Biological/*chemistry},
language = {eng},
month = {jan},
number = {Database issue},
pages = {D781--D786},
publisher = {Oxford University Press},
title = {{T3DB: a comprehensively annotated database of common toxins and their targets}},
url = {https://pubmed.ncbi.nlm.nih.gov/19897546 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2808899/},
volume = {38},
year = {2010}
}
@article{jaghoori_1001_2016,
abstract = {Large-scale computing technologies have enabled high-throughput virtual screening involving thousands to millions of drug candidates. It is not trivial, however, for biochemical scientists to evaluate the technical alternatives and their implications for running such large experiments. Besides experience with the molecular docking tool itself, the scientist needs to learn how to run it on high-performance computing (HPC) infrastructures, and understand the impact of the choices made. Here, we review such considerations for a specific tool, AutoDock Vina, and use experimental data to illustrate the following points: (1) an additional level of parallelization increases virtual screening throughput on a multi-core machine; (2) capturing of the random seed is not enough (though necessary) for reproducibility on heterogeneous distributed computing systems; (3) the overall time spent on the screening of a ligand library can be improved by analysis of factors affecting execution time per ligand, including number of active torsions, heavy atoms and exhaustiveness. We also illustrate differences among four common HPC infrastructures: grid, Hadoop, small cluster and multi-core (virtual machine on the cloud). Our analysis shows that these platforms are suitable for screening experiments of different sizes. These considerations can guide scientists when choosing the best computing platform and set-up for their future large virtual screening experiments.},
author = {Jaghoori, Mohammad Mahdi and Bleijlevens, Boris and Olabarriaga, Silvia D.},
doi = {10.1007/s10822-016-9900-9},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaghoori, Bleijlevens, Olabarriaga - 2016 - 1001 Ways to run AutoDock Vina for virtual screening.pdf:pdf},
issn = {15734951},
journal = {J. Comput. Aided. Mol. Des.},
keywords = {AutoDock Vina,Grid computing,Hadoop,High-performance computing,Multi-core,Reproducibility,Virtual screening},
number = {3},
pages = {237--249},
title = {{1001 Ways to run AutoDock Vina for virtual screening}},
url = {https://doi.org/10.1007/s10822-016-9900-9},
volume = {30},
year = {2016}
}
@article{Chaput2016,
abstract = {Background: In a structure-based virtual screening, the choice of the docking program is essential for the success of a hit identification. Benchmarks are meant to help in guiding this choice, especially when undertaken on a large variety of protein targets. Here, the performance of four popular virtual screening programs, Gold, Glide, Surflex and FlexX, is compared using the Directory of Useful Decoys-Enhanced database (DUD-E), which includes 102 targets with an average of 224 ligands per target and 50 decoys per ligand, generated to avoid biases in the benchmarking. Then, a relationship between these program performances and the properties of the targets or the small molecules was investigated. Results: The comparison was based on two metrics, with three different parameters each. The BEDROC scores with $\alpha$ = 80.5, indicated that, on the overall database, Glide succeeded (score {\textgreater} 0.5) for 30 targets, Gold for 27, FlexX for 14 and Surflex for 11. The performance did not depend on the hydrophobicity nor the openness of the protein cavities, neither on the families to which the proteins belong. However, despite the care in the construction of the DUD-E database, the small differences that remain between the actives and the decoys likely explain the successes of Gold, Surflex and FlexX. Moreover, the similarity between the actives of a target and its crystal structure ligand seems to be at the basis of the good performance of Glide. When all targets with significant biases are removed from the benchmarking, a subset of 47 targets remains, for which Glide succeeded for only 5 targets, Gold for 4 and FlexX and Surflex for 2. Conclusion: The performance dramatic drop of all four programs when the biases are removed shows that we should beware of virtual screening benchmarks, because good performances may be due to wrong reasons. Therefore, benchmarking would hardly provide guidelines for virtual screening experiments, despite the tendency that is maintained, i.e., Glide and Gold display better performance than FlexX and Surflex. We recommend to always use several programs and combine their results. Graphical Abstract Summary of the results obtained by virtual screening with the four programs, Glide, Gold, Surflex and FlexX, on the 102 targets of the DUD-E database. The percentage of targets with successful results, i.e., with BDEROC($\alpha$ = 80.5) {\textgreater} 0.5, when the entire database is considered are in Blue, and when targets with biased chemical libraries are removed are in Red.},
author = {Chaput, Ludovic and Martinez-Sanz, Juan and Saettel, Nicolas and Mouawad, Liliane},
doi = {10.1186/s13321-016-0167-x},
issn = {17582946},
journal = {J. Cheminform.},
keywords = {BEDROC,Benchmark,DUD-E,Docking,FlexX,Glide,Gold,Structure-based virtual screening,Surflex},
month = {dec},
number = {1},
pages = {1--17},
publisher = {BioMed Central},
title = {{Benchmark of four popular virtual screening programs: construction of the active/decoy dataset remains a major determinant of measured performance}},
volume = {8},
year = {2016}
}
@article{wojcikowski_performance_2017,
abstract = {Classical scoring functions have reached a plateau in their performance in virtual screening and binding affinity prediction. Recently, machine-learning scoring functions trained on protein-ligand complexes have shown great promise in small tailored studies. They have also raised controversy, specifically concerning model overfitting and applicability to novel targets. Here we provide a new ready-to-use scoring function (RF-Score-VS) trained on 15 426 active and 893 897 inactive molecules docked to a set of 102 targets. We use the full DUD-E data sets along with three docking tools, five classical and three machine-learning scoring functions for model building and performance assessment. Our results show RF-Score-VS can substantially improve virtual screening performance: RF-Score-VS top 1{\%} provides 55.6{\%} hit rate, whereas that of Vina only 16.2{\%} (for smaller percent the difference is even more encouraging: RF-Score-VS top 0.1{\%} achieves 88.6{\%} hit rate for 27.5{\%} using Vina). In addition, RFScore- VS provides much better prediction of measured binding affinity than Vina (Pearson correlation of 0.56 and -0.18, respectively). Lastly, we test RF-Score-VS on an independent test set from the DEKOIS benchmark and observed comparable results. We provide full data sets to facilitate further research in this area (http://github.com/oddt/rfscorevs) as well as ready-to-use RF-Score-VS (http://github.com/oddt/rfscorevs-binary).},
author = {W{\'{o}}jcikowski, Maciej and Ballester, Pedro J. and Siedlecki, Pawel},
doi = {10.1038/srep46710},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/W{\'{o}}jcikowski, Ballester, Siedlecki - 2017 - Performance of machine-learning scoring functions in structure-based virtual screening.pdf:pdf;:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/W{\'{o}}jcikowski, Ballester, Siedlecki - 2017 - Performance of machine-learning scoring functions in structure-based virtual screening.html:html},
issn = {20452322},
journal = {Sci. Rep.},
pages = {46710},
title = {{Performance of machine-learning scoring functions in structure-based virtual screening}},
url = {https://www.nature.com/articles/srep46710},
volume = {7},
year = {2017}
}
@misc{Lee2020,
abstract = {Advances in next-generation sequencing and high-throughput techniques have enabled the generation of vast amounts of diverse omics data. These big data provide an unprecedented opportunity in biology, but impose great challenges in data integration, data mining, and knowledge discovery due to the complexity, heterogeneity, dynamics, uncertainty, and high-dimensionality inherited in the omics data. Network has been widely used to represent relations between entities in biological system, such as protein-protein interaction, gene regulation, and brain connectivity (i.e. network construction) as well as to infer novel relations given a reconstructed network (aka link prediction). Particularly, heterogeneous multi-layered network (HMLN) has proven successful in integrating diverse biological data for the representation of the hierarchy of biological system. The HMLN provides unparalleled opportunities but imposes new computational challenges on establishing causal genotype-phenotype associations and understanding environmental impact on organisms. In this review, we focus on the recent advances in developing novel computational methods for the inference of novel biological relations from the HMLN. We first discuss the properties of biological HMLN. Then we survey four categories of state-of-the-art methods (matrix factorization, random walk, knowledge graph, and deep learning). Thirdly, we demonstrate their applications to omics data integration and analysis. Finally, we outline strategies for future directions in the development of new HMLN models.},
author = {Lee, Bohyun and Zhang, Shuo and Poleksic, Aleksandar and Xie, Lei},
booktitle = {Front. Genet.  },
isbn = {1664-8021},
pages = {1381},
title = {{Heterogeneous Multi-Layered Network Model for Omics Data Integration and Analysis   }},
url = {https://www.frontiersin.org/article/10.3389/fgene.2019.01381},
volume = {10      },
year = {2020}
}
@misc{Sharma2017,
abstract = {The experimental methods for the prediction of molecular toxicity are tedious and time-consuming tasks. Thus, the computational approaches could be used to develop alternative methods for toxicity prediction. We have developed a tool for the prediction of molecular toxicity along with the aqueous solubility and permeability of any molecule/metabolite. Using a comprehensive and curated set of toxin molecules as a training set, the different chemical and structural based features such as descriptors and fingerprints were exploited for feature selection, optimization and development of machine learning based classification and regression models. The compositional differences in the distribution of atoms were apparent between toxins and non-toxins, and hence, the molecular features were used for the classification and regression. On 10-fold cross-validation, the descriptor-based, fingerprint-based and hybrid-based classification models showed similar accuracy (93{\%}) and Matthews's correlation coefficient (0.84). The performances of all the three models were comparable (Matthews's correlation coefficient = 0.84–0.87) on the blind dataset. In addition, the regression-based models using descriptors as input features were also compared and evaluated on the blind dataset. Random forest based regression model for the prediction of solubility performed better (R{\textless}sup{\textgreater}2{\textless}/sup{\textgreater} = 0.84) than the multi-linear regression (MLR) and partial least square regression (PLSR) models, whereas, the partial least squares based regression model for the prediction of permeability (caco-2) performed better (R{\textless}sup{\textgreater}2{\textless}/sup{\textgreater} = 0.68) in comparison to the random forest and MLR based regression models. The performance of final classification and regression models was evaluated using the two validation datasets including the known toxins and commonly used constituents of health products, which attests to its accuracy. The ToxiM web server would be a highly useful and reliable tool for the prediction of toxicity, solubility, and permeability of small molecules.},
author = {Sharma, Ashok K and Srivastava, Gopal N and Roy, Ankita and Sharma, Vineet K},
booktitle = {Front. Pharmacol.  },
isbn = {1663-9812},
pages = {880},
title = {{ToxiM: A Toxicity Prediction Tool for Small Molecules Developed Using Machine Learning and Chemoinformatics Approaches   }},
url = {https://www.frontiersin.org/article/10.3389/fphar.2017.00880},
volume = {8      },
year = {2017}
}
@article{Subramanian2017,
abstract = {We previously piloted the concept of a Connectivity Map (CMap), whereby genes, drugs, and disease states are connected by virtue of common gene-expression signatures. Here, we report more than a 1,000-fold scale-up of the CMap as part of the NIH LINCS Consortium, made possible by a new, low-cost, high-throughput reduced representation expression profiling method that we term L1000. We show that L1000 is highly reproducible, comparable to RNA sequencing, and suitable for computational inference of the expression levels of 81{\%} of non-measured transcripts. We further show that the expanded CMap can be used to discover mechanism of action of small molecules, functionally annotate genetic variants of disease genes, and inform clinical trials. The 1.3 million L1000 profiles described here, as well as tools for their analysis, are available at https://clue.io. The next generation Connectivity Map, a large-scale compendium of functional perturbations in cultured human cells coupled to a gene-expression readout, facilitates the discovery of connections between genes, drugs, and diseases.},
author = {Subramanian, Aravind and Narayan, Rajiv and Corsello, Steven M. and Peck, David D. and Natoli, Ted E. and Lu, Xiaodong and Gould, Joshua and Davis, John F. and Tubelli, Andrew A. and Asiedu, Jacob K. and Lahr, David L. and Hirschman, Jodi E. and Liu, Zihan and Donahue, Melanie and Julian, Bina and Khan, Mariya and Wadden, David and Smith, Ian C. and Lam, Daniel and Liberzon, Arthur and Toder, Courtney and Bagul, Mukta and Orzechowski, Marek and Enache, Oana M. and Piccioni, Federica and Johnson, Sarah A. and Lyons, Nicholas J. and Berger, Alice H. and Shamji, Alykhan F. and Brooks, Angela N. and Vrcic, Anita and Flynn, Corey and Rosains, Jacqueline and Takeda, David Y. and Hu, Roger and Davison, Desiree and Lamb, Justin and Ardlie, Kristin and Hogstrom, Larson and Greenside, Peyton and Gray, Nathanael S. and Clemons, Paul A. and Silver, Serena and Wu, Xiaoyun and Zhao, Wen Ning and Read-Button, Willis and Wu, Xiaohua and Haggarty, Stephen J. and Ronco, Lucienne V. and Boehm, Jesse S. and Schreiber, Stuart L. and Doench, John G. and Bittker, Joshua A. and Root, David E. and Wong, Bang and Golub, Todd R.},
doi = {10.1016/j.cell.2017.10.049},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Subramanian et al. - 2017 - A Next Generation Connectivity Map L1000 Platform and the First 1,000,000 Profiles.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {Functional genomics,chemical biology,gene expression profiling},
month = {nov},
number = {6},
pages = {1437--1452.e17},
pmid = {29195078},
publisher = {Cell Press},
title = {{A Next Generation Connectivity Map: L1000 Platform and the First 1,000,000 Profiles}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867417313090},
volume = {171},
year = {2017}
}
@article{Yang2019g,
abstract = {The widespread applications in microarray technology have produced the vast quantity  of publicly available gene expression datasets. However, analysis of gene expression data using biostatistics and machine learning approaches is a challenging task due to (1) high noise; (2) small sample size with high dimensionality; (3) batch effects and (4) low reproducibility of significant biomarkers. These issues reveal the complexity of gene expression data, thus significantly obstructing microarray technology in clinical applications. The integrative analysis offers an opportunity to address these issues and provides a more comprehensive understanding of the biological systems, but current methods have several limitations. This work leverages state of the art machine learning development for multiple gene expression datasets integration, classification and identification of significant biomarkers. We design a novel integrative framework, MVIAm - Multi-View based Integrative Analysis of microarray data for identifying biomarkers. It applies multiple cross-platform normalization methods to aggregate multiple datasets into a multi-view dataset and utilizes a robust learning mechanism Multi-View Self-Paced Learning (MVSPL) for gene selection in cancer classification problems. We demonstrate the capabilities of MVIAm using simulated data and studies of breast cancer and lung cancer, it can be applied flexibly and is an effective tool for facing the four challenges of gene expression data analysis. Our proposed model makes microarray integrative analysis more systematic and expands its range of applications.},
author = {Yang, Zi-Yi and Liu, Xiao-Ying and Shu, Jun and Zhang, Hui and Ren, Yan-Qiong and Xu, Zong-Ben and Liang, Yong},
doi = {10.1038/s41598-019-49967-4},
issn = {2045-2322 (Electronic)},
journal = {Sci. Rep.},
language = {eng},
month = {sep},
number = {1},
pages = {13504},
pmid = {31534156},
title = {{Multi-view based integrative analysis of gene expression data for identifying  biomarkers.}},
volume = {9},
year = {2019}
}
@article{Abrams2019,
abstract = {Background: RNA sequencing technologies have allowed researchers to gain a better understanding of how the transcriptome affects disease. However, sequencing technologies often unintentionally introduce experimental error into RNA sequencing data. To counteract this, normalization methods are standardly applied with the intent of reducing the non-biologically derived variability inherent in transcriptomic measurements. However, the comparative efficacy of the various normalization techniques has not been tested in a standardized manner. Here we propose tests that evaluate numerous normalization techniques and applied them to a large-scale standard data set. These tests comprise a protocol that allows researchers to measure the amount of non-biological variability which is present in any data set after normalization has been performed, a crucial step to assessing the biological validity of data following normalization. Results: In this study we present two tests to assess the validity of normalization methods applied to a large-scale data set collected for systematic evaluation purposes. We tested various RNASeq normalization procedures and concluded that transcripts per million (TPM) was the best performing normalization method based on its preservation of biological signal as compared to the other methods tested. Conclusion: Normalization is of vital importance to accurately interpret the results of genomic and transcriptomic experiments. More work, however, needs to be performed to optimize normalization methods for RNASeq data. The present effort helps pave the way for more systematic evaluations of normalization methods across different platforms. With our proposed schema researchers can evaluate their own or future normalization methods to further improve the field of RNASeq normalization.},
author = {Abrams, Zachary B. and Johnson, Travis S. and Huang, Kun and Payne, Philip R.O. and Coombes, Kevin},
doi = {10.1186/s12859-019-3247-x},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abrams et al. - 2019 - A protocol to evaluate RNA sequencing normalization methods.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Biological variability,Normalization,RNASeq,Standardization},
month = {dec},
number = {S24},
pages = {679},
publisher = {BioMed Central Ltd.},
title = {{A protocol to evaluate RNA sequencing normalization methods}},
url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-3247-x},
volume = {20},
year = {2019}
}
@article{Hebenstreit2011,
abstract = {The expression level of a gene is often used as a proxy for determining whether the protein or RNA product is functional in a cell or tissue. Therefore, it is of fundamental importance to understand the global distribution of gene expression levels, and to be able to interpret it mechanistically and functionally. Here we use RNA sequencing (RNA-seq) of mouse Th2 cells, coupled with a range of other techniques, to show that all genes can be separated, based on their expression abundance, into two distinct groups: one group comprised of lowly expressed and putatively non-functional mRNAs, and the other of highly expressed mRNAs with active chromatin marks at their promoters. These observations are confirmed in many other microarray and RNA-seq data sets of metazoan cell types.},
author = {Hebenstreit, Daniel and Fang, Miaoqing and Gu, Muxin and Charoensawan, Varodom and van Oudenaarden, Alexander and Teichmann, Sarah A},
doi = {10.1038/msb.2011.28},
issn = {1744-4292},
journal = {Mol. Syst. Biol.},
keywords = {*Gene Expression Regulation,Animals,Cells, Cultured,Computational Biology,Gene Expression Profiling/*methods,In Situ Hybridization, Fluorescence,Mice,Mice, Inbred C57BL,Microarray Analysis,RNA, Messenger/genetics,Sequence Analysis, RNA/*methods,Th2 Cells},
language = {eng},
month = {jun},
pages = {497},
publisher = {Nature Publishing Group},
title = {{RNA sequencing reveals two major classes of gene expression levels in metazoan cells}},
url = {https://pubmed.ncbi.nlm.nih.gov/21654674 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3159973/},
volume = {7},
year = {2011}
}
@article{Fresnais2020,
abstract = {Larger training datasets have been shown to improve the accuracy of machine learning (ML)-based scoring functions (SFs) for structure-based virtual screening (SBVS). In addition, massive test sets for SBVS, known as ultra-large compound libraries, have been demonstrated to enable the fast discovery of selective drug leads with low-nanomolar potency. This proof-of-concept was carried out on two targets using a single docking tool along with its SF. It is thus unclear whether this high level of performance would generalise to other targets, docking tools and SFs. We found that screening a larger compound library results in more potent actives being identified in all six additional targets using a different docking tool along with its classical SF. Furthermore, we established that a way to improve the potency of the retrieved molecules further is to rank them with more accurate ML-based SFs (we found this to be true in four of the six targets; the difference was not significant in the remaining two targets). A 3-fold increase in average hit rate across targets was also achieved by the ML-based SFs. Lastly, we observed that classical and ML-based SFs often find different actives, which supports using both types of SFs on those targets.},
author = {Fresnais, Louison and Ballester, Pedro J},
doi = {10.1093/bib/bbaa095},
issn = {1467-5463},
journal = {Brief. Bioinform.},
keywords = {RF-Score-VS,SBVS,database size impact,machine learning,virtual{\_}screening},
mendeley-tags = {RF-Score-VS,SBVS,database size impact,machine learning,virtual{\_}screening},
month = {jun},
title = {{The impact of compound library size on the performance of scoring functions for structure-based virtual screening}},
url = {https://doi.org/10.1093/bib/bbaa095},
year = {2020}
}
@article{Dumont2015,
abstract = {Abstract The exposure of the skin to consumer products, drugs, and environmental chemicals can result in their penetrating the skin barrier and entering systemic circulation, potentially resulting in adverse effects in the skin and other organs. The assessment of dermal penetration and bioavailability (including penetration, metabolism, and entry into the systemic circulation) is therefore an important consideration in the risk assessment of chemicals. The skin is a heterogeneous organ with a multilayer structure. Based on its architecture and physiology, substances can penetrate through three major ways but can also be blocked in the different skin layers and in the skin appendages, which act as reservoir. In addition to that, as the skin is a metabolically competent organ, substances can undergo metabolism. After a brief description of the skin architecture, this review will focus on the skin penetration mechanisms and skin metabolic capacities. The skin absorption has traditionally been tested in vivo on animals. However, with the new legislation (i.e., Registration, Evaluation, Authorisation, and Restriction of Chemicals Regulation or Cosmetics Regulation), alternatives to animal testing have to be implemented. In a second part, this review will provide a description of the main in vitro and in silico or computational models available to study skin absorption and skin metabolism (i.e., ex vivo skin models, artificial membrane barriers, primary cells and cell lines, Quantitative Structure?Activity Relationship [QSAR], simulators for the prediction of skin metabolism).},
annote = {doi: 10.1089/aivt.2015.0003},
author = {Dumont, Coralie and Prieto, Pilar and Asturiol, David and Worth, Andrew},
doi = {10.1089/aivt.2015.0003},
issn = {2332-1512},
journal = {Appl. Vitr. Toxicol.},
month = {jun},
number = {2},
pages = {147--164},
publisher = {Mary Ann Liebert, Inc., publishers},
title = {{Review of the Availability of In Vitro and In Silico Methods for Assessing Dermal Bioavailability}},
url = {https://doi.org/10.1089/aivt.2015.0003},
volume = {1},
year = {2015}
}
@article{Lacroix2018,
abstract = {Polyphenol-rich foods are part of many nutritional interventions aimed at improving health and preventing cardiometabolic diseases (CMDs). Polyphenols have oxidative, inflammatory, and/or metabolic effects. Research into the chemistry and biology of polyphenol bioactives is prolific but knowledge of their molecular interactions with proteins is limited. We mined public data to (i) identify proteins that interact with or metabolize polyphenols, (ii) mapped these proteins to pathways and networks, and (iii) annotated functions enriched within the resulting polyphenol-protein interactome. A total of 1,395 polyphenols and their metabolites were retrieved (using Phenol-Explorer and Dictionary of Natural Products) of which 369 polyphenols interacted with 5,699 unique proteins in 11,987 interactions as annotated in STITCH, Pathway Commons, and BindingDB. Pathway enrichment analysis using the KEGG repository identified a broad coverage of significant pathways of low specificity to particular polyphenol (sub)classes. When compared to drugs or micronutrients, polyphenols have pleiotropic effects across many biological processes related to metabolism and CMDs. These systems-wide effects were also found in the protein interactome of the polyphenol-rich citrus fruits, used as a case study. In sum, these findings provide a knowledgebase for identifying polyphenol classes (and polyphenol-rich foods) that individually or in combination influence metabolism.},
author = {Lacroix, S{\'{e}}bastien and {Klicic Badoux}, Jasna and Scott-Boyer, Marie-Pier and Parolo, Silvia and Matone, Alice and Priami, Corrado and Morine, Melissa J and Kaput, Jim and Moco, Sofia},
doi = {10.1038/s41598-018-20625-5},
issn = {2045-2322},
journal = {Sci. Rep.},
number = {1},
pages = {2232},
title = {{A computationally driven analysis of the polyphenol-protein interactome}},
url = {https://doi.org/10.1038/s41598-018-20625-5},
volume = {8},
year = {2018}
}
@article{Poupin2019,
annote = {doi: 10.1021/acs.jproteome.8b00524},
author = {Poupin, Nathalie and Corlu, Anne and Cabaton, Nicolas J and Dubois-Pot-Schneider, H{\'{e}}l{\`{e}}ne and Canlet, C{\'{e}}cile and Person, Elodie and Bruel, Sandrine and Frainay, Cl{\'{e}}ment and Vinson, Florence and Maurier, Florence and Morel, Fabrice and Robin, Marie-Anne and Fromenty, Bernard and Zalko, Daniel and Jourdan, Fabien},
doi = {10.1021/acs.jproteome.8b00524},
issn = {1535-3893},
journal = {J. Proteome Res.},
month = {jan},
number = {1},
pages = {204--216},
publisher = {American Chemical Society},
title = {{Large-Scale Modeling Approach Reveals Functional Metabolic Shifts during Hepatic Differentiation}},
url = {https://doi.org/10.1021/acs.jproteome.8b00524},
volume = {18},
year = {2019}
}
@article{Musa2018,
abstract = {Large-scale perturbation databases, such as ConnectivityMap (CMap) or Library of Integrated Network-based Cellular Signatures (LINCS), provide enormous opportunities for computational pharmacogenomics and drug design. A reason for this is that in contrast to classical pharmacology focusing at one target at a time, the transcriptomics profiles provided by CMap and LINCS open the door for systems biology approaches on the pathway and network level. In this article, we provide a review of recent developments in computational pharmacogenomics with respect to CMap and LINCS and related applications.},
author = {Musa, Aliyu and Ghoraie, Laleh Soltan and Zhang, Shu Dong and Glazko, Galina and Yli-Harja, Olli and Dehmer, Matthias and Haibe-Kains, Benjamin and Emmert-Streib, Frank},
doi = {10.1093/bib/bbw112},
issn = {14774054},
journal = {Brief. Bioinform.},
keywords = {Big data,Bioinformatics,Drug discovery,Drug repositioning,Drug repurposing,Pharmacogenomics},
month = {may},
number = {3},
pages = {506--523},
pmid = {28069634},
publisher = {Oxford University Press},
title = {{A review of connectivity map and computational approaches in pharmacogenomics}},
url = {https://academic.oup.com/bib/article-lookup/doi/10.1093/bib/bbw112},
volume = {19},
year = {2018}
}
@article{Wang2004,
abstract = {We have screened the entire Protein Data Bank (Release No. 103, January 2003) and identified 5671 protein-ligand complexes out of 19 621 experimental structures. A systematic examination of the primary references of these entries has led to a collection of binding affinity data (Kd, Ki, and IC50) for a total of 1359 complexes. The outcomes of this project have been organized into a Web-accessible database named the PDBbind database.},
author = {Wang, Renxiao and Fang, Xueliang and Lu, Yipin and Wang, Shaomeng},
doi = {10.1021/jm030580l},
issn = {00222623},
journal = {J. Med. Chem.},
month = {jun},
number = {12},
pages = {2977--2980},
pmid = {15163179},
title = {{The PDBbind database: Collection of binding affinities for protein-ligand complexes with known three-dimensional structures}},
volume = {47},
year = {2004}
}
@article{Ramos2020d,
abstract = {OBJECTIVE: Data normalization and clustering are mandatory steps in gene expression  and downstream analyses, respectively. However, user-friendly implementations of these methodologies are available exclusively under expensive licensing agreements, or in stand-alone scripts developed, reflecting on a great obstacle for users with less computational skills. RESULTS: We developed an online tool called CORAZON (Correlations Analyses Zipper Online), which implements three unsupervised learning methods to cluster gene expression datasets in a friendly environment. It allows the usage of eight gene expression normalization/transformation methodologies and the attribute's influence. The normalizations requiring the gene length only could be performed to RNA-seq, meanwhile the others can be used with microarray and/or NanoString data. Clustering methodologies performances were evaluated through five models with accuracies between 92 and 100{\%}. We applied our tool to obtain functional insights of non-coding RNAs (ncRNAs) based on Gene Ontology enrichment of clusters in a dataset generated by the ENCODE project. The clusters where the majority of transcripts are coding genes were enriched in Cellular, Metabolic, Transports, and Systems Development categories. Meanwhile, the ncRNAs were enriched in the Detection of Stimulus, Sensory Perception, Immunological System, and Digestion categories. CORAZON source-code is freely available at https://gitlab.com/integrativebioinformatics/corazon and the web-server can be accessed at http://corazon.integrativebioinformatics.me .},
author = {Ramos, Tha{\'{i}}s A R and Maracaja-Coutinho, Vinicius and Ortega, J Miguel and do R{\^{e}}go, Tha{\'{i}}s G},
doi = {10.1186/s13104-020-05171-6},
issn = {1756-0500 (Electronic)},
journal = {BMC Res. Notes},
language = {eng},
month = {jul},
number = {1},
pages = {338},
pmid = {32665017},
title = {{CORAZON: a web server for data normalization and unsupervised clustering based on  expression profiles.}},
volume = {13},
year = {2020}
}
@article{Li2019,
abstract = {Studies have shown that the accuracy of random forest (RF)-based scoring functions (SFs), such as RF-Score-v3, increases with more training samples, whereas that of classical SFs, such as X-Score, does not. Nevertheless, the impact of the similarity between training and test samples on this matter has not been studied in a systematic manner. It is therefore unclear how these SFs would perform when only trained on protein-ligand complexes that are highly dissimilar or highly similar to the test set. It is also unclear whether SFs based on machine learning algorithms other than RF can also improve accuracy with increasing training set size and to what extent they learn from dissimilar or similar training complexes. Results: We present a systematic study to investigate how the accuracy of classical and machine-learning SFs varies with protein-ligand complex similarities between training and test sets. We considered three types of similarity metrics, based on the comparison of either protein structures, protein sequences or ligand structures. Regardless of the similarity metric, we found that incorporating a larger proportion of similar complexes to the training set did not make classical SFs more accurate. In contrast, RF-Score-v3 was able to outperform X-Score even when trained on just 32{\%} of the most dissimilar complexes, showing that its superior performance owes considerably to learning from dissimilar training complexes to those in the test set. In addition, we generated the first SF employing Extreme Gradient Boosting (XGBoost), XGB-Score, and observed that it also improves with training set size while outperforming the rest of SFs. Given the continuous growth of training datasets, the development of machine-learning SFs has become very appealing. Availability and implementation: https://github.com/HongjianLi/MLSF Supplementary information: Supplementary data are available at Bioinformatics online.},
author = {Li, Hongjian and Peng, Jiangjun and Sidorov, Pavel and Leung, Yee and Leung, Kwong Sak and Wong, Man Hon and Lu, Gang and Ballester, Pedro J. and Valencia, Alfonso},
doi = {10.1093/bioinformatics/btz183},
editor = {Valencia, Alfonso},
issn = {14602059},
journal = {Bioinformatics},
month = {mar},
number = {20},
pages = {3989--3995},
pmid = {30873528},
title = {{Classical scoring functions for docking are unable to exploit large volumes of structural and interaction data}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/30873528 https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btz183/5380764},
volume = {35},
year = {2019}
}
@article{Igarashi2015,
abstract = {Toxicogenomics focuses on assessing the safety of compounds using gene expression profiles. Gene expression signatures from large toxicogenomics databases are expected to perform better than small databases in identifying biomarkers for the prediction and evaluation of drug safety based on a compound's toxicological mechanisms in animal target organs. Over the past 10 years, the Japanese Toxicogenomics Project consortium (TGP) has been developing a large-scale toxicogenomics database consisting of data from 170 compounds (mostly drugs) with the aim of improving and enhancing drug safety assessment. Most of the data generated by the project (e.g. gene expression, pathology, lot number) are freely available to the public via Open TG-GATEs (Toxicogenomics Project-Genomics Assisted Toxicity Evaluation System). Here, we provide a comprehensive overview of the database, including both gene expression data and metadata, with a description of experimental conditions and procedures used to generate the database. Open TG-GATEs is available from http://toxico.nibio.go.jp/english/index.html.},
author = {Igarashi, Yoshinobu and Nakatsu, Noriyuki and Yamashita, Tomoya and Ono, Atsushi and Ohno, Yasuo and Urushidani, Tetsuro and Yamada, Hiroshi},
doi = {10.1093/nar/gku955},
edition = {2014/10/13},
issn = {1362-4962},
journal = {Nucleic Acids Res.},
keywords = {*Databases, Genetic,*Toxicogenetics,Animals,Biomarkers/metabolism,Genomics,Humans,Internet,Kidney/drug effects/metabolism/pathology,Liver/drug effects/metabolism/pathology,Male,Rats,Rats, Sprague-Dawley,Transcriptome/*drug effects},
language = {eng},
month = {jan},
number = {Database issue},
pages = {D921--D927},
publisher = {Oxford University Press},
title = {{Open TG-GATEs: a large-scale toxicogenomics database}},
url = {https://pubmed.ncbi.nlm.nih.gov/25313160 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4384023/},
volume = {43},
year = {2015}
}
@article{Vatakuti2016,
annote = {doi: 10.1021/acs.chemrestox.5b00491},
author = {Vatakuti, Suresh and Pennings, Jeroen L A and Gore, Emilia and Olinga, Peter and Groothuis, Geny M M},
doi = {10.1021/acs.chemrestox.5b00491},
issn = {0893-228X},
journal = {Chem. Res. Toxicol.},
month = {mar},
number = {3},
pages = {342--351},
publisher = {American Chemical Society},
title = {{Classification of Cholestatic and Necrotic Hepatotoxicants Using Transcriptomics on Human Precision-Cut Liver Slices}},
url = {https://doi.org/10.1021/acs.chemrestox.5b00491},
volume = {29},
year = {2016}
}
@article{bauer_evaluation_2013,
abstract = {The application of molecular benchmarking sets helps to assess the actual performance of virtual screening (VS) workflows. To improve the efficiency of structure-based VS approaches, the selection and optimization of various parameters can be guided by benchmarking. With the DEKOIS 2.0 library, we aim to further extend and complement the collection of publicly available decoy sets. Based on BindingDB bioactivity data, we provide 81 new and structurally diverse benchmark sets for a wide variety of different target classes. To ensure a meaningful selection of ligands, we address several issues that can be found in bioactivity data. We have improved our previously introduced DEKOIS methodology with enhanced physicochemical matching, now including the consideration of molecular charges, as well as a more sophisticated elimination of latent actives in the decoy set (LADS). We evaluate the docking performance of Glide, GOLD, and AutoDock Vina with our data sets and highlight existing challenges for VS tools. All DEKOIS 2.0 benchmark sets will be made accessible at http://www.dekois.com. {\textcopyright} 2013 American Chemical Society.},
author = {Bauer, Matthias R. and Ibrahim, Tamer M. and Vogel, Simon M. and Boeckler, Frank M.},
doi = {10.1021/ci400115b},
issn = {15499596},
journal = {J. Chem. Inf. Model.},
number = {6},
pages = {1447--1462},
title = {{Evaluation and optimization of virtual screening workflows with DEKOIS 2.0 - A public library of challenging docking benchmark sets}},
url = {http://pubs.acs.org/doi/10.1021/ci400115b},
volume = {53},
year = {2013}
}
@article{Musa2017,
abstract = {Large-scale perturbation databases, such as Connectivity Map (CMap) or Library of Integrated Network-based Cellular Signatures (LINCS), provide enormous opportunities for computational pharmacogenomics and drug design. A reason for this is that in contrast to classical pharmacology focusing at one target at a time, the transcriptomics profiles provided by CMap and LINCS open the door for systems biology approaches on the pathway and network level. In this article, we provide a review of recent developments in computational pharmacogenomics with respect to CMap and LINCS and related applications.},
author = {Musa, Aliyu and Ghoraie, Laleh Soltan and Zhang, Shu-Dong and Glazko, Galina and Yli-Harja, Olli and Dehmer, Matthias and Haibe-Kains, Benjamin and Emmert-Streib, Frank},
doi = {10.1093/bib/bbw112},
issn = {1477-4054},
journal = {Brief. Bioinform.},
month = {jan},
number = {3},
pages = {506--523},
title = {{A review of connectivity map and computational approaches in pharmacogenomics}},
url = {https://doi.org/10.1093/bib/bbw112},
volume = {19},
year = {2017}
}
@article{Ramaiahgari2017,
abstract = {Effective prediction of human responses to chemical and drug exposure is of critical importance in environmental toxicology research and drug development. While significant progress has been made to address this challenge using invitro liver models, these approaches often fail due to inadequate tissue model functionality. Herein, we describe the development, optimization, and characterization of a novel three-dimensional (3D) spheroid model using differentiated HepaRG cells that achieve and maintain physiologically relevant levels of xenobiotic metabolism (CYP1A2, CYP2B6, and CYP3A4/5). This invitro model maintains a stable phenotype over multiple weeks in both 96- and 384-well formats, supports highly reproducible tissue-like architectures and models pharmacologically- and environmentally important hepatic receptor pathways (ie AhR, CAR, and PXR) analogous to primary human hepatocyte cultures. HepaRG spheroid cultures use 50–100× fewer cells than conventional two dimensional cultures, and enable the identification of metabolically activated toxicants. Spheroid size, time in culture and culture media composition were important factors affecting basal levels of xenobiotic metabolism and liver enzyme inducibility with activators of hepatic receptors AhR, CAR and PXR. Repeated exposure studies showed higher sensitivity than traditional 2D cultures in identifying compounds that cause liver injury and metabolism-dependent toxicity. This platform combines the well-documented impact of 3D culture configuration for improved tissue functionality and longevity with the requisite throughput and repeatability needed for year-over-year toxicology screening.},
author = {Ramaiahgari, Sreenivasa C and Waidyanatha, Suramya and Dixon, Darlene and DeVito, Michael J and Paules, Richard S and Ferguson, Stephen S},
doi = {10.1093/toxsci/kfx122},
issn = {1096-6080},
journal = {Toxicol. Sci.},
month = {jun},
number = {1},
pages = {124--136},
title = {{From the Cover: Three-Dimensional (3D) HepaRG Spheroid Model With Physiologically Relevant Xenobiotic Metabolism Competence and Hepatocyte Functionality for Liver Toxicity Screening}},
url = {https://doi.org/10.1093/toxsci/kfx122},
volume = {159},
year = {2017}
}
@article{Wu2018,
abstract = {Toxicity prediction is very important to public health. Among its many applications, toxicity prediction is essential to reduce the cost and labor of a drug's preclinical and clinical trials, because a lot of drug evaluations (cellular, animal, and clinical) can be spared due to the predicted toxicity. In the era of Big Data and artificial intelligence, toxicity prediction can benefit from machine learning, which has been widely used in many fields such as natural language processing, speech recognition, image recognition, computational chemistry, and bioinformatics, with excellent performance. In this article, we review machine learning methods that have been applied to toxicity prediction, including deep learning, random forests, k-nearest neighbors, and support vector machines. We also discuss the input parameter to the machine learning algorithm, especially its shift from chemical structural description only to that combined with human transcriptome data analysis, which can greatly enhance prediction accuracy.},
author = {Wu, Yunyi and Wang, Guanyu},
doi = {10.3390/ijms19082358},
issn = {1422-0067},
journal = {Int. J. Mol. Sci.},
keywords = {*Machine Learning,*Natural Language Processing,*Transcriptome,Animals,Gene Expression Profiling/*methods,Humans,chemical structure,deep learning,machine learning,molecular fingerprint,molecular fragment,toxicity prediction,transcriptome},
language = {eng},
month = {aug},
number = {8},
pages = {2358},
publisher = {MDPI},
title = {{Machine Learning Based Toxicity Prediction: From Chemical Structural Description to Transcriptome Analysis}},
url = {https://pubmed.ncbi.nlm.nih.gov/30103448 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6121588/},
volume = {19},
year = {2018}
}
@article{Nguyen2020,
abstract = {We present the performances of our mathematical deep learning (MathDL) models for D3R Grand Challenge 4 (GC4). This challenge involves pose prediction, affinity ranking, and free energy estimation for beta secretase 1 (BACE) as well as affinity ranking and free energy estimation for Cathepsin S (CatS). We have developed advanced mathematics, namely differential geometry, algebraic graph, and/or algebraic topology, to accurately and efficiently encode high dimensional physical/chemical interactions into scalable low-dimensional rotational and translational invariant representations. These representations are integrated with deep learning models, such as generative adversarial networks (GAN) and convolutional neural networks (CNN) for pose prediction and energy evaluation, respectively. Overall, our MathDL models achieved the top place in pose prediction for BACE ligands in Stage 1a. Moreover, our submissions obtained the highest Spearman correlation coefficient on the affinity ranking of 460 CatS compounds, and the smallest centered root mean square error on the free energy set of 39 CatS molecules. It is worthy to mention that our method on docking pose predictions has significantly improved from our previous ones.},
archivePrefix = {arXiv},
arxivId = {1909.07784},
author = {Nguyen, Duc Duy and Gao, Kaifu and Wang, Menglun and Wei, Guo Wei},
doi = {10.1007/s10822-019-00237-5},
eprint = {1909.07784},
issn = {15734951},
journal = {J. Comput. Aided. Mol. Des.},
keywords = {Algebraic topology,Binding affinity,D3R—drug design data resource,Deep learning,Differential geometry,Docking,Generative adversarial network,Graph theory,Pose prediction},
month = {feb},
number = {2},
pages = {131--147},
publisher = {Springer},
title = {{MathDL: mathematical deep learning for D3R Grand Challenge 4}},
url = {http://link.springer.com/10.1007/s10822-019-00237-5},
volume = {34},
year = {2020}
}
@article{afifi_improving_2018,
abstract = {Despite recent efforts to improve the scoring performance of scoring functions, accurately predicting the binding affinity is still a challenging task. Therefore, different approaches were tried to improve the prediction performance of four scoring functions (x-score, vina, autodock, and rf-score) by substituting the linear regression model of classical scoring function by random forest to examine the performance improvement if an additive functional form is not imposed, and by combining different scoring functions into hybrid ones. The datasets were derived from the PDBbind-CN database version 2016. When evaluating the original scoring functions on the generic dataset, rf-score has outperformed classical scoring functions, which shows the superiority of descriptor-based scoring functions. Substituting linear regression as a linear model by random forest as a nonlinear model had largely improved the scoring performance of autodock and vina while x-score had only a slight performance increase. All hybrid scoring functions had only a slight improvement—if any—on both of the combined scoring functions, which is not worth the slower calculation time.},
author = {Afifi, Karim and Al-Sadek, Ahmed Farouk},
doi = {10.1111/cbdd.13206},
issn = {17470285},
journal = {Chem. Biol. Drug Des.},
keywords = {autodock,autodock vina,docking,drug design,rf-score,scoring,scoring function,virtual screening,x-score},
number = {2},
pages = {1429--1434},
shorttitle = {Improving classical scoring functions using random},
title = {{Improving classical scoring functions using random forest: The non-additivity of free energy terms' contributions in binding}},
url = {http://doi.wiley.com/10.1111/cbdd.13206},
volume = {92},
year = {2018}
}
@article{Machado2014,
abstract = {Author Summary Constraint-based modeling has become one of the most successful approaches for modeling large-scale biochemical networks. There are nowadays hundreds of genome-scale reconstructions of metabolic networks available for a wide variety of organisms ranging from bacteria to human cells. One of the limitations of the constraint-based approach is that it describes the cellular phenotype simply in terms of biochemical reaction rates, in a way that is disconnected from other biological processes such as genetic regulation. In order to overcome this limitation, different approaches for integration of gene expression data into constraint-based models have been developed during the past few years. However, all the methods developed so far have only been tested using isolated case studies. In this work, we elaborate a detailed survey of these methods, and perform a critical and quantitative evaluation of a selected subset of methods, using experimental datasets that include different organisms and conditions. This study highlights some of the current limitations in many of these methods, and reveals that no method published so far systematically outperforms the others.},
author = {Machado, Daniel and Herrg{\aa}rd, Markus},
journal = {PLOS Comput. Biol.},
month = {apr},
number = {4},
pages = {e1003580},
publisher = {Public Library of Science},
title = {{Systematic Evaluation of Methods for Integration of Transcriptomic Data into Constraint-Based Models of Metabolism}},
url = {https://doi.org/10.1371/journal.pcbi.1003580},
volume = {10},
year = {2014}
}
@misc{Pawar2019,
abstract = {A plethora of databases exist online that can assist in in silico chemical or drug safety assessment. However, a systematic review and grouping of databases, based on purpose and information content, consolidated in a single source, has been lacking. To resolve this issue, this review provides a comprehensive listing of the key in silico data resources relevant to: chemical identity and properties, drug action, toxicology (including nano-material toxicity), exposure, omics, pathways, Absorption, Distribution, Metabolism and Elimination (ADME) properties, clinical trials, pharmacovigilance, patents-related databases, biological (genes, enzymes, proteins, other macromolecules etc.) databases, protein-protein interactions (PPIs), environmental exposure related, and finally databases relating to animal alternatives in support of 3Rs policies. More than nine hundred databases were identified and reviewed against criteria relating to accessibility, data coverage, interoperability or application programming interface (API), appropriate identifiers, types of in vitro, in vivo,-clinical or other data recorded and suitability for modelling, read-across, or similarity searching. This review also specifically addresses the need for solutions for mapping and integration of databases into a common platform for better translatability of preclinical data to clinical data.},
author = {Pawar, Gopal and Madden, Judith C and Ebbrell, David and Firman, James W and Cronin, Mark T D},
booktitle = {Front. Pharmacol.  },
isbn = {1663-9812},
pages = {561},
title = {{In Silico Toxicology Data Resources to Support Read-Across and (Q)SAR   }},
url = {https://www.frontiersin.org/article/10.3389/fphar.2019.00561},
volume = {10      },
year = {2019}
}
@article{Polak2012,
abstract = {Background: Drugs safety issues are now recognized as being factors generating the most reasons for drug withdrawals at various levels of development and at the post-approval stage. Among them cardiotoxicity remains the main reason, despite the substantial effort put into in vitro and in vivo testing, with the main focus put on hERG channel inhibition as the hypothesized surrogate of drug proarrhythmic potency. The large interest in the IKr current has resulted in the development of predictive tools and informative databases describing a drug's susceptibility to interactions with the hERG channel, although there are no similar, publicly available sets of data describing other ionic currents driven by the human cardiomyocyte ionic channels, which are recognized as an overlooked drug safety target.Discussion: The aim of this database development and publication was to provide a scientifically useful, easily usable and clearly verifiable set of information describing not only IKr (hERG), but also other human cardiomyocyte specific ionic channels inhibition data (IKs, INa, ICa).Summary: The broad range of data (chemical space and in vitro settings) and the easy to use user interface makes tox-database.net a useful tool for interested scientists.Database URL: http://tox-database.net. {\textcopyright} 2012 Polak et al.; licensee BioMed Central Ltd.},
author = {Polak, Sebastian and Wi{\'{s}}niowska, Barbara and Glinka, Anna and Polak, Mi{\l}osz},
doi = {10.1186/2050-6511-13-6},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Polak et al. - 2012 - Tox-Database.net A curated resource for data describing chemical triggered in vitro cardiac ion channels inhibitio.pdf:pdf},
issn = {20506511},
journal = {BMC Pharmacol. Toxicol.},
keywords = {Cardiotoxicity,IC50,In vitro data,L-type calcium current,Rapid potassium current,Slow potassium current,Sodium current},
month = {aug},
number = {1},
pages = {6},
title = {{Tox-Database.net: A curated resource for data describing chemical triggered in vitro cardiac ion channels inhibition}},
url = {https://bmcpharmacoltoxicol.biomedcentral.com/articles/10.1186/2050-6511-13-6},
volume = {13},
year = {2012}
}
@article{le_guilloux_fpocket:_2009,
abstract = {Background: Virtual screening methods start to be well established as effective approaches to identify hits, candidates and leads for drug discovery research. Among those, structure based virtual screening (SBVS) approaches aim at docking collections of small compounds in the target structure to identify potent compounds. For SBVS, the identification of candidate pockets in protein structures is a key feature, and the recent years have seen increasing interest in developing methods for pocket and cavity detection on protein surfaces. Results: Fpocket is an open source pocket detection package based on Voronoi tessellation and alpha spheres built on top of the publicly available package Qhull. The modular source code is organised around a central library of functions, a basis for three main programs: (i) Fpocket, to perform pocket identification, (ii) Tpocket, to organise pocket detection benchmarking on a set of known protein-ligand complexes, and (iii) Dpocket, to collect pocket descriptor values on a set of proteins. Fpocket is written in the C programming language, which makes it a platform well suited for the scientific community willing to develop new scoring functions and extract various pocket descriptors on a large scale level. Fpocket 1.0, relying on a simple scoring function, is able to detect 94{\%} and 92{\%} of the pockets within the best three ranked pockets from the holo and apo proteins respectively, outperforming the standards of the field, while being faster. Conclusion: Fpocket provides a rapid, open source and stable basis for further developments related to protein pocket detection, efficient pocket descriptor extraction, or drugablity prediction purposes. Fpocket is freely available under the GNU GPL license at http://fpocket.sourceforge.net. {\textcopyright} 2009 Le Guilloux et al; licensee BioMed Central Ltd.},
author = {{Le Guilloux}, Vincent and Schmidtke, Peter and Tuffery, Pierre},
doi = {10.1186/1471-2105-10-168},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Le Guilloux, Schmidtke, Tuffery - 2009 - Fpocket An open source platform for ligand pocket detection.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
pages = {168},
pmid = {19486540},
shorttitle = {Fpocket},
title = {{Fpocket: An open source platform for ligand pocket detection}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2700099/},
volume = {10},
year = {2009}
}
@article{vogel_dekois:_2011,
abstract = {For widely applied in silico screening techniques success depends on the rational selection of an appropriate method. We herein present a fast, versatile, and robust method to construct demanding evaluation kits for objective in silico screening (DEKOIS). This automated process enables creating tailor-made decoy sets for any given sets of bioactives. It facilitates a target-dependent validation of docking algorithms and scoring functions helping to save time and resources. We have developed metrics for assessing and improving decoy set quality and employ them to investigate how decoy embedding affects docking. We demonstrate that screening performance is target-dependent and can be impaired by latent actives in the decoy set (LADS) or enhanced by poor decoy embedding. The presented method allows extending and complementing the collection of publicly available high quality decoy sets toward new target space. All present and future DEKOIS data sets will be made accessible at www.dekois.com. {\textcopyright} 2011 American Chemical Society.},
author = {Vogel, Simon M. and Bauer, Matthias R. and Boeckler, Frank M.},
doi = {10.1021/ci2001549},
issn = {15499596},
journal = {J. Chem. Inf. Model.},
number = {10},
pages = {2650--2665},
shorttitle = {DEKOIS},
title = {{DEKOIS: Demanding evaluation kits for objective in silico screening - A versatile tool for benchmarking docking programs and scoring functions}},
url = {https://pubs.acs.org/doi/10.1021/ci2001549},
volume = {51},
year = {2011}
}
@misc{Li2016d,
abstract = {Microarray technology, with its high-throughput advantage, has been applied to  analyze various biomaterials, such as nucleic acids, proteins, glycans, peptides, and cells.},
author = {Li, Paul C H},
booktitle = {Methods Mol. Biol.},
doi = {10.1007/978-1-4939-3136-1_1},
issn = {1940-6029 (Electronic)},
keywords = {Humans,Microarray Analysis},
language = {eng},
pages = {3--4},
pmid = {26614064},
title = {{Overview of Microarray Technology.}},
volume = {1368},
year = {2016}
}
@article{huang_scoring_2010,
abstract = {The scoring function is one of the most important components in structure-based drug design. Despite considerable success, accurate and rapid prediction of protein-ligand interactions is still a challenge in molecular docking. In this perspective, we have reviewed three basic types of scoring functions (force-field, empirical, and knowledge-based) and the consensus scoring technique that are used for protein-ligand docking. The commonly-used assessment criteria and publicly available protein-ligand databases for performance evaluation of the scoring functions have also been presented and discussed. We end with a discussion of the challenges faced by existing scoring functions and possible future directions for developing improved scoring functions. {\textcopyright} 2010 the Owner Societies.},
author = {Huang, Sheng You and Grinter, Sam Z. and Zou, Xiaoqin},
doi = {10.1039/c0cp00151a},
issn = {14639076},
journal = {Phys. Chem. Chem. Phys.},
number = {40},
pages = {12899--12908},
pmid = {20730182},
shorttitle = {Scoring functions and their evaluation methods for},
title = {{Scoring functions and their evaluation methods for protein-ligand docking: Recent advances and future directions}},
url = {http://xlink.rsc.org/?DOI=c0cp00151a},
volume = {12},
year = {2010}
}
@article{Misselbeck2019,
abstract = {Metabolic syndrome is a pathological condition characterized by obesity, hyperglycemia, hypertension, elevated levels of triglycerides and low levels of high-density lipoprotein cholesterol that increase cardiovascular disease risk and type 2 diabetes. Although numerous predisposing genetic risk factors have been identified, the biological mechanisms underlying this complex phenotype are not fully elucidated. Here we introduce a systems biology approach based on network analysis to investigate deregulated biological processes and subsequently identify drug repurposing candidates. A proximity score describing the interaction between drugs and pathways is defined by combining topological and functional similarities. The results of this computational framework highlight a prominent role of the immune system in metabolic syndrome and suggest a potential use of the BTK inhibitor ibrutinib as a novel pharmacological treatment. An experimental validation using a high fat diet-induced obesity model in zebrafish larvae shows the effectiveness of ibrutinib in lowering the inflammatory load due to macrophage accumulation.},
author = {Misselbeck, Karla and Parolo, Silvia and Lorenzini, Francesca and Savoca, Valeria and Leonardelli, Lorena and Bora, Pranami and Morine, Melissa J and Mione, Maria Caterina and Domenici, Enrico and Priami, Corrado},
doi = {10.1038/s41467-019-13208-z},
issn = {2041-1723},
journal = {Nat. Commun.},
number = {1},
pages = {5215},
title = {{A network-based approach to identify deregulated pathways and drug effects in metabolic syndrome}},
url = {https://doi.org/10.1038/s41467-019-13208-z},
volume = {10},
year = {2019}
}
@article{Jetten2013,
abstract = {Efforts are put into developing toxicogenomics-based toxicity testing methods using in vitro human cell models for improving human risk assessment/replacing animal models. Human in vitro liver models include HepG2, HepaRG and primary human hepatocytes (PHH). Studies on comparability/applicability of these cell types mainly focus on assessing baseline biotransformation capacities/cytochrome P450-inducibility, but compound-induced gene expression profiles are at least as important. Therefore, we compared baseline and aflatoxin B1- and benzo($\alpha$)pyrene-induced gene expression profiles in HepG2, HepaRG and PHH (11-13 donors). At baseline, all liver models differ from each other with respect to whole genome gene expression levels. PHH show profound inter-individual differences, and are most similar to HepaRG. After compound exposure, induced gene expression profiles are more similar between cell models, especially for benzo($\alpha$)pyrene. Pathways involved in compound metabolism are induced in all 3 models, while others are more pronounced in a specific cell model. Examples are transcriptomic modifications of carbohydrate-related genes (HepaRG) and of receptor-related genes (PHH) after benzo($\alpha$)pyrene exposure, and of cell cycle-related genes (HepG2) after aflatoxin B1 exposure. PHH gene expression responses are the most heterogeneous. In conclusion, at base line level PHH are more similar to HepaRG than to HepG2, but for toxicogenomics applications both cell lines perform equally well in comparison to PHH.},
author = {Jetten, M J A and Kleinjans, J C S and Claessen, S M and Chesn{\'{e}}, C and van Delft, J H M},
doi = {https://doi.org/10.1016/j.tiv.2013.07.010},
issn = {0887-2333},
journal = {Toxicol. Vitr.},
keywords = {Gene expression,HepG2,HepaRG,Interindividual variability,Primary human hepatocytes},
number = {7},
pages = {2031--2040},
title = {{Baseline and genotoxic compound induced gene expression profiles in HepG2 and HepaRG compared to primary human hepatocytes}},
url = {http://www.sciencedirect.com/science/article/pii/S0887233313001884},
volume = {27},
year = {2013}
}
@article{Mezencev2020d,
abstract = {Whole-genome expression data generated by microarray studies have shown promise for  quantitative human health risk assessment. While numerous approaches have been developed to determine benchmark doses (BMDs) from probeset-level dose responses, sensitivity of the results to methods used for normalization of the data has not yet been systematically investigated. Normalization of microarray data converts raw hybridization signals to expression estimates that are expected to be proportional to the amounts of transcripts in the profiled specimens. Different approaches to normalization have been shown to greatly influence the results of some downstream analyses, including biological interpretation. In this study we evaluate the influence of microarray normalization methods on the transcriptomic BMDs. We demonstrate using in vivo data that the use of alternative pipelines for normalization of Affymetrix microarray data can have a considerable impact on the number of detected differentially expressed genes and pathways (processes) determined to be treatment responsive, which may lead to alternative interpretations of the data. In addition, we found that normalization can have a considerable effect (as much as {\~{}}30-fold in this study) on estimation of the minimum biological potency (transcriptomic point of departure). We argue for consideration of alternative normalization methods and their data-informed selection to most effectively interpret microarray data for use in human health risk assessment.},
author = {Mezencev, Roman and Auerbach, Scott S},
doi = {10.1371/journal.pone.0232955},
issn = {1932-6203 (Electronic)},
journal = {PLoS One},
keywords = {Benchmarking,Computational Biology,Gene Expression Profiling,Genome,Humans,Nucleic Acid Hybridization,Oligonucleotide Array Sequence Analysis,Risk Assessment,Transcriptome,genetics,methods},
language = {eng},
number = {5},
pages = {e0232955},
pmid = {32413060},
title = {{The sensitivity of transcriptomics BMD modeling to the methods used for microarray  data normalization.}},
volume = {15},
year = {2020}
}
@article{Finotello2012,
abstract = {Motivations.  In recent years, RNA sequencing (RNA-seq) has rapidly become the method of choice for measuring and comparing gene transcription levels. Despite its wide application, it is now clear that this methodology is not free from biases and that a careful normalization procedure is the basis for a correct data interpretation. The most common normalization techniques account for: library size, gene or transcript length and sequence-specific biases such as GC-content effects. The aim of the present work is to investigate biases affecting RNA seq data and their effect on differential expression analysis. In order to reduce biases due to over-simplification of gene transcription models, we consider exon-based counts.      Methods.  We two used publicly available RNA-seq data sets from two-group comparison studies which are characterized by multiple technical replicates. We summarized read counts at exon level and investigated their dependence on sequence-specific covariates: GC-content and exon length. In addition, we considered the effect of library size correction on between-groups comparison and the impact of the above mentioned biases on the detection of differentially expressed exons. The assessment is performed on raw data, as well as on data normalized with different approaches: RPKM [1], library size scaling, based on Trimmed Mean of M-values (TMM) [2] and on Poisson goodness-of-fit statistic applied to non differentially expressed genes [3], and within-lane normalization based on loess regression of log-counts on GC-content and exon length [4]. We selected differentially expressed exons using the GLM-based version of edgeR [5] as it can consider an "offset" matrix which codifies counts normalization, that can be computed with the desired approach, and library size scaling factors specified by the user.   Results.  In our study, read counts show a significant dependence on exon length and a moderate dependence on GC-content. Exon length bias also affects differential expression analysis: longer exons tend to have lower P-values and to be selected as differentially expressed more frequently than shorter exons. The tested normalization techniques do not completely remove biases and, in particular, RPKM approach over-corrects for exon length bias. Moreover, the choice of the strategy for library size adjustment has a great impact on the direction of the detected differential expression. The results obtained on these data sets demonstrate that RNA-seq data normalization is still an open issue. Further efforts should be directed towards the clarification of the relationship between read counts and sequence-specific biases, which are, in turn, correlated to each other, and the definition of new models for their correction.  References  1. Mortazavi A, Williams BA, McCue K, Schaeffer L, Wold B. Mapping and quantifying mammalian transcriptomes by RNA-seq. Nature methods. 2008;5(7):621-8.  2. Robinson MD, Oshlack A. A scaling normalization method for differential expression analysis of RNA-seq data. Genome Biol. 2010;11(3):R25.  3. Li J, Witten DM, Johnstone IM, Tibshirani R. Normalization, testing, and false discovery rate estimation for RNA-sequencing data. Biostatistics. 2011.  4. Risso D, Schwartz K, Sherlock G, Dudoit S. GC-content normalization for RNA-seq data. BMC Bioinformatics. 2011;12(1):480.  5. McCarthy DJ, Chen Y, Smyth GK. Differential expression analysis of multifactor RNA-seq experiments with respect to biological variation. Nucleic Acids Res. 2012.},
author = {Finotello, F and Lavezzo, E and Barzon, L and Fontana, P and Si-Ammour, A and Toppo, S and {Di Camillo}, B},
doi = {10.14806/ej.18.a.441},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Finotello et al. - 2012 - RNA sequencing data biases and normalization.pdf:pdf},
journal = {EMBnet.journal},
month = {apr},
number = {A},
pages = {99},
publisher = {EMBnet Stichting},
title = {{RNA sequencing data: biases and normalization}},
volume = {18},
year = {2012}
}
@article{Ekins2019,
abstract = {A variety of machine learning methods such as naive Bayesian, support vector machines and more recently deep neural networks are demonstrating their utility for drug discovery and development. These leverage the generally bigger datasets created from high-throughput screening data and allow prediction of bioactivities for targets and molecular properties with increased levels of accuracy. We have only just begun to exploit the potential of these techniques but they may already be fundamentally changing the research process for identifying new molecules and/or repurposing old drugs. The integrated application of such machine learning models for end-to-end (E2E) application is broadly relevant and has considerable implications for developing future therapies and their targeting.},
author = {Ekins, Sean and Puhl, Ana C and Zorn, Kimberley M and Lane, Thomas R and Russo, Daniel P and Klein, Jennifer J and Hickey, Anthony J and Clark, Alex M},
doi = {10.1038/s41563-019-0338-z},
issn = {1476-4660},
journal = {Nat. Mater.},
number = {5},
pages = {435--441},
title = {{Exploiting machine learning for end-to-end drug discovery and development}},
url = {https://doi.org/10.1038/s41563-019-0338-z},
volume = {18},
year = {2019}
}
@article{Igarashi2015a,
abstract = {Toxicogenomics focuses on assessing the safety of compounds using gene expression profiles. Gene expression signatures from large toxicogenomics databases are expected to perform better than small databases in identifying biomarkers for the prediction and evaluation of drug safety based on a compound's toxicological mechanisms in animal target organs. Over the past 10 years, the Japanese Toxicogenomics Project consortium (TGP) has been developing a large-scale toxicogenomics database consisting of data from 170 compounds (mostly drugs) with the aim of improving and enhancing drug safety assessment. Most of the data generated by the project (e.g. gene expression, pathology, lot number) are freely available to the public via Open TG-GATEs (Toxicogenomics Project-Genomics Assisted Toxicity Evaluation System). Here, we provide a comprehensive overview of the database, including both gene expression data and metadata, with a description of experimental conditions and procedures used to generate the database. Open TG-GATEs is available from http://toxico.nibio.go.jp/english/index. html.},
author = {Igarashi, Yoshinobu and Nakatsu, Noriyuki and Yamashita, Tomoya and Ono, Atsushi and Ohno, Yasuo and Urushidani, Tetsuro and Yamada, Hiroshi},
doi = {10.1093/nar/gku955},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Igarashi et al. - 2015 - Open TG-GATEs A large-scale toxicogenomics database.pdf:pdf},
issn = {13624962},
journal = {Nucleic Acids Res.},
month = {jan},
number = {D1},
pages = {D921--D927},
publisher = {Oxford University Press},
title = {{Open TG-GATEs: A large-scale toxicogenomics database}},
url = {https://academic.oup.com/nar/article/43/D1/D921/2439524},
volume = {43},
year = {2015}
}
@article{mukherjee_docking_2010,
abstract = {A database consisting of 780 ligand-receptor complexes, termed SB2010, has been derived from the Protein Databank to evaluate the accuracy of docking protocols for regenerating bound ligand conformations. The goal is to provide easily accessible community resources for development of improved procedures to aid virtual screening for ligands with a wide range of flexibilities. Three core experiments using the program DOCK, which employ rigid (RGD), fixed anchor (FAD), and flexible (FLX) protocols, were used to gauge performance by several different metrics: (1) global results, (2) ligand flexibility, (3) protein family, and (4) cross-docking. Global spectrum plots of successes and failures vs rmsd reveal well-defined inflection regions, which suggest the commonly used 2 {\AA} criteria is a reasonable choice for defining success. Across all 780 systems, success tracks with the relative difficulty of the calculations: RGD (82.3{\%}) {\textgreater} FAD (78.1{\%}) {\textgreater} FLX (63.8{\%}). In general, failures due to scoring strongly outweigh those due to sampling. Subsets of SB2010 grouped by ligand flexibility (7-or-less, 8-to-15, and 15-plus rotatable bonds) reveal that success degrades linearly for FAD and FLX protocols, in contrast to RGD, which remains constant. Despite the challenges associated with FLX anchor orientation and on-the-fly flexible growth, success rates for the 7-or-less (74.5{\%}) and, in particular, the 8-to-15 (55.2{\%}) subset are encouraging. Poorer results for the very flexible 15-plus set (39.3{\%}) indicate substantial room for improvement. Family-based success appears largely independent of ligand flexibility, suggesting a strong dependence on the binding site environment. For example, zinc-containing proteins are generally problematic, despite moderately flexible ligands. Finally, representative cross-docking examples, for carbonic anhydrase, thermolysin, and neuraminidase families, show the utility of family-based analysis for rapid identification of particularly good or bad docking trends, and the type of failures involved (scoring/sampling), which will likely be of interest to researchers making specific receptor choices for virtual screening. SB2010 is available for download at http://rizzolab.org. {\textcopyright} 2010 American Chemical Society.},
author = {Mukherjee, Sudipto and Balius, Trent E. and Rizzo, Robert C.},
doi = {10.1021/ci1001982},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mukherjee, Balius, Rizzo - 2010 - Docking validation resources Protein family and ligand flexibility experiments.pdf:pdf},
issn = {15499596},
journal = {J. Chem. Inf. Model.},
number = {11},
pages = {1986--2000},
pmid = {21033739},
shorttitle = {Docking {\{}Validation{\}} {\{}Resources{\}}},
title = {{Docking validation resources: Protein family and ligand flexibility experiments}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3058392/},
volume = {50},
year = {2010}
}
@article{McCall2011,
abstract = {Various databases have harnessed the wealth of publicly available microarray data to  address biological questions ranging from across-tissue differential expression to homologous gene expression. Despite their practical value, these databases rely on relative measures of expression and are unable to address the most fundamental question--which genes are expressed in a given cell type. The Gene Expression Barcode is the first database to provide reliable absolute measures of expression for most annotated genes for 131 human and 89 mouse tissue types, including diseased tissue. This is made possible by a novel algorithm that leverages information from the GEO and ArrayExpress public repositories to build statistical models that permit converting data from a single microarray into expressed/unexpressed calls for each gene. For selected platforms, users may upload data and obtain results in a matter of seconds. The raw data, curated annotation, and code used to create our resource are also available at http://rafalab.jhsph.edu/barcode.},
author = {McCall, Matthew N and Uppal, Karan and Jaffee, Harris A and Zilliox, Michael J and Irizarry, Rafael A},
doi = {10.1093/nar/gkq1259},
issn = {1362-4962 (Electronic)},
journal = {Nucleic Acids Res.},
keywords = {Animals,Databases, Genetic,Gene Expression Profiling,Humans,Mice,Oligonucleotide Array Sequence Analysis,Software},
language = {eng},
month = {jan},
number = {Database issue},
pages = {D1011--5},
pmid = {21177656},
title = {{The Gene Expression Barcode: leveraging public data repositories to begin cataloging  the human and murine transcriptomes.}},
volume = {39},
year = {2011}
}
@article{trott_autodock_2010,
abstract = {AutoDock Vina, a new program for molecular docking and virtual screening, is presented. AutoDock Vina achieves an approximately two orders of magnitude speed-up compared with the molecular docking software previously developed in our lab (AutoDock 4), while also significantly improving the accuracy of the binding mode predictions, judging by our tests on the training set used in AutoDock 4 development. Further speed-up is achieved from parallelism, by using multithreading on multicore machines. AutoDock Vina automatically calculates the grid maps and clusters the results in a way transparent to the user.},
author = {Trott, Oleg and Olson, Arthur J.},
doi = {10.1002/jcc.21334},
issn = {01928651},
journal = {J. Comput. Chem.},
keywords = {*Ligands,*Software,Algorithms,Automation,Binding Sites,Computational Biology/*methods,Hydrogen Bonding,Hydrophobic and Hydrophilic Interactions,Molecular Dynamics Simulation,Sensitivity and Specificity,Solvents/chemistry,Thermodynamics,Time Factors},
number = {2},
pages = {NA--NA},
pmid = {19499576},
title = {{AutoDock Vina: Improving the speed and accuracy of docking with a new scoring function, efficient optimization, and multithreading}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/19499576},
volume = {31},
year = {2009}
}
@article{Zilliox2007,
abstract = {The ability to measure genome-wide expression holds great promise for characterizing  cells and distinguishing diseased from normal tissues. Thus far, microarray technology has been useful only for measuring relative expression between two or more samples, which has handicapped its ability to classify tissue types. Here we present a method that can successfully predict tissue type based on data from a single hybridization. A preliminary web-tool is available online (http://rafalab.jhsph.edu/barcode/).},
author = {Zilliox, Michael J and Irizarry, Rafael A},
doi = {10.1038/nmeth1102},
issn = {1548-7091 (Print)},
journal = {Nat. Methods},
keywords = {Algorithms,Animals,Breast Neoplasms,Computational Biology,Databases, Genetic,Electronic Data Processing,Female,Gene Expression Profiling,Genome,Humans,Internet,Mice,Oligonucleotide Array Sequence Analysis,Prognosis,diagnosis,genetics,methods,statistics {\&} numerical data},
language = {eng},
month = {nov},
number = {11},
pages = {911--913},
pmid = {17906632},
title = {{A gene expression bar code for microarray data.}},
volume = {4},
year = {2007}
}
@article{madhavi_sastry_protein_2013,
abstract = {Structure-based virtual screening plays an important role in drug discovery and complements other screening approaches. In general, protein crystal structures are prepared prior to docking in order to add hydrogen atoms, optimize hydrogen bonds, remove atomic clashes, and perform other operations that are not part of the x-ray crystal structure refinement process. In addition, ligands must be prepared to create 3-dimensional geometries, assign proper bond orders, and generate accessible tautomer and ionization states prior to virtual screening. While the prerequisite for proper system preparation is generally accepted in the field, an extensive study of the preparation steps and their effect on virtual screening enrichments has not been performed. In this work, we systematically explore each of the steps involved in preparing a system for virtual screening. We first explore a large number of parameters using the Glide validation set of 36 crystal structures and 1,000 decoys. We then apply a subset of protocols to the DUD database. We show that database enrichment is improved with proper preparation and that neglecting certain steps of the preparation process produces a systematic degradation in enrichments, which can be large for some targets. We provide examples illustrating the structural changes introduced by the preparation that impact database enrichment. While the work presented here was performed with the Protein Preparation Wizard and Glide, the insights and guidance are expected to be generalizable to structure-based virtual screening with other docking methods. {\textcopyright} 2013 Springer Science+Business Media Dordrecht.},
author = {{Madhavi Sastry}, G. and Adzhigirey, Matvey and Day, Tyler and Annabhimoju, Ramakrishna and Sherman, Woody},
doi = {10.1007/s10822-013-9644-8},
issn = {0920654X},
journal = {J. Comput. Aided. Mol. Des.},
keywords = {Docking,Enrichment,Epik,Ligand preparation,PrepWizard,Protein preparation,Protein preparation wizard,Virtual screening},
number = {3},
pages = {221--234},
shorttitle = {Protein and ligand preparation},
title = {{Protein and ligand preparation: Parameters, protocols, and influence on virtual screening enrichments}},
url = {http://link.springer.com/10.1007/s10822-013-9644-8},
volume = {27},
year = {2013}
}
@article{ebejer_freely_2012,
abstract = {Conformer generation has important implications in cheminformatics, particularly in computational drug discovery where the quality of conformer generation software may affect the outcome of a virtual screening exercise. We examine the performance of four freely available small molecule conformer generation tools (Balloon, Confab, Frog2, and RDKit) alongside a commercial tool (MOE). The aim of this study is 3-fold: (i) to identify which tools most accurately reproduce experimentally determined structures; (ii) to examine the diversity of the generated conformational set; and (iii) to benchmark the computational time expended. These aspects were tested using a set of 708 drug-like molecules assembled from the OMEGA validation set and the Astex Diverse Set. These molecules have varying physicochemical properties and at least one known X-ray crystal structure. We found that RDKit and Confab are statistically better than other methods at generating low rmsd conformers to the known structure. RDKit is particularly suited for less flexible molecules while Confab, with its systematic approach, is able to generate conformers which are geometrically closer to the experimentally determined structure for molecules with a large number of rotatable bonds (≥10). In our tests RDKit also resulted as the second fastest method after Frog2. In order to enhance the performance of RDKit, we developed a postprocessing algorithm to build a diverse and representative set of conformers which also contains a close conformer to the known structure. Our analysis indicates that, with postprocessing, RDKit is a valid free alternative to commercial, proprietary software. {\textcopyright} 2012 American Chemical Society.},
author = {Ebejer, Jean Paul and Morris, Garrett M. and Deane, Charlotte M.},
doi = {10.1021/ci2004658},
issn = {15499596},
journal = {J. Chem. Inf. Model.},
number = {5},
pages = {1146--1158},
shorttitle = {Freely {\{}Available{\}} {\{}Conformer{\}} {\{}Generation{\}} {\{}Metho}},
title = {{Freely available conformer generation methods: How good are they?}},
url = {http://pubs.acs.org/doi/10.1021/ci2004658},
volume = {52},
year = {2012}
}
@article{Schubert2018,
abstract = {Aberrant cell signaling can cause cancer and other diseases and is a focal point of drug research. A common approach is to infer signaling activity of pathways from gene expression. However, mapping gene expression to pathway components disregards the effect of post-translational modifications, and downstream signatures represent very specific experimental conditions. Here we present PROGENy, a method that overcomes both limitations by leveraging a large compendium of publicly available perturbation experiments to yield a common core of Pathway RespOnsive GENes. Unlike pathway mapping methods, PROGENy can (i) recover the effect of known driver mutations, (ii) provide or improve strong markers for drug indications, and (iii) distinguish between oncogenic and tumor suppressor pathways for patient survival. Collectively, these results show that PROGENy accurately infers pathway activity from gene expression in a wide range of conditions.},
author = {Schubert, Michael and Klinger, Bertram and Kl{\"{u}}nemann, Martina and Sieber, Anja and Uhlitz, Florian and Sauer, Sascha and Garnett, Mathew J and Bl{\"{u}}thgen, Nils and Saez-Rodriguez, Julio},
doi = {10.1038/s41467-017-02391-6},
issn = {2041-1723},
journal = {Nat. Commun.},
number = {1},
pages = {20},
title = {{Perturbation-response genes reveal signaling footprints in cancer gene expression}},
url = {https://doi.org/10.1038/s41467-017-02391-6},
volume = {9},
year = {2018}
}
@misc{Liu2019d,
abstract = {Dozens of normalization methods for correcting experimental variation and bias in high-throughput expression data have been developed during the last two decades. Up to 23 methods among them consider the skewness of expression data between sample states, which are even more than the conventional methods, such as loess and quantile. From the perspective of reference selection, we classified the normalization methods for skewed expression data into three categories, data-driven reference, foreign reference, and entire gene set. We separately introduced and summarized these normalization methods designed for gene expression data with global shift between compared conditions, including both microarray and RNA-seq, based on the reference selection strategies. To our best knowledge, this is the most comprehensive review of available preprocessing algorithms for the unbalanced transcriptome data. The anatomy and summarization of these methods shed light on the understanding and appropriate application of preprocessing methods.},
author = {Liu, Xueyan and Li, Nan and Liu, Sheng and Wang, Jun and Zhang, Ning and Zheng, Xubin and Leung, Kwong-Sak and Cheng, Lixin},
booktitle = {Front. Bioeng. Biotechnol.  },
isbn = {2296-4185},
pages = {358},
title = {{Normalization Methods for the Analysis of Unbalanced Transcriptome Data: A Review   }},
url = {https://www.frontiersin.org/article/10.3389/fbioe.2019.00358},
volume = {7      },
year = {2019}
}
@incollection{Hardt2018,
abstract = {The computational prediction of compound effects from molecular data is an important task in hazard and risk assessment and pivotal for judging the safety of any drug, chemical or cosmetic compound. In particular, the identification of such compound effects at the level of molecular interaction networks can be helpful for the construction of adverse outcome pathways (AOPs). AOPs emerged as a guiding concept for toxicity prediction, because of the inherent mechanistic information of such networks. In fact, integrating molecular interactions in transcriptome analysis and observing expression changes in closely interacting genes might allow identifying the key molecular initiating events of compound toxicity. In this work we describe a computational approach that is suitable for the identification of such network modules from transcriptomics data, which is the major molecular readout of toxicogenomics studies. The approach is composed of different tools (1) for primary data analysis, i.e., the biostatistical quantification of the gene expression changes, (2) for functional annotation and prioritization of genes using literature mining, as well as (3) for the construction of an interaction network that consists of interactions with high confidence and the identification of predictive modules from these networks. We describe the different steps of the approach and demonstrate its performance with public data on drugs that induce hepatic and cardiac toxicity.},
author = {Hardt, C. and Bauer, C. and Schuchhardt, J. and Herwig, R.},
booktitle = {Methods Mol. Biol.},
doi = {10.1007/978-1-4939-8618-7_16},
issn = {10643745},
keywords = {Computational modeling,Drug Toxicity,Literature mining,Molecular interactions,Network analysis,Toxicogenomics},
pages = {335--355},
publisher = {Humana Press Inc.},
title = {{Computational network analysis for drug toxicity prediction}},
url = {http://link.springer.com/10.1007/978-1-4939-8618-7{\_}16},
volume = {1819},
year = {2018}
}
@article{Frezza2011,
abstract = {Inherited mutations in fumarate hydratase (FH), an enzyme in the tricarboxylic acid cycle — which links many of the metabolic reactions in aerobic cellular respiration — can lead to malignancies including kidney cancer. Frezza et al. now observe a metabolic pathway in FH-deficient cells that converts glutamine into bilirubin through the synthesis and degradation of haem. This renders FH-deficient cells sensitive to inhibition of haem oxygenase, a key enzyme in this pathway. Haem oxygenase might therefore be a therapeutic target in patients with tumours associated with FH loss.},
author = {Frezza, Christian and Zheng, Liang and Folger, Ori and Rajagopalan, Kartik N and MacKenzie, Elaine D and Jerby, Livnat and Micaroni, Massimo and Chaneton, Barbara and Adam, Julie and Hedley, Ann and Kalna, Gabriela and Tomlinson, Ian P M and Pollard, Patrick J and Watson, Dave G and Deberardinis, Ralph J and Shlomi, Tomer and Ruppin, Eytan and Gottlieb, Eyal},
doi = {10.1038/nature10363},
issn = {1476-4687},
journal = {Nature},
number = {7363},
pages = {225--228},
title = {{Haem oxygenase is synthetically lethal with the tumour suppressor fumarate hydratase}},
url = {https://doi.org/10.1038/nature10363},
volume = {477},
year = {2011}
}
@article{bemis_properties_1996,
abstract = {In order to better understand the common features present in drug molecules, we use shape description methods to analyze a database of commercially available drugs and prepare a list of common drug shapes. A useful way of organizing this structural data is to group the atoms of each drug molecule into ring, linker, framework, and side chain atoms. On the basis of the two-dimensional molecular structures (without regard to atom type, hybridization, and bond order), there are 1179 different frameworks among the 5120 compounds analyzed. However, the shapes of half of the drugs in the database are described by the 32 most frequently occurring frameworks. This suggests that the diversity of shapes in the set of known drugs is extremely low. In our second method of analysis, in which atom type, hybridization, and bond order are considered, more diversity is seen; there are 2506 different frameworks among the 5120 compounds in the database, and the most frequently occurring 42 frameworks account for only one-fourth of the drugs. We discuss the possible interpretations of these findings and the way they may be used to guide future drug discovery research.},
author = {Bemis, Guy W. and Murcko, Mark A.},
doi = {10.1021/jm9602928},
issn = {00222623},
journal = {J. Med. Chem.},
number = {15},
pages = {2887--2893},
pmid = {8709122},
title = {{The properties of known drugs. 1. Molecular frameworks}},
url = {https://pubs.acs.org/doi/10.1021/jm9602928},
volume = {39},
year = {1996}
}
@article{Nair2020,
abstract = {In the past few decades, major initiatives have been launched around the world to address chemical safety testing. These efforts aim to innovate and improve the efficacy of existing methods with the long-term goal of developing new risk assessment paradigms. The transcriptomic and toxicological profiling of mammalian cells has resulted in the creation of multiple toxicogenomic datasets and corresponding tools for analysis. To enable easy access and analysis of these valuable toxicogenomic data, we have developed ToxicoDB (toxicodb.ca), a free and open cloud-based platform integrating data from large in vitro toxicogenomic studies, including gene expression profiles of primary human and rat hepatocytes treated with 231 potential toxicants. To efficiently mine these complex toxicogenomic data, ToxicoDB provides users with harmonized chemical annotations, time- and dose-dependent plots of compounds across datasets, as well as the toxicity-related pathway analysis. The data in ToxicoDB have been generated using our open-source R package, ToxicoGx (github.com/bhklab/ToxicoGx). Altogether, ToxicoDB provides a streamlined process for mining highly organized, curated, and accessible toxicogenomic data that can be ultimately applied to preclinical toxicity studies and further our understanding of adverse outcomes.},
author = {Nair, Sisira Kadambat and Eeles, Christopher and Ho, Chantal and Beri, Gangesh and Yoo, Esther and Tkachuk, Denis and Tang, Amy and Nijrabi, Parwaiz and Smirnov, Petr and Seo, Heewon and Jennen, Danyel and Haibe-Kains, Benjamin},
doi = {10.1093/nar/gkaa390},
issn = {0305-1048},
journal = {Nucleic Acids Res.},
month = {may},
number = {W1},
pages = {W455--W462},
title = {{ToxicoDB: an integrated database to mine and visualize large-scale toxicogenomic datasets}},
url = {https://doi.org/10.1093/nar/gkaa390},
volume = {48},
year = {2020}
}
@article{Brunk2018,
abstract = {Genome-scale network reconstructions have helped uncover the molecular basis of  metabolism. Here we present Recon3D, a computational resource that includes three-dimensional (3D) metabolite and protein structure data and enables integrated analyses of metabolic functions in humans. We use Recon3D to functionally characterize mutations associated with disease, and identify metabolic response signatures that are caused by exposure to certain drugs. Recon3D represents the most comprehensive human metabolic network model to date, accounting for 3,288 open reading frames (representing 17{\%} of functionally annotated human genes), 13,543 metabolic reactions involving 4,140 unique metabolites, and 12,890 protein structures. These data provide a unique resource for investigating molecular mechanisms of human metabolism. Recon3D is available at http://vmh.life.},
author = {Brunk, Elizabeth and Sahoo, Swagatika and Zielinski, Daniel C and Altunkaya, Ali and Dr{\"{a}}ger, Andreas and Mih, Nathan and Gatto, Francesco and Nilsson, Avlant and {Preciat Gonzalez}, German Andres and Aurich, Maike Kathrin and Prli{\'{c}}, Andreas and Sastry, Anand and Danielsdottir, Anna D and Heinken, Almut and Noronha, Alberto and Rose, Peter W and Burley, Stephen K and Fleming, Ronan M T and Nielsen, Jens and Thiele, Ines and Palsson, Bernhard O},
doi = {10.1038/nbt.4072},
issn = {1546-1696 (Electronic)},
journal = {Nat. Biotechnol.},
keywords = {Computational Biology,Databases, Genetic,Databases, Protein,Humans,Internet,Metabolic Networks and Pathways,Molecular Sequence Annotation,Open Reading Frames,genetics,methods},
language = {eng},
month = {mar},
number = {3},
pages = {272--281},
pmid = {29457794},
title = {{Recon3D enables a three-dimensional view of gene variation in human metabolism.}},
volume = {36},
year = {2018}
}
@article{Federico2020d,
abstract = {Preprocessing of transcriptomics data plays a pivotal role in the development of  toxicogenomics-driven tools for chemical toxicity assessment. The generation and exploitation of large volumes of molecular profiles, following an appropriate experimental design, allows the employment of toxicogenomics (TGx) approaches for a thorough characterisation of the mechanism of action (MOA) of different compounds. To date, a plethora of data preprocessing methodologies have been suggested. However, in most cases, building the optimal analytical workflow is not straightforward. A careful selection of the right tools must be carried out, since it will affect the downstream analyses and modelling approaches. Transcriptomics data preprocessing spans across multiple steps such as quality check, filtering, normalization, batch effect detection and correction. Currently, there is a lack of standard guidelines for data preprocessing in the TGx field. Defining the optimal tools and procedures to be employed in the transcriptomics data preprocessing will lead to the generation of homogeneous and unbiased data, allowing the development of more reliable, robust and accurate predictive models. In this review, we outline methods for the preprocessing of three main transcriptomic technologies including microarray, bulk RNA-Sequencing (RNA-Seq), and single cell RNA-Sequencing (scRNA-Seq). Moreover, we discuss the most common methods for the identification of differentially expressed genes and to perform a functional enrichment analysis. This review is the second part of a three-article series on Transcriptomics in Toxicogenomics.},
author = {Federico, Antonio and Serra, Angela and Ha, My Kieu and Kohonen, Pekka and Choi, Jang-Sik and Liampa, Irene and Nymark, Penny and Sanabria, Natasha and Cattelani, Luca and Fratello, Michele and Kinaret, Pia Anneli Sofia and Jagiello, Karolina and Puzyn, Tomasz and Melagraki, Georgia and Gulumian, Mary and Afantitis, Antreas and Sarimveis, Haralambos and Yoon, Tae-Hyun and Grafstr{\"{o}}m, Roland and Greco, Dario},
doi = {10.3390/nano10050903},
issn = {2079-4991 (Print)},
journal = {Nanomater. (Basel, Switzerland)},
language = {eng},
month = {may},
number = {5},
pmid = {32397130},
title = {{Transcriptomics in Toxicogenomics, Part II: Preprocessing and Differential  Expression Analysis for High Quality Data.}},
volume = {10},
year = {2020}
}
@article{Schultz2015,
abstract = {Category formation, grouping and read across methods are broadly applicable in toxicological assessments and may be used to fill data gaps for chemical safety assessment and regulatory decisions. In order to facilitate a transparent and systematic approach to aid regulatory acceptance, a strategy to evaluate chemical category membership, to support the use of read-across predictions that may be used to fill data gaps for regulatory decisions is proposed. There are two major aspects of any read-across exercise, namely assessing similarity and uncertainty. While there can be an over-arching rationale for grouping organic substances based on molecular structure and chemical properties, these similarities alone are generally not sufficient to justify a read-across prediction. Further scientific justification is normally required to justify the chemical grouping, typically including considerations of bioavailability, metabolism and biological/mechanistic plausibility. Sources of uncertainty include a variety of elements which are typically divided into two main issues: the uncertainty associated firstly with the similarity justification and secondly the completeness of the read-across argument. This article focuses on chronic toxicity, whilst acknowledging the approaches are applicable to all endpoints. Templates, developed from work to prepare for the application of new toxicological data to read-across assessment, are presented. These templates act as proposals to assist in assessing similarity in the context of chemistry, toxicokinetics and toxicodynamics as well as to guide the systematic characterisation of uncertainty both in the context of the similarity rationale, the read across data and overall approach and conclusion. Lastly, a workflow for reporting a read-across prediction is suggested.},
author = {Schultz, T W and Amcoff, P and Berggren, E and Gautier, F and Klaric, M and Knight, D J and Mahony, C and Schwarz, M and White, A and Cronin, M T D},
doi = {https://doi.org/10.1016/j.yrtph.2015.05.016},
issn = {0273-2300},
journal = {Regul. Toxicol. Pharmacol.},
keywords = {Chemical analogue identification,OECD,Prediction,REACH,Read-across,Regulatory acceptance,Similarity,Toxicity,Uncertainty},
number = {3},
pages = {586--601},
title = {{A strategy for structuring and reporting a read-across prediction of toxicity}},
url = {http://www.sciencedirect.com/science/article/pii/S0273230015001154},
volume = {72},
year = {2015}
}
@article{Haggart2011,
abstract = {With the advent of modern high-throughput genomics, there is a significant need for  genome-scale analysis techniques that can assist in complex systems analysis. Metabolic genome-scale network reconstructions (GENREs) paired with constraint-based modeling are an efficient method to integrate genomics, transcriptomics, and proteomics to conduct organism-specific analysis. This text explains key steps in the GENRE construction process and several methods of constraint-based modeling that can help elucidate basic life processes and development of disease treatment, bioenergy solutions, and industrial bioproduction applications.},
author = {Haggart, Charles R and Bartell, Jennifer A and Saucerman, Jeffrey J and Papin, Jason A},
doi = {10.1016/B978-0-12-385118-5.00021-9},
issn = {1557-7988 (Electronic)},
journal = {Methods Enzymol.},
keywords = {Algorithms,Animals,Bayes Theorem,Computer Simulation,Databases, Genetic,Gene Expression Profiling,Genome, Human,Humans,Metabolic Networks and Pathways,Models, Biological,Systems Biology,genetics},
language = {eng},
pages = {411--433},
pmid = {21943909},
title = {{Whole-genome metabolic network reconstruction and constraint-based modeling.}},
volume = {500},
year = {2011}
}
@article{ashtawy_comparative_2015,
abstract = {Accurately predicting the binding affinities of large diverse sets of protein-ligand complexes efficiently is a key challenge in computational biomolecular science, with applications in drug discovery, chemical biology, and structural biology. Since a scoring function (SF) is used to score, rank, and identify potential drug leads, the fidelity with which it predicts the affinity of a ligand candidate for a protein's binding site has a significant bearing on the accuracy of virtual screening. Despite intense efforts in developing conventional SFs, which are either force-field based, knowledge-based, or empirical, their limited predictive accuracy has been a major roadblock toward cost-effective drug discovery. Therefore, in this work, we explore a range of novel SFs employing different machine-learning (ML) approaches in conjunction with a variety of physicochemical and geometrical features characterizing protein-ligand complexes. We assess the scoring accuracies of these new ML SFs as well as those of conventional SFs in the context of the 2007 and 2010 PDBbind benchmark datasets on both diverse and protein-family-specific test sets. We also investigate the influence of the size of the training dataset and the type and number of features used on scoring accuracy. We find that the best performing ML SF has a Pearson correlation coefficient of 0.806 between predicted and measured binding affinities compared to 0.644 achieved by a state-of-the-art conventional SF. We also find that ML SFs benefit more than their conventional counterparts from increases in the number of features and the size of training dataset. In addition, they perform better on novel proteins that they were never trained on before.},
author = {Ashtawy, Hossam M. and Mahapatra, Nihar R.},
doi = {10.1109/TCBB.2014.2351824},
issn = {15455963},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinforma.},
keywords = {Drug discovery,Machine learning,Protein-ligand binding affinity,Scoring function,Scoring power,Virtual screening},
number = {2},
pages = {335--347},
title = {{A comparative assessment of predictive accuracies of conventional and machine learning scoring functions for protein-ligand binding affinity prediction}},
url = {http://ieeexplore.ieee.org/document/6883187/},
volume = {12},
year = {2015}
}
@article{Zyprych-Walczak2015,
abstract = {High-throughput sequencing technologies, such as the Illumina Hi-seq, are powerful new tools for investigating a wide range of biological and medical problems. Massive and complex data sets produced by the sequencers create a need for development of statistical and computational methods that can tackle the analysis and management of data. The data normalization is one of the most crucial steps of data processing and this process must be carefully considered as it has a profound effect on the results of the analysis. In this work, we focus on a comprehensive comparison of five normalization methods related to sequencing depth, widely used for transcriptome sequencing (RNA-seq) data, and their impact on the results of gene expression analysis. Based on this study, we suggest a universal workflow that can be applied for the selection of the optimal normalization procedure for any particular data set. The described workflow includes calculation of the bias and variance values for the control genes, sensitivity and specificity of the methods, and classification errors as well as generation of the diagnostic plots. Combining the above information facilitates the selection of the most appropriate normalization method for the studied data sets and determines which methods can be used interchangeably.},
author = {Zyprych-Walczak, J. and Szabelska, A. and Handschuh, L. and G{\'{o}}rczak, K. and Klamecka, K. and Figlerowicz, M. and Siatkowski, I.},
doi = {10.1155/2015/621690},
issn = {23146141},
journal = {Biomed Res. Int.},
title = {{The Impact of Normalization Methods on RNA-Seq Data Analysis}},
volume = {2015},
year = {2015}
}
@article{Opdam2017,
abstract = {Genome-scale models of metabolism can illuminate the molecular basis of cell  phenotypes. Since some enzymes are only active in specific cell types, several algorithms use omics data to construct cell-line- and tissue-specific metabolic models from genome-scale models. However, these methods are often not rigorously benchmarked, and it is unclear how algorithm and parameter selection (e.g., gene expression thresholds, metabolic constraints) affects model content and predictive accuracy. To investigate this, we built hundreds of models of four different cancer cell lines using six algorithms, four gene expression thresholds, and three sets of metabolic constraints. Model content varied substantially across different parameter sets, but the algorithms generally increased accuracy in gene essentiality predictions. However, model extraction method choice had the largest impact on model accuracy. We further highlight how assumptions during model development influence model prediction accuracy. These insights will guide further development of context-specific models, thus more accurately resolving genotype-phenotype relationships.},
author = {Opdam, Sjoerd and Richelle, Anne and Kellman, Benjamin and Li, Shanzhong and Zielinski, Daniel C and Lewis, Nathan E},
doi = {10.1016/j.cels.2017.01.010},
issn = {2405-4712 (Print)},
journal = {Cell Syst.},
keywords = {Algorithms,Animals,Forecasting,Genome,Genomics,Humans,Metabolomics,Models, Biological,Models, Theoretical,Systems Biology,methods},
language = {eng},
month = {mar},
number = {3},
pages = {318--329.e6},
pmid = {28215528},
title = {{A Systematic Evaluation of Methods for Tailoring Genome-Scale Metabolic Models.}},
volume = {4},
year = {2017}
}
@article{Benedetti2020,
abstract = {{\textless}p{\textgreater}Correlation networks are frequently used to statistically extract biological interactions between omics markers. Network edge selection is typically based on the statistical significance of the correlation coefficients. This procedure, however, is not guaranteed to capture biological mechanisms. We here propose an alternative approach for network reconstruction: a cutoff selection algorithm that maximizes the overlap of the inferred network with available prior knowledge. We first evaluate the approach on IgG glycomics data, for which the biochemical pathway is known and well-characterized. Importantly, even in the case of incomplete or incorrect prior knowledge, the optimal network is close to the true optimum. We then demonstrate the generalizability of the approach with applications to untargeted metabolomics and transcriptomics data. For the transcriptomics case, we demonstrate that the optimized network is superior to statistical networks in systematically retrieving interactions that were not included in the biological reference used for optimization.{\textless}/p{\textgreater}},
author = {Benedetti, Elisa and Pu{\v{c}}i{\'{c}}-Bakovi{\'{c}}, Maja and Keser, Toma and Gerstner, Nathalie and B{\"{u}}y{\"{u}}k{\"{o}}zkan, Mustafa and {\v{S}}tambuk, Tamara and Selman, Maurice H. J. and Rudan, Igor and Pola{\v{s}}ek, Ozren and Hayward, Caroline and Al-Amin, Hassen and Suhre, Karsten and Kastenm{\"{u}}ller, Gabi and Lauc, Gordan and Krumsiek, Jan},
doi = {10.1038/s41467-020-18675-3},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Benedetti et al. - 2020 - A strategy to incorporate prior knowledge into correlation network cutoff selection.pdf:pdf},
issn = {2041-1723},
journal = {Nat. Commun.},
keywords = {Biochemical reaction networks,Computational biology and bioinformatics,Computational models},
month = {dec},
number = {1},
pages = {5153},
publisher = {Nature Publishing Group},
title = {{A strategy to incorporate prior knowledge into correlation network cutoff selection}},
url = {http://www.nature.com/articles/s41467-020-18675-3},
volume = {11},
year = {2020}
}
@article{McCall2014,
abstract = {The Gene Expression Barcode project, http://barcode.luhs.org, seeks to determine the  genes expressed for every tissue and cell type in humans and mice. Understanding the absolute expression of genes across tissues and cell types has applications in basic cell biology, hypothesis generation for gene function and clinical predictions using gene expression signatures. In its current version, this project uses the abundant publicly available microarray data sets combined with a suite of single-array preprocessing, quality control and analysis methods. In this article, we present the improvements that have been made since the previous version of the Gene Expression Barcode in 2011. These include a variety of new data mining tools and summaries, estimated transcriptomes and curated annotations.},
author = {McCall, Matthew N and Jaffee, Harris A and Zelisko, Susan J and Sinha, Neeraj and Hooiveld, Guido and Irizarry, Rafael A and Zilliox, Michael J},
doi = {10.1093/nar/gkt1204},
issn = {1362-4962 (Electronic)},
journal = {Nucleic Acids Res.},
keywords = {Animals,Data Mining,Databases, Genetic,Gene Expression Profiling,Humans,Internet,Mice,Oligonucleotide Array Sequence Analysis,Software,Transcriptome},
language = {eng},
month = {jan},
number = {Database issue},
pages = {D938--43},
pmid = {24271388},
title = {{The Gene Expression Barcode 3.0: improved data processing and mining tools.}},
volume = {42},
year = {2014}
}
@article{li_assessing_2018,
abstract = {Scoring functions are a group of computational methods widely applied in structure-based drug design for fast evaluation of protein-ligand interactions. To date, a whole spectrum of scoring functions have been developed based on different assumptions or algorithms. Therefore, it is important to both the end users and the developers of scoring functions that their performance be objectively assessed. We have developed the comparative assessment of scoring functions (CASF) benchmark as an open-access solution for scoring function evaluation. The latest CASF-2013 benchmark enables evaluation of the so-called 'scoring power', 'ranking power', 'docking power', and 'screening power' of a given scoring function with a high-quality test set of 195 complexes formed between diverse protein molecules and their small-molecule ligands. Evaluation results of the standard scoring functions implemented in several mainstream software programs (including Schr{\"{o}}dinger, MOE, Discovery Studio, SYBYL, and GOLD) are provided as reference. This benchmark has become popular among the scoring function community since its first release. In this protocol, we provide detailed descriptions of the data files included in the CASF-2013 package and step-by-step instructions on how to conduct the performance tests with the ready-to-use computer scripts included in the package. This protocol is expected to lower the technical hurdles in front of new and existing users of the CASF-2013 benchmark. On a standard desktop workstation, it takes roughly half an hour to complete the whole evaluation procedure for one scoring function, once the required inputs, i.e., the results computed on the test set, are ready to use.},
author = {Li, Yan and Su, Minyi and Liu, Zhihai and Li, Jie and Liu, Jie and Han, Li and Wang, Renxiao},
doi = {10.1038/nprot.2017.114},
issn = {17502799},
journal = {Nat. Protoc.},
number = {4},
pages = {666--680},
title = {{Assessing protein-ligand interaction scoring functions with the CASF-2013 benchmark}},
url = {http://www.nature.com/doifinder/10.1038/nprot.2017.114},
volume = {13},
year = {2018}
}
@article{Josse2008,
abstract = {The human hepatoma HepaRG cells are able to differentiate in vitro into hepatocyte-like cells and to express various liver-specific functions, including the major cytochromes P450. This study was aimed to determine whether differentiated HepaRG cells retained their specific functional capacities for a long time period at confluence. We show that expression of transcripts encoding CYP1A2, 2B6, 3A4, and 2E1, several phase II and antioxidant enzymes, membrane transporters, including organic cation transporter 1 and bile salt export pump, the nuclear receptors constitutive androstane receptor and pregnane X receptor, and aldolase B remained relatively stable for at least the 4-week confluence period tested. Similarly, activities of CYP3A4 and CYP1A2 and their responsiveness to prototypical inducers were well preserved. Aflatoxin B1, a potent hepatotoxicant and carcinogen, induced a dose-dependent and cumulative cytotoxicity. Furthermore, at a concentration as low as 0.1 $\mu$M, this mycotoxin caused a decrease in both CYP3A4 activity and intracellular ATP associated with morphological alterations, after 14 days following every 2-day exposure. Moreover, using the comet assay, a dose-dependent DNA damage was observed after a 3-h treatment of differentiated HepaRG cells with 1 to 5 $\mu$M aflatoxin B1 in the absence of any cell damage, and this DNA damaging effect was strongly reduced in the presence of ketoconazole, a CYP3A4 inhibitor. These results bring the first demonstration of long-term stable expression of liver-specific markers in HepaRG hepatocyte cultures maintained at confluence and show that these cells represent a suitable in vitro liver cell model for analysis of acute and chronic toxicity as well as genotoxicity of chemicals in human liver. The American Society for Pharmacology and Experimental Therapeutics},
author = {Joss{\'{e}}, Rozenn and Aninat, Caroline and Glaise, Denise and Dumont, Julie and Fessard, Val{\'{e}}rie and Morel, Fabrice and Poul, Jean-Michel and Guguen-Guillouzo, Christiane and Guillouzo, Andr{\'{e}}},
doi = {10.1124/dmd.107.019901},
journal = {Drug Metab. Dispos.},
month = {jun},
number = {6},
pages = {1111 LP  -- 1118},
title = {{Long-Term Functional Stability of Human HepaRG Hepatocytes and Use for Chronic Toxicity and Genotoxicity Studies}},
url = {http://dmd.aspetjournals.org/content/36/6/1111.abstract},
volume = {36},
year = {2008}
}
@misc{PPR:PPR121426,
author = {Liu, Anika and Walter, Moritz and Wright, Peter and Bartosik, Aleksandra Maria and Dolciami, Daniela and Elbasir, Abdurrahman and Yang, Hongbin and Bender, Andreas},
doi = {10.21203/rs.3.rs-16599/v1},
publisher = {Research Square},
title = {{Prediction and mechanistic analysis of Drug-Induced Liver Injury (DILI) based on chemical structure}},
url = {https://doi.org/10.21203/rs.3.rs-16599/v1},
year = {2020}
}
@book{laurent_schaeffer_role_nodate,
author = {Schaeffer, Laurent},
title = {{The {\{}Role{\}} of {\{}Functional{\}} {\{}Groups{\}} in {\{}Drug{\}}–{\{}Receptor{\}} {\{}Interactions{\}}.{\{}The{\}} {\{}Practice{\}} of {\{}Medicinal{\}} {\{}Chemistry{\}} ({\{}Fourth{\}} {\{}Edition{\}}), 2008}}
}
@article{Castillo2017,
abstract = {BACKGROUND: Nowadays, many public repositories containing large microarray gene expression datasets are available. However, the problem lies in the fact that microarray technology are less powerful and accurate than more recent Next Generation Sequencing technologies, such as RNA-Seq. In any case, information from microarrays is truthful and robust, thus it can be exploited through the integration of microarray data with RNA-Seq data. Additionally, information extraction and acquisition of large number of samples in RNA-Seq still entails very high costs in terms of time and computational resources.This paper proposes a new model to find the gene signature of breast cancer cell lines through the integration of heterogeneous data from different breast cancer datasets, obtained from microarray and RNA-Seq technologies. Consequently, data integration is expected to provide a more robust statistical significance to the results obtained. Finally, a classification method is proposed in order to test the robustness of the Differentially Expressed Genes when unseen data is presented for diagnosis. RESULTS: The proposed data integration allows analyzing gene expression samples coming from different technologies. The most significant genes of the whole integrated data were obtained through the intersection of the three gene sets, corresponding to the identified expressed genes within the microarray data itself, within the RNA-Seq data itself, and within the integrated data from both technologies. This intersection reveals 98 possible technology-independent biomarkers. Two different heterogeneous datasets were distinguished for the classification tasks: a training dataset for gene expression identification and classifier validation, and a test dataset with unseen data for testing the classifier. Both of them achieved great classification accuracies, therefore confirming the validity of the obtained set of genes as possible biomarkers for breast cancer. Through a feature selection process, a final small subset made up by six genes was considered for breast cancer diagnosis. CONCLUSIONS: This work proposes a novel data integration stage in the traditional gene expression analysis pipeline through the combination of heterogeneous data from microarrays and RNA-Seq technologies. Available samples have been successfully classified using a subset of six genes obtained by a feature selection method. Consequently, a new classification and diagnosis tool was built and its performance was validated using previously unseen samples.},
author = {Castillo, Daniel and G{\'{a}}lvez, Juan Manuel and Herrera, Luis Javier and Rom{\'{a}}n, Bel{\'{e}}n San and Rojas, Fernando and Rojas, Ignacio},
doi = {10.1186/s12859-017-1925-0},
issn = {1471-2105},
journal = {BMC Bioinformatics},
keywords = {Algorithms,Breast Neoplasms/*genetics,Breast cancer,Cancer,Classification,Cluster Analysis,Databases, Genetic,Female,Gene Expression Profiling/*methods,Gene Expression Regulation, Neoplastic,Gene expression,Humans,Integration,Microarray,Oligonucleotide Array Sequence Analysis/*methods,RNA-Seq,Random Forest,Reproducibility of Results,SVM,Sequence Analysis, RNA/*methods,k-NN},
language = {eng},
month = {nov},
number = {1},
pages = {506},
publisher = {BioMed Central},
title = {{Integration of RNA-Seq data with heterogeneous microarray data for breast cancer profiling}},
url = {https://pubmed.ncbi.nlm.nih.gov/29157215 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5697344/},
volume = {18},
year = {2017}
}
@article{Bordbar2012,
abstract = {Abstract.? Bordbar A, Palsson BO (University of California San Diego, La Jolla, CA, USA). Using the reconstructed genome-scale human metabolic network to study physiology and pathology (Key Symposium). J Intern Med 2012; 271: 131?141. Metabolism plays a key role in many major human diseases. Generation of high-throughput omics data has ushered in a new era of systems biology. Genome-scale metabolic network reconstructions provide a platform to interpret omics data in a biochemically meaningful manner. The release of the global human metabolic network, Recon 1, in 2007 has enabled new systems biology approaches to study human physiology, pathology and pharmacology. There are currently more than 20 publications that utilize Recon 1, including studies of cancer, diabetes, host?pathogen interactions, heritable metabolic disorders and off-target drug binding effects. In this mini-review, we focus on the reconstruction of the global human metabolic network and four classes of its application. We show that computational simulations for numerous pathologies have yielded clinically relevant results, many corroborated by existing or newly generated experimental data.},
annote = {doi: 10.1111/j.1365-2796.2011.02494.x},
author = {Bordbar, A and Palsson, B O},
doi = {10.1111/j.1365-2796.2011.02494.x},
issn = {0954-6820},
journal = {J. Intern. Med.},
keywords = {constraints-based modelling,human metabolism,systems biology},
month = {feb},
number = {2},
pages = {131--141},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Using the reconstructed genome-scale human metabolic network to study physiology and pathology}},
url = {https://doi.org/10.1111/j.1365-2796.2011.02494.x},
volume = {271},
year = {2012}
}
@article{balius_dock_nodate,
author = {Balius, Trent E},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Balius - Unknown - {\{}DOCK{\}} 3.7 {\{}How{\}} {\{}It{\}} {\{}Works{\}} – and {\{}How{\}} to {\{}Tweak{\}} your {\{}Setup{\}}.pdf:pdf},
pages = {61},
title = {{{\{}DOCK{\}} 3.7: {\{}How{\}} {\{}It{\}} {\{}Works{\}} – and {\{}How{\}} to {\{}Tweak{\}} your {\{}Setup{\}}}}
}
@article{Blais2017,
abstract = {The laboratory rat has been used as a surrogate to study human biology for more than a century. Here we present the first genome-scale network reconstruction of Rattus norvegicus metabolism, iRno, and a significantly improved reconstruction of human metabolism, iHsa. These curated models comprehensively capture metabolic features known to distinguish rats from humans including vitamin C and bile acid synthesis pathways. After reconciling network differences between iRno and iHsa, we integrate toxicogenomics data from rat and human hepatocytes, to generate biomarker predictions in response to 76 drugs. We validate comparative predictions for xanthine derivatives with new experimental data and literature-based evidence delineating metabolite biomarkers unique to humans. Our results provide mechanistic insights into species-specific metabolism and facilitate the selection of biomarkers consistent with rat and human biology. These models can serve as powerful computational platforms for contextualizing experimental data and making functional predictions for clinical and basic science applications.},
author = {Blais, Edik M and Rawls, Kristopher D and Dougherty, Bonnie V and Li, Zhuo I and Kolling, Glynis L and Ye, Ping and Wallqvist, Anders and Papin, Jason A},
doi = {10.1038/ncomms14250},
issn = {2041-1723},
journal = {Nat. Commun.},
number = {1},
pages = {14250},
title = {{Reconciled rat and human metabolic networks for comparative toxicogenomics and biomarker predictions}},
url = {https://doi.org/10.1038/ncomms14250},
volume = {8},
year = {2017}
}
@article{Larriba2019d,
abstract = {Data derived from microarray technologies are generally subject to various sources  of noise and accordingly the raw data are pre-processed before formally analysed. Data normalization is a key pre-processing step when dealing with microarray experiments, such as circadian gene-expressions, since it removes systematic variations across arrays. A wide variety of normalization methods are available in the literature. However, from our experience in the study of rhythmic expression patterns in oscillatory systems (e.g. cell-cycle, circadian clock), the choice of the normalization method may substantially impair the identification of rhythmic genes. Hence, the identification of a gene as rhythmic could be just as an artefact of how the data were normalized. Yet, gene rhythmicity detection is crucial in modern toxicological and pharmacological studies, thus a procedure to truly identify rhythmic genes that are robust to the choice of a normalization method is required.To perform the task of detecting rhythmic features, we propose a rhythmicity measure based on bootstrap methodology to robustly identify rhythmic genes in oscillatory systems. Although our methodology can be extended to any high-throughput experiment, in this chapter, we illustrate how to apply it to a publicly available circadian clock microarray gene-expression data and give full details (both statistical and computational) so that the methodology can be used in an easy way. We will show that the choice of normalization method has very little effect on the proposed methodology since the results derived from the bootstrap-based rhythmicity measure are highly rank correlated for any pair of normalization methods considered. This suggests, on the one hand, that the rhythmicity measure proposed is robust to the choice of the normalization method, and on the other hand, that gene rhythmicity detected using this measure is potentially not a mere artefact of the normalization method used. In this way the researcher using this methodology will be protected against the possible effect of different normalizations, as the conclusions obtained will not depend so strongly on them. Additionally, the described bootstrap methodology can also be employed as a tool to simulate gene-expression participating in an oscillatory system from a reference data set.},
author = {Larriba, Yolanda and Rueda, Cristina and Fern{\'{a}}ndez, Miguel A and Peddada, Shyamal D},
doi = {10.1007/978-1-4939-9442-7_9},
issn = {1940-6029 (Electronic)},
journal = {Methods Mol. Biol.},
keywords = {Algorithms,Cell Line, Tumor,Gene Expression Regulation,Humans,Oligonucleotide Array Sequence Analysis,Statistics, Nonparametric,methods},
language = {eng},
pages = {207--225},
pmid = {31115890},
title = {{Microarray Data Normalization and Robust Detection of Rhythmic Features.}},
volume = {1986},
year = {2019}
}
@article{VandenHof2014,
annote = {doi: 10.1021/tx4004165},
author = {{Van den Hof}, Wim F P M and Coonen, Maarten L J and van Herwijnen, Marcel and Brauers, Karen and Wodzig, Will K W H and van Delft, Joost H M and Kleinjans, Jos C S},
doi = {10.1021/tx4004165},
issn = {0893-228X},
journal = {Chem. Res. Toxicol.},
month = {mar},
number = {3},
pages = {433--442},
publisher = {American Chemical Society},
title = {{Classification of Hepatotoxicants Using HepG2 Cells: A Proof of Principle Study}},
url = {https://doi.org/10.1021/tx4004165},
volume = {27},
year = {2014}
}
@article{irwin_zinc:_2012,
abstract = {ZINC is a free public resource for ligand discovery. The database contains over twenty million commercially available molecules in biologically relevant representations that may be downloaded in popular ready-to-dock formats and subsets. The Web site also enables searches by structure, biological activity, physical property, vendor, catalog number, name, and CAS number. Small custom subsets may be created, edited, shared, docked, downloaded, and conveyed to a vendor for purchase. The database is maintained and curated for a high purchasing success rate and is freely available at zinc.docking.org. {\textcopyright} 2012 American Chemical Society.},
author = {Irwin, John J. and Sterling, Teague and Mysinger, Michael M. and Bolstad, Erin S. and Coleman, Ryan G.},
doi = {10.1021/ci3001277},
issn = {15499596},
journal = {J. Chem. Inf. Model.},
keywords = {*Chemistry,*Databases as Topic/economics,Bioinorganic,Biology/*methods,Drug Delivery Systems,Small Molecule Libraries/chemistry},
number = {7},
pages = {1757--1768},
pmid = {22587354},
title = {{ZINC: A free tool to discover chemistry for biology}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/22587354},
volume = {52},
year = {2012}
}
@article{Chen2019,
abstract = {Performance of structure-based molecular docking largely depends on the accuracy of scoring functions. One important type of scoring functions are knowledge-based potentials derived from known three-dimensional structures of proteins and/or protein–ligand complex structures. This study seeks to improve a knowledge-based protein–ligand potential based on a distance-scale finite ideal-gas reference (DFIRE) state (DLIGAND) by expanding the representation of protein atoms from 13 mol2 atom types to 167 residue-specific atom types, and employing a recently updated dataset containing 12,450 monomer protein chains for training. We found that the updated version DLIGAND2 has a consistent improvement over DLIGAND in predicting binding affinities for either native complex structures or docking-generated poses. More importantly, DLIGAND2 has a 52{\%} increase over DLIGAND in enrichment factors in top 1{\%} predictions based on the DUD-E decoy set, and consistently improves over Autodock Vina and other statistical energy functions in all three benchmark tests. We further found that DLIGAND2 outperforms empirical and machine-learning methods compared for virtual screening on new targets that are not homologous to the DUD-E training set. Given the best performance as a parameter-free statistical potential and among the best in all performance measures, DLIGAND2 should be useful for re-assessing the poses generated by docking software, or acting as one term in other scoring functions. The program is available at 
                  https://github.com/sysu-yanglab/DLIGAND2
                  
                .},
author = {Chen, Pin and Ke, Yaobin and Lu, Yutong and Du, Yunfei and Li, Jiahui and Yan, Hui and Zhao, Huiying and Zhou, Yaoqi and Yang, Yuedong},
doi = {10.1186/s13321-019-0373-4},
file = {:C$\backslash$:/Users/louison.fresnais/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2019 - DLIGAND2 an improved knowledge-based energy function for protein–ligand interactions using the distance-scaled, fin.pdf:pdf},
issn = {1758-2946},
journal = {J. Cheminform.},
keywords = {Computational Biology/Bioinformatics,Computer Applications in Chemistry,Documentation and Information in Chemistry,Theoretical and Computational Chemistry},
month = {dec},
number = {1},
pages = {52},
publisher = {BioMed Central},
title = {{DLIGAND2: an improved knowledge-based energy function for protein–ligand interactions using the distance-scaled, finite, ideal-gas reference state}},
url = {https://jcheminf.biomedcentral.com/articles/10.1186/s13321-019-0373-4},
volume = {11},
year = {2019}
}
@article{Vinken2012,
abstract = {Alternative methods, replacing animal testing, are urgently needed in view of the European regulatory changes in the field of cosmetic products and their ingredients. In this context, a joint research initiative called SEURAT was recently raised by the European Commission and COLIPA, representing the European cosmetics industry, with the overall goal of developing an animal-free repeated dose toxicity testing strategy for human safety assessment purposes. Although cosmetic ingredients are usually harmless for the consumer, one of the initial tasks of this research consortium included the identification of organs that could potentially be affected by cosmetic ingredients upon systemic exposure. The strategy that was followed hereof is described in the present paper and relies on the systematic evaluation, by using a self-generated electronic databank, of published reports issued by the scientific committee of DG SANCO responsible for the safety of cosmetic ingredients. By screening of the repeated dose toxicity studies present in these reports, it was found that the liver is potentially the most frequently targeted organ by cosmetic ingredients when orally administered to experimental animals, followed by the kidney and the spleen. Combined listing of altered morphological, histopathological, and biochemical parameters subsequently indicated the possible occurrence of hepatotoxicity, including steatosis and cholestasis, triggered by a limited number of cosmetic compounds. These findings are not only of relevance for the in vitro modeling efforts and choice of compounds to be tested in the SEURAT project cluster, but also demonstrate the importance of using previously generated toxicological data through an electronic databank for addressing specific questions regarding the safety evaluation of cosmetic ingredients.},
author = {Vinken, Mathieu and Pauwels, Marleen and Ates, Gamze and Vivier, Manon and Vanhaecke, Tamara and Rogiers, Vera},
doi = {10.1007/s00204-011-0769-z},
issn = {1432-0738},
journal = {Arch. Toxicol.},
number = {3},
pages = {405--412},
title = {{Screening of repeated dose toxicity data present in SCC(NF)P/SCCS safety evaluations of cosmetic ingredients}},
url = {https://doi.org/10.1007/s00204-011-0769-z},
volume = {86},
year = {2012}
}
@misc{Smalley2010,
abstract = {Connectivity mapping is the process of establishing connections between different biological states using gene-expression profiles or signatures. There are a number of applications but in toxicology the most pertinent is for understanding mechanisms of toxicity. In its essence the process involves comparing a query gene signature generated as a result of exposure of a biological system to a chemical to those in a database that have been previously derived. In the ideal situation the query gene-expression signature is characteristic of the event and will be matched to similar events in the database. Key criteria are therefore the means of choosing the signature to be matched and the means by which the match is made. In this article we explore these concepts with examples applicable to toxicology. {\textcopyright} 2009 Elsevier Ireland Ltd. All rights reserved.},
author = {Smalley, Joshua L. and Gant, Timothy W. and Zhang, Shu Dong},
booktitle = {Toxicology},
doi = {10.1016/j.tox.2009.09.014},
issn = {0300483X},
keywords = {Connectivity mapping,Predictive toxicology,Query gene signature,Reference gene-expression profile},
month = {feb},
number = {3},
pages = {143--146},
title = {{Application of connectivity mapping in predictive toxicology based on gene-expression similarity}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0300483X09004879},
volume = {268},
year = {2010}
}
@article{rogers_extended-connectivity_2010,
abstract = {Extended-connectivity fingerprints (ECFPs) are a novel class of topological fingerprints for molecular characterization. Historically, topological fingerprints were developed for substructure and similarity searching. ECFPs were developed specifically for structure-activity modeling. ECFPs are circular fingerprints with a number of useful qualities: they can be very rapidly calculated; they are not predefined and can represent an essentially infinite number of different molecular features (including stereochemical information); their features represent the presence of particular substructures, allowing easier interpretation of analysis results; and the ECFP algorithm can be tailored to generate different types of circular fingerprints, optimized for different uses. While the use of ECFPs has been widely adopted and validated, a description of their implementation has not previously been presented in the literature. {\textcopyright} 2010 American Chemical Society.},
annote = {doi: 10.1021/ci100050t},
author = {Rogers, David and Hahn, Mathew},
doi = {10.1021/ci100050t},
issn = {15499596},
journal = {J. Chem. Inf. Model.},
number = {5},
pages = {742--754},
title = {{Extended-connectivity fingerprints}},
url = {https://doi.org/10.1021/ci100050t},
volume = {50},
year = {2010}
}
@article{Subramanian2017,
abstract = {We previously piloted the concept of a Connectivity Map (CMap), whereby genes,  drugs, and disease states are connected by virtue of common gene-expression signatures. Here, we report more than a 1,000-fold scale-up of the CMap as part of the NIH LINCS Consortium, made possible by a new, low-cost, high-throughput reduced representation expression profiling method that we term L1000. We show that L1000 is highly reproducible, comparable to RNA sequencing, and suitable for computational inference of the expression levels of 81{\%} of non-measured transcripts. We further show that the expanded CMap can be used to discover mechanism of action of small molecules, functionally annotate genetic variants of disease genes, and inform clinical trials. The 1.3 million L1000 profiles described here, as well as tools for their analysis, are available at https://clue.io.},
author = {Subramanian, Aravind and Narayan, Rajiv and Corsello, Steven M and Peck, David D and Natoli, Ted E and Lu, Xiaodong and Gould, Joshua and Davis, John F and Tubelli, Andrew A and Asiedu, Jacob K and Lahr, David L and Hirschman, Jodi E and Liu, Zihan and Donahue, Melanie and Julian, Bina and Khan, Mariya and Wadden, David and Smith, Ian C and Lam, Daniel and Liberzon, Arthur and Toder, Courtney and Bagul, Mukta and Orzechowski, Marek and Enache, Oana M and Piccioni, Federica and Johnson, Sarah A and Lyons, Nicholas J and Berger, Alice H and Shamji, Alykhan F and Brooks, Angela N and Vrcic, Anita and Flynn, Corey and Rosains, Jacqueline and Takeda, David Y and Hu, Roger and Davison, Desiree and Lamb, Justin and Ardlie, Kristin and Hogstrom, Larson and Greenside, Peyton and Gray, Nathanael S and Clemons, Paul A and Silver, Serena and Wu, Xiaoyun and Zhao, Wen-Ning and Read-Button, Willis and Wu, Xiaohua and Haggarty, Stephen J and Ronco, Lucienne V and Boehm, Jesse S and Schreiber, Stuart L and Doench, John G and Bittker, Joshua A and Root, David E and Wong, Bang and Golub, Todd R},
doi = {10.1016/j.cell.2017.10.049},
issn = {1097-4172 (Electronic)},
journal = {Cell},
keywords = {Cell Line, Tumor,Drug Resistance, Neoplasm,Gene Expression Profiling,Humans,Neoplasms,Organ Specificity,Pharmaceutical Preparations,Sequence Analysis, RNA,Small Molecule Libraries,drug therapy,economics,metabolism,methods},
language = {eng},
month = {nov},
number = {6},
pages = {1437--1452.e17},
pmid = {29195078},
title = {{A Next Generation Connectivity Map: L1000 Platform and the First 1,000,000 Profiles.}},
volume = {171},
year = {2017}
}
@misc{noauthor_adl:_nodate,
title = {{{\{}ADL{\}}: {\{}Autodock{\}} results: http://mgldev.scripps.edu/pipermail/autodock/2009-{\{}April{\}}/005619.html}},
url = {http://mgldev.scripps.edu/pipermail/autodock/2009-April/005619.html}
}
